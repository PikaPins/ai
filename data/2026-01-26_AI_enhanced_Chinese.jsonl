{"id": "2601.16241", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.16241", "abs": "https://arxiv.org/abs/2601.16241", "authors": ["Xinyu Li", "Jinyang Huang", "Feng-Qi Cui", "Meng Wang", "Peng Zhao", "Meng Li", "Dan Guo", "Meng Wang"], "title": "A New Paradigm for Trusted Respiratory Monitoring Via Consumer Electronics-grade Radar Signals", "comment": null, "summary": "Respiratory monitoring is an extremely important task in modern medical services. Due to its significant advantages, e.g., non-contact, radar-based respiratory monitoring has attracted widespread attention from both academia and industry. Unfortunately, though it can achieve high monitoring accuracy, consumer electronics-grade radar data inevitably contains User-sensitive Identity Information (USI), which may be maliciously used and further lead to privacy leakage. To track these challenges, by variational mode decomposition (VMD) and adversarial loss-based encryption, we propose a novel Trusted Respiratory Monitoring paradigm, Tru-RM, to perform automated respiratory monitoring through radio signals while effectively anonymizing USI. The key enablers of Tru-RM are Attribute Feature Decoupling (AFD), Flexible Perturbation Encryptor (FPE), and robust Perturbation Tolerable Network (PTN) used for attribute decomposition, identity encryption, and perturbed respiratory monitoring, respectively. Specifically, AFD is designed to decompose the raw radar signals into the universal respiratory component, the personal difference component, and other unrelated components. Then, by using large noise to drown out the other unrelated components, and the phase noise algorithm with a learning intensity parameter to eliminate USI in the personal difference component, FPE is designed to achieve complete user identity information encryption without affecting respiratory features. Finally, by designing the transferred generalized domain-independent network, PTN is employed to accurately detect respiration when waveforms change significantly. Extensive experiments based on various detection distances, respiratory patterns, and durations demonstrate the superior performance of Tru-RM on strong anonymity of USI, and high detection accuracy of perturbed respiratory waveforms.", "AI": {"tldr": "Tru-RM\u662f\u57fa\u4e8eVMD\u548c\u5bf9\u6297\u635f\u5931\u7684\u52a0\u5bc6\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u53ef\u4fe1\u8d56\u547c\u5438\u76d1\u6d4b\u6846\u67b6\uff0c\u80fd\u591f\u5728\u51c6\u786e\u76d1\u6d4b\u547c\u5438\u7684\u540c\u65f6\u533f\u540d\u5316\u7528\u6237\u654f\u611f\u8eab\u4efd\u4fe1\u606f\u3002", "motivation": "\u968f\u7740\u96f7\u8fbe\u6280\u672f\u5728\u547c\u5438\u76d1\u6d4b\u9886\u57df\u7684\u5e94\u7528\uff0c\u5982\u4f55\u5728\u4fdd\u8bc1\u76d1\u6d4b\u51c6\u786e\u6027\u7684\u540c\u65f6\u4fdd\u62a4\u7528\u6237\u9690\u79c1\u6210\u4e3a\u4e86\u4e00\u4e2a\u6311\u6218\u3002", "method": "Tru-RM\u901a\u8fc7VMD\u5206\u89e3\u4fe1\u53f7\u5e76\u4f7f\u7528FPE\u548cPTN\u5206\u522b\u5b9e\u73b0\u8eab\u4efd\u4fe1\u606f\u7684\u89e3\u8026\u548c\u6270\u52a8\u540e\u7684\u547c\u5438\u76d1\u6d4b\u3002\u5177\u4f53\u800c\u8a00\uff0cAFD\u5c06\u539f\u59cb\u96f7\u8fbe\u4fe1\u53f7\u5206\u89e3\u4e3a\u901a\u7528\u547c\u5438\u6210\u5206\u3001\u4e2a\u4eba\u5dee\u5f02\u6210\u5206\u548c\u5176\u4ed6\u65e0\u5173\u6210\u5206\uff0cFPE\u901a\u8fc7\u5927\u91cf\u7684\u566a\u58f0\u548c\u76f8\u4f4d\u566a\u58f0\u7b97\u6cd5\u5206\u522b\u6291\u5236\u4e2a\u4eba\u5dee\u5f02\u6210\u5206\u4e2d\u7684\u8eab\u4efd\u4fe1\u606f\u53ca\u5176\u4f59\u65e0\u5173\u6210\u5206\uff0cPTN\u5219\u7528\u4e8e\u4ece\u6270\u52a8\u7684\u4fe1\u53f7\u4e2d\u6b63\u786e\u68c0\u6d4b\u547c\u5438\u3002", "result": "\u57fa\u4e8e\u4e0d\u540c\u68c0\u6d4b\u8ddd\u79bb\u3001\u547c\u5438\u6a21\u5f0f\u548c\u65f6\u95f4\u957f\u5ea6\u7684\u5927\u91cf\u5b9e\u9a8c\u663e\u793a\uff0cTru-RM\u5728\u4fdd\u62a4\u7528\u6237\u654f\u611f\u8eab\u4efd\u4fe1\u606f\u7684\u533f\u540d\u6027\u548c\u6270\u52a8\u540e\u7684\u547c\u5438\u6ce2\u5f62\u68c0\u6d4b\u51c6\u786e\u6027\u65b9\u9762\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002", "conclusion": "Tru-RM\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u5f0f\uff0c\u65e2\u4fdd\u8bc1\u4e86\u96f7\u8fbe\u547c\u5438\u76d1\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u53c8\u80fd\u591f\u5728\u4e0d\u635f\u5bb3\u547c\u5438\u76d1\u6d4b\u8d28\u91cf\u7684\u524d\u63d0\u4e0b\u4fdd\u62a4\u4e86\u7528\u6237\u7684\u9690\u79c1\u3002"}}
{"id": "2601.16298", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.16298", "abs": "https://arxiv.org/abs/2601.16298", "authors": ["Shaoyu Li", "Hexuan Yu", "Md Mohaimin Al Barat", "Yang Xiao", "Y. Thomas Hou", "Wenjing Lou"], "title": "FC-GUARD: Enabling Anonymous yet Compliant Fiat-to-Cryptocurrency Exchanges", "comment": "10 pages", "summary": "With the rise of decentralized finance, fiat-to-cryptocurrency exchange platforms have become popular entry points into the cryptocurrency ecosystem. However, these platforms frequently fail to ensure adequate privacy protection, as evidenced by real-world breaches that exposed personally identifiable information (PII) and crypto addresses. Such leaks enable adversaries to link real-world identities to cryptocurrency transactions, undermining the presumed anonymity of cryptocurrency use.\n  We propose FC-GUARD, a privacy-preserving exchange system designed to preserve user anonymity without compromising regulatory compliance in the exchange of fiat currency for cryptocurrencies. Leveraging verifiable credentials and zero-knowledge proof techniques, FC-GUARD enables fiat-to-cryptocurrency exchanges without revealing users' PII or fiat account details. This breaks the linkage between users' real-world identities and their cryptocurrency addresses, thereby upholding anonymity, a fundamental expectation in the cryptocurrency ecosystem. In addition, FC-GUARD complies with key regulations over cryptocurrency usage, such as know-your-customer requirements and auditability for tax reporting obligations by integrating a lawful de-anonymization mechanism that allows the auditing authority to identify misbehaving users. This ensures regulatory compliance while defaulting to privacy protection. We implement our system on both desktop and mobile platforms, and our evaluation shows its feasibility for practical deployment.", "AI": {"tldr": "FC-GUARD \u662f\u4e00\u79cd\u9690\u79c1\u4fdd\u62a4\u7684\u8d27\u5e01\u4ea4\u6613\u5e73\u53f0\uff0c\u80fd\u591f\u5728\u4e0d\u6cc4\u9732\u7528\u6237\u4e2a\u4eba\u4fe1\u606f\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u6cd5\u5b9a\u8d27\u5e01\u4e0e\u52a0\u5bc6\u8d27\u5e01\u7684\u4ea4\u6613\u3002\u8be5\u7cfb\u7edf\u91c7\u7528\u96f6\u77e5\u8bc6\u8bc1\u660e\u548c\u53ef\u9a8c\u8bc1\u51ed\u8bc1\u6280\u672f\uff0c\u540c\u65f6\u786e\u4fdd\u7b26\u5408\u4e0e\u52a0\u5bc6\u8d27\u5e01\u4f7f\u7528\u76f8\u5173\u7684\u76d1\u7ba1\u8981\u6c42\u3002", "motivation": "\u5f53\u524d\u7684\u52a0\u5bc6\u8d27\u5e01\u4ea4\u6613\u5e73\u53f0\u5728\u63d0\u4f9b\u4fbf\u5229\u7684\u540c\u65f6\uff0c\u4e5f\u5b58\u5728\u4e25\u91cd\u7684\u9690\u79c1\u6cc4\u9732\u95ee\u9898\uff0c\u5982\u771f\u5b9e\u8eab\u4efd\u4fe1\u606f\u548c\u52a0\u5bc6\u5730\u5740\u88ab\u66b4\u9732\u3002FC-GUARD \u7684\u63d0\u51fa\u610f\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u4e3a\u7528\u6237\u63d0\u4f9b\u533f\u540d\u4ea4\u6613\u7684\u540c\u65f6\u6ee1\u8db3\u76d1\u7ba1\u8981\u6c42\u3002", "method": "FC-GUARD \u91c7\u7528\u4e86\u96f6\u77e5\u8bc6\u8bc1\u660e\u548c\u53ef\u9a8c\u8bc1\u51ed\u8bc1\u6280\u672f\u6765\u5b9e\u73b0\u52a0\u5bc6\u8d27\u5e01\u4ea4\u6613\u8fc7\u7a0b\u4e2d\u7684\u9690\u79c1\u4fdd\u62a4\uff0c\u5e76\u901a\u8fc7\u6cd5\u5b9a\u5316\u53cd\u533f\u540d\u673a\u5236\u6765\u786e\u4fdd\u4ea4\u6613\u5e73\u53f0\u7684\u76d1\u7ba1\u5408\u89c4\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e FC-GUARD \u5728\u684c\u9762\u548c\u79fb\u52a8\u5e73\u53f0\u4e0a\u5177\u6709\u5b9e\u9645\u90e8\u7f72\u7684\u53ef\u80fd\u6027\uff0c\u80fd\u591f\u5728\u4fdd\u62a4\u7528\u6237\u9690\u79c1\u7684\u524d\u63d0\u4e0b\u6ee1\u8db3\u76d1\u7ba1\u8981\u6c42\u3002", "conclusion": "\u6211\u4eec\u9a8c\u8bc1\u4e86 FC-GUARD \u7cfb\u7edf\u5728\u589e\u5f3a\u7528\u6237\u9690\u79c1\u4fdd\u62a4\u7684\u540c\u65f6\uff0c\u4f9d\u7136\u80fd\u591f\u7b26\u5408\u4e0e\u52a0\u5bc6\u8d27\u5e01\u4ea4\u6613\u76f8\u5173\u7684\u6cd5\u5f8b\u6cd5\u89c4\u8981\u6c42\u3002"}}
{"id": "2601.16354", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.16354", "abs": "https://arxiv.org/abs/2601.16354", "authors": ["Khoa Nguyen", "Khiem Ton", "NhatHai Phan", "Issa Khalil", "Khang Tran", "Cristian Borcea", "Ruoming Jin", "Abdallah Khreishah", "My T. Thai"], "title": "NOIR: Privacy-Preserving Generation of Code with Open-Source LLMs", "comment": "To appear at Usenix Security Symposium 2026", "summary": "Although boosting software development performance, large language model (LLM)-powered code generation introduces intellectual property and data security risks rooted in the fact that a service provider (cloud) observes a client's prompts and generated code, which can be proprietary in commercial systems. To mitigate this problem, we propose NOIR, the first framework to protect the client's prompts and generated code from the cloud. NOIR uses an encoder and a decoder at the client to encode and send the prompts' embeddings to the cloud to get enriched embeddings from the LLM, which are then decoded to generate the code locally at the client. Since the cloud can use the embeddings to infer the prompt and the generated code, NOIR introduces a new mechanism to achieve indistinguishability, a local differential privacy protection at the token embedding level, in the vocabulary used in the prompts and code, and a data-independent and randomized tokenizer on the client side. These components effectively defend against reconstruction and frequency analysis attacks by an honest-but-curious cloud. Extensive analysis and results using open-source LLMs show that NOIR significantly outperforms existing baselines on benchmarks, including the Evalplus (MBPP and HumanEval, Pass@1 of 76.7 and 77.4), and BigCodeBench (Pass@1 of 38.7, only a 1.77% drop from the original LLM) under strong privacy against attacks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86NOIR\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u5728\u5ba2\u6237\u7aef\u4f7f\u7528\u52a0\u5bc6\u673a\u5236\u4fdd\u62a4\u5ba2\u6237\u7aef\u63d0\u793a\u548c\u751f\u6210\u4ee3\u7801\uff0c\u9632\u6b62\u4e91\u670d\u52a1\u63d0\u4f9b\u5546\u7684\u6f5c\u5728\u5a01\u80c1\u3002", "motivation": "\u4e3a\u4e86\u5e94\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u9a71\u52a8\u7684\u4ee3\u7801\u751f\u6210\u5e26\u6765\u7684\u77e5\u8bc6\u4ea7\u6743\u548c\u6570\u636e\u5b89\u5168\u98ce\u9669\uff0c\u7279\u522b\u662f\u4e91\u63d0\u4f9b\u5546\u80fd\u591f\u89c2\u6d4b\u5230\u5ba2\u6237\u7aef\u7684\u63d0\u793a\u548c\u751f\u6210\u4ee3\u7801\uff0c\u672c\u6587\u63d0\u51fa\u4e86NOIR\u6846\u67b6\uff0c\u65e8\u5728\u4fdd\u62a4\u8fd9\u4e9b\u654f\u611f\u4fe1\u606f\u3002", "method": "NOIR\u6846\u67b6\u5305\u542b\u5ba2\u6237\u7aef\u7684\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\uff0c\u7528\u4e8e\u5c06\u63d0\u793a\u7684\u5d4c\u5165\u4f20\u8f93\u7ed9\u4e91\u4ee5\u83b7\u5f97\u589e\u5f3a\u7684\u5d4c\u5165\uff0c\u518d\u901a\u8fc7\u672c\u5730\u89e3\u7801\u751f\u6210\u4ee3\u7801\u3002\u540c\u65f6\u5f15\u5165\u4e86\u4e00\u79cd\u57fa\u4e8e\u8bcd\u6c47\u8868\u7684\u672c\u5730\u5dee\u5206\u9690\u79c1\u4fdd\u62a4\u673a\u5236\u548c\u5ba2\u6237\u7aef\u7684\u968f\u673a\u5316\u5206\u8bcd\u5668\uff0c\u5728\u4e0d\u5f71\u54cd\u4ee3\u7801\u751f\u6210\u8d28\u91cf\u7684\u524d\u63d0\u4e0b\uff0c\u589e\u5f3a\u5bf9\u91cd\u5efa\u653b\u51fb\u548c\u9891\u7387\u5206\u6790\u653b\u51fb\u7684\u9632\u5fa1\u3002", "result": "\u4f7f\u7528\u5f00\u6e90LLM\u8fdb\u884c\u7684\u5e7f\u6cdb\u5206\u6790\u548c\u7ed3\u679c\u663e\u793a\uff0cNOIR\u6846\u67b6\u5728\u5f00\u6e90\u8bc4\u4ef7\u57fa\u51c6\u4e0a\u7684\u8868\u73b0\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u5c24\u5176\u662f\u5728Evalplus\uff08MBPP\u548cHumanEval\uff0c\u547d\u4e2d\u7387\u4e3a76.7\u548c77.4\uff09\u548cBigCodeBench\uff08\u547d\u4e2d\u7387\u4e3a38.7\uff0c\u4ec5\u6bd4\u539f\u59cbLLM\u4f4e1.77%\uff09\u7684\u6d4b\u8bd5\u4e2d\u3002", "conclusion": "NOIR\u6846\u67b6\u5728\u4e25\u683c\u7684\u9690\u79c1\u9632\u62a4\u6761\u4ef6\u4e0b\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u5c3d\u7ba1\u5728\u67d0\u4e9b\u7ec6\u8282\u4e0a\u7565\u6709\u4e0b\u964d\uff0c\u4f46\u5728\u6574\u4f53\u4e0a\u4ecd\u662f\u6700\u6709\u6548\u7684\u65b9\u6cd5\u4e4b\u4e00\uff0c\u5c55\u793a\u4e86\u4fdd\u62a4\u77e5\u8bc6\u4ea7\u6743\u548c\u6570\u636e\u5b89\u5168\u65b9\u9762\u7684\u5b9e\u9645\u6548\u679c\u3002"}}
{"id": "2601.16448", "categories": ["cs.CR", "cs.OS"], "pdf": "https://arxiv.org/pdf/2601.16448", "abs": "https://arxiv.org/abs/2601.16448", "authors": ["Richard Habeeb", "Man-Ki Yoon", "Hao Chen Zhong Shao"], "title": "Ringmaster: How to juggle high-throughput host OS system calls from TrustZone TEEs", "comment": null, "summary": "Many safety-critical systems require timely processing of sensor inputs to avoid potential safety hazards. Additionally, to support useful application features, such systems increasingly have a large rich operating system (OS) at the cost of potential security bugs. Thus, if a malicious party gains supervisor privileges, they could cause real-world damage by denying service to time-sensitive programs. Many past approaches to this problem completely isolate time-sensitive programs with a hypervisor; however, this prevents the programs from accessing useful OS services\n  We introduce Ringmaster, a novel framework that enables enclaves or TEEs (Trusted Execution Environments) to asynchronously access rich, but potentially untrusted, OS services via Linux's io_uring. When service is denied by the untrusted OS, enclaves continue to operate on Ringmaster's minimal ARM TrustZone kernel with access to small, critical device drivers. This approach balances the need for secure, time-sensitive processing with the convenience of rich OS services. Additionally, Ringmaster supports large unmodified programs as enclaves, offering lower overhead compared to existing systems. We demonstrate how Ringmaster helps us build a working highly-secure system with minimal engineering. In our experiments with an unmanned aerial vehicle, Ringmaster achieved nearly 1GiB/sec of data into enclave on a Raspberry Pi4b, 0-3% throughput overhead compared to non-enclave tasks.", "AI": {"tldr": "Ringmaster\u6846\u67b6\u901a\u8fc7\u7ed3\u5408Linux\u7684io_uring\u6280\u672f\u4e0eARM TrustZone\u6700\u5c0f\u5185\u6838\uff0c\u8ba9\u53ef\u4fe1\u6267\u884c\u73af\u5883(TEEs)\u80fd\u5f02\u6b65\u8bbf\u95ee\u53ef\u80fd\u4e0d\u5b8c\u5168\u53ef\u4fe1\u7684\u4e30\u5bcc\u64cd\u4f5c\u7cfb\u7edf\u670d\u52a1\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u5b89\u5168\u6027\u548c\u9ad8\u6548\u6027\u3002", "motivation": "\u8bb8\u591a\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u4f9d\u8d56\u53ca\u65f6\u5904\u7406\u4f20\u611f\u5668\u8f93\u5165\u4ee5\u907f\u514d\u6f5c\u5728\u7684\u5b89\u5168\u9690\u60a3\uff0c\u4f46\u4e0e\u6b64\u540c\u65f6\uff0c\u4e3a\u4e86\u652f\u6301\u6709\u7528\u7684\u7279\u6027\uff0c\u8fd9\u4e9b\u7cfb\u7edf\u8fd8\u9700\u8981\u5305\u542b\u5e9e\u5927\u7684\u64cd\u4f5c\u7cfb\u7edf\uff0c\u589e\u52a0\u4e86\u5b89\u5168\u6f0f\u6d1e\u7684\u98ce\u9669\u3002\u56e0\u6b64\uff0c\u6076\u610f\u7528\u6237\u4e00\u65e6\u83b7\u5f97\u4e86\u76d1\u7763\u6743\u9650\uff0c\u5c31\u80fd\u901a\u8fc7\u62d2\u7edd\u670d\u52a1\u5371\u53ca\u65f6\u95f4\u5173\u952e\u578b\u7a0b\u5e8f\u3002", "method": "Ringmaster\u6846\u67b6\u5177\u4f53\u91c7\u7528Linux\u7684io_uring\u6280\u672f\uff0c\u4f7fTEEs\u80fd\u591f\u5f02\u6b65\u8bbf\u95ee\u53d7\u9650\u64cd\u4f5c\u7cfb\u7edf\u7684\u4e30\u5bcc\u670d\u52a1\u3002\u5f53\u64cd\u4f5c\u7cfb\u7edf\u7684\u670d\u52a1\u88ab\u62d2\u7edd\u65f6\uff0cTEEs\u53ef\u4ee5\u4ece\u53d7\u9650\u64cd\u4f5c\u7cfb\u7edf\u7684\u8d44\u6e90\u5207\u6362\u5230ARM TrustZone\u5e73\u53f0\u4e0a\u8fd0\u884c\u7684\u7cbe\u7b80\u5185\u6838\uff0c\u4fdd\u8bc1\u5173\u952e\u9a71\u52a8\u7a0b\u5e8f\u7684\u53ef\u7528\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5728\u642d\u8f7dRaspberry Pi 4b\u7684\u65e0\u4eba\u9a7e\u9a76\u822a\u7a7a\u5668\u4e0a\uff0cRingmaster\u5b9e\u73b0\u4e86\u8fd1\u4e4e1GiB/s\u7684\u6570\u636e\u6d41\u901f\u8fdb\u5165TEEs\u4e2d\uff0c\u4e14\u5bf9\u4e8e\u975eTEEs\u4efb\u52a1\u76f8\u6bd4\uff0c\u541e\u5410\u91cf\u6027\u80fd\u4ec5\u67090-3%\u7684\u5fae\u5c0f\u63d0\u5347\u3002", "conclusion": "Ringmaster\u6846\u67b6\u6210\u529f\u5730\u5b9e\u73b0\u4e86\u4e00\u4e2a\u9ad8\u6548\u3001\u5b89\u5168\u7684\u7cfb\u7edf\uff0c\u663e\u793a\u51fa\u4e86\u5176\u5e73\u8861\u5b89\u5168\u4e0e\u6548\u7387\u7684\u4f18\u52bf\uff0c\u5e76\u4e3a\u8fdb\u4e00\u6b65\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2601.16286", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.16286", "abs": "https://arxiv.org/abs/2601.16286", "authors": ["Varun Chillara", "Dylan Kline", "Christopher Alvares", "Evan Wooten", "Huan Yang", "Shlok Khetan", "Cade Bauer", "Tr\u00e9 Guillory", "Tanishka Shah", "Yashodhara Dhariwal", "Volodymyr Pavlov", "George Popstefanov"], "title": "SemanticALLI: Caching Reasoning, Not Just Responses, in Agentic Systems", "comment": null, "summary": "Agentic AI pipelines suffer from a hidden inefficiency: they frequently reconstruct identical intermediate logic, such as metric normalization or chart scaffolding, even when the user's natural language phrasing is entirely novel. Conventional boundary caching fails to capture this inefficiency because it treats inference as a monolithic black box.\n  We introduce SemanticALLI, a pipeline-aware architecture within Alli (PMG's marketing intelligence platform), designed to operationalize redundant reasoning. By decomposing generation into Analytic Intent Resolution (AIR) and Visualization Synthesis (VS), SemanticALLI elevates structured intermediate representations (IRs) to first-class, cacheable artifacts.\n  The impact of caching within the agentic loop is substantial. In our evaluation, baseline monolithic caching caps at a 38.7% hit rate due to linguistic variance. In contrast, our structured approach allows for an additional stage, the Visualization Synthesis stage, to achieve an 83.10% hit rate, bypassing 4,023 LLM calls with a median latency of just 2.66 ms. This internal reuse reduces total token consumption, offering a practical lesson for AI system design: even when users rarely repeat themselves, the pipeline often does, at stable, structured checkpoints where caching is most reliable.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSemanticALLI\u7684\u65b0\u67b6\u6784\uff0c\u901a\u8fc7\u5c06\u751f\u6210\u8fc7\u7a0b\u5206\u89e3\u4e3aAnalytic Intent Resolution\u548cVisualization Synthesis\uff0c\u5b9e\u73b0\u5728AI\u7ba1\u9053\u4e2d\u7684\u5197\u4f59\u63a8\u7406\u7684\u7f13\u5b58\u64cd\u4f5c\uff0c\u663e\u8457\u964d\u4f4e\u4e86LLM\u7684\u8c03\u7528\u6b21\u6570\u548c\u5ef6\u8fdf\uff0c\u63d0\u4f9b\u4e86AI\u7cfb\u7edf\u8bbe\u8ba1\u7684\u4e00\u4e2a\u5b9e\u9645\u6848\u4f8b\u3002", "motivation": "\u73b0\u6709AI\u7ba1\u9053\u5728\u5904\u7406\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u65f6\uff0c\u9891\u7e41\u5730\u91cd\u65b0\u751f\u6210\u76f8\u540c\u7684\u4e2d\u95f4\u903b\u8f91\uff0c\u5bfc\u81f4\u8d44\u6e90\u6d6a\u8d39\u3002\u4f20\u7edf\u8fb9\u754c\u7f13\u5b58\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u5f15\u5165SemanticALLI\u67b6\u6784\uff0c\u5c06\u751f\u6210\u8fc7\u7a0b\u6309\u5206\u89e3\u4e3a\u4e24\u6b21\u9636\u6bb5\u5904\u7406\uff1aAnalytic Intent Resolution\u548cVisualization Synthesis\uff0c\u5e76\u901a\u8fc7\u4f18\u5316\u7f13\u5b58\u7b56\u7565\u63d0\u5347\u4e86\u4e2d\u95f4\u8868\u793a\u7684\u590d\u7528\u6027\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5c55\u793a\u4e86\u663e\u8457\u7684\u6548\u679c\uff0c\u76f8\u6bd4\u4f20\u7edf\u7684\u5355\u9636\u6bb5\u7f13\u5b58\u65b9\u6cd5\uff0c\u591a\u9636\u6bb5\u7f13\u5b58\u53ef\u4ee5\u8fbe\u523083.10%\u7684\u547d\u4e2d\u7387\uff0c\u51cf\u5c11\u4e864023\u6b21LLM\u8c03\u7528\uff0c\u6bcf\u8c03\u7528\u7684\u5e73\u5747\u5ef6\u8fdf\u4ec5\u4e3a2.66ms\u3002", "conclusion": "\u8be5\u7814\u7a76\u8868\u660e\uff0c\u5728\u7279\u5b9a\u7684\u7ed3\u6784\u5316\u68c0\u67e5\u70b9\u5904\u5b9e\u73b0\u7f13\u5b58\u80fd\u591f\u6709\u6548\u5730\u63d0\u5347AI\u7ba1\u9053\u7684\u6548\u7387\u3002"}}
{"id": "2601.16463", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.16463", "abs": "https://arxiv.org/abs/2601.16463", "authors": ["Wenbo Guo", "Chengwei Liu", "Ming Kang", "Yiran Zhang", "Jiahui Wu", "Zhengzi Xu", "Vinay Sachidananda", "Yang Liu"], "title": "Cutting the Gordian Knot: Detecting Malicious PyPI Packages via a Knowledge-Mining Framework", "comment": null, "summary": "The Python Package Index (PyPI) has become a target for malicious actors, yet existing detection tools generate false positive rates of 15-30%, incorrectly flagging one-third of legitimate packages as malicious. This problem arises because current tools rely on simple syntactic rules rather than semantic understanding, failing to distinguish between identical API calls serving legitimate versus malicious purposes. To address this challenge, we propose PyGuard, a knowledge-driven framework that converts detection failures into useful behavioral knowledge by extracting patterns from existing tools' false positives and negatives. Our method utilizes hierarchical pattern mining to identify behavioral sequences that distinguish malicious from benign code, employs Large Language Models to create semantic abstractions beyond syntactic variations, and combines this knowledge into a detection system that integrates exact pattern matching with contextual reasoning. PyGuard achieves 99.50% accuracy with only 2 false positives versus 1,927-2,117 in existing tools, maintains 98.28% accuracy on obfuscated code, and identified 219 previously unknown malicious packages in real-world deployment. The behavioral patterns show cross-ecosystem applicability with 98.07% accuracy on NPM packages, demonstrating that semantic understanding enables knowledge transfer across programming languages.", "AI": {"tldr": "PyGuard\u662f\u4e00\u6b3e\u77e5\u8bc6\u9a71\u52a8\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u8f6c\u6362\u73b0\u6709\u68c0\u6d4b\u5de5\u5177\u7684\u8bef\u62a5\u548c\u6f0f\u62a5\u4e3a\u6709\u7528\u7684\u884c\u4e3a\u77e5\u8bc6\uff0c\u7ed3\u5408\u5c42\u6b21\u6a21\u5f0f\u6316\u6398\u3001\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u548c\u4e0a\u4e0b\u6587\u63a8\u7406\uff0c\u5b9e\u73b0\u4e86\u5bf9Python\u5305\u4e2d\u6076\u610f\u884c\u4e3a\u7684\u9ad8\u51c6\u786e\u68c0\u6d4b\u3002", "motivation": "\u73b0\u6709\u68c0\u6d4b\u5de5\u5177\u7531\u4e8e\u4f9d\u8d56\u7b80\u5355\u7684\u8bed\u6cd5\u89c4\u5219\u800c\u8bef\u62a5\u7387\u9ad8\uff0c\u65e0\u6cd5\u533a\u5206\u5408\u6cd5\u4e0e\u6076\u610f\u7684API\u8c03\u7528\u3002PyGuard\u65e8\u5728\u63d0\u4f9b\u4e00\u79cd\u77e5\u8bc6\u9a71\u52a8\u7684\u65b9\u6cd5\uff0c\u4ee5\u63d0\u9ad8\u6076\u610f\u5305\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "method": "PyGuard\u5229\u7528\u5c42\u6b21\u6a21\u5f0f\u6316\u6398\u63d0\u53d6\u5dee\u5f02\u884c\u4e3a\u5e8f\u5217\uff0c\u4f7f\u7528\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u751f\u6210\u8bed\u4e49\u62bd\u8c61\uff0c\u5e76\u7ed3\u5408\u7cbe\u786e\u6a21\u5f0f\u5339\u914d\u548c\u4e0a\u4e0b\u6587\u63a8\u7406\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u9ad8\u6548\u51c6\u786e\u7684\u68c0\u6d4b\u7cfb\u7edf\u3002", "result": "PyGuard\u5728\u771f\u5b9e\u90e8\u7f72\u4e2d\u51c6\u786e\u7387\u9ad8\u8fbe99.50%\uff0c\u8bef\u62a5\u4e3a2\uff0c\u800c\u5728\u73b0\u6709\u5de5\u5177\u4e2d\u8bef\u62a5\u5219\u9ad8\u8fbe1,927-2,117\u3002\u5b83\u8fd8\u80fd\u5728\u6df7\u6dc6\u4ee3\u7801\u4e2d\u4fdd\u630198.28%\u7684\u51c6\u786e\u7387\uff0c\u5e76\u53d1\u73b0219\u4e2a\u672a\u77e5\u6076\u610f\u5305\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u663e\u793a\u51fa\u8de8\u751f\u6001\u7cfb\u7edf\u7684\u9002\u7528\u6027\uff0cNPM\u5305\u4e0a\u7684\u51c6\u786e\u7387\u4e3a98.07%\u3002", "conclusion": "PyGuard\u901a\u8fc7\u77e5\u8bc6\u63d0\u53d6\u548c\u6a21\u5f0f\u8bc6\u522b\u63d0\u9ad8\u4e86Python\u5305\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u5bf9\u9632\u8303\u901a\u8fc7\u5305\u4f20\u64ad\u7684\u6076\u610f\u884c\u4e3a\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2601.16473", "categories": ["cs.CR", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.16473", "abs": "https://arxiv.org/abs/2601.16473", "authors": ["Wei Song", "Zhenchang Xing", "Liming Zhu", "Yulei Sui", "Jingling Xue"], "title": "DeMark: A Query-Free Black-Box Attack on Deepfake Watermarking Defenses", "comment": null, "summary": "The rapid proliferation of realistic deepfakes has raised urgent concerns over their misuse, motivating the use of defensive watermarks in synthetic images for reliable detection and provenance tracking. However, this defense paradigm assumes such watermarks are inherently resistant to removal. We challenge this assumption with DeMark, a query-free black-box attack framework that targets defensive image watermarking schemes for deepfakes. DeMark exploits latent-space vulnerabilities in encoder-decoder watermarking models through a compressive sensing based sparsification process, suppressing watermark signals while preserving perceptual and structural realism appropriate for deepfakes. Across eight state-of-the-art watermarking schemes, DeMark reduces watermark detection accuracy from 100% to 32.9% on average while maintaining natural visual quality, outperforming existing attacks. We further evaluate three defense strategies, including image super resolution, sparse watermarking, and adversarial training, and find them largely ineffective. These results demonstrate that current encoder decoder watermarking schemes remain vulnerable to latent-space manipulations, underscoring the need for more robust watermarking methods to safeguard against deepfakes.", "AI": {"tldr": "\u7814\u7a76\u4eba\u5458\u63d0\u51fa\u4e86DeMark\uff0c\u4e00\u79cd\u65e0\u9700\u67e5\u8be2\u7684\u9ed1\u76d2\u653b\u51fb\u6846\u67b6\uff0c\u65e8\u5728\u6311\u6218\u56fe\u50cf\u6c34\u5370\u65b9\u6848\u5bf9\u6df1\u5ea6\u4f2a\u9020\u7684\u62b5\u6297\u529b\u3002DeMark\u5229\u7528\u7f16\u7801\u5668-\u89e3\u7801\u5668\u6c34\u5370\u6a21\u578b\u4e2d\u7684\u6f5c\u5728\u7a7a\u95f4\u6f0f\u6d1e\uff0c\u901a\u8fc7\u538b\u7f29\u611f\u77e5\u8fc7\u7a0b\u7a00\u758f\u5316\u6c34\u5370\u4fe1\u53f7\uff0c\u4ece\u800c\u964d\u4f4e\u6c34\u5370\u68c0\u6d4b\u51c6\u786e\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u81ea\u7136\u7684\u89c6\u89c9\u8d28\u91cf\u3002\u8fd9\u9879\u7814\u7a76\u63ed\u793a\u4e86\u5f53\u524d\u7684\u6c34\u5370\u65b9\u6848\u5728\u9762\u4e34\u6f5c\u5728\u7a7a\u95f4\u64cd\u7eb5\u65f6\u7684\u8106\u5f31\u6027\uff0c\u63d0\u51fa\u4e86\u5bf9\u66f4\u7a33\u5065\u7684\u6c34\u5370\u65b9\u6cd5\u7684\u9700\u6c42\u3002", "motivation": "\u968f\u7740\u6df1\u5ea6\u4f2a\u9020\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u9632\u5fa1\u6846\u67b6\u4f9d\u8d56\u7684\u6c34\u5370\u65b9\u6848\u7684\u5b89\u5168\u6027\u6210\u4e3a\u4e9f\u5f85\u89e3\u51b3\u7684\u95ee\u9898\u3002\u9274\u4e8e\u73b0\u6709\u7814\u7a76\u666e\u904d\u5047\u8bbe\u6c34\u5370\u65b9\u6848\u662f\u65e0\u635f\u7684\uff0cDeMark\u65e8\u5728\u9a8c\u8bc1\u8fd9\u4e00\u5047\u8bbe\uff0c\u5f3a\u8c03\u4e86\u5f00\u53d1\u66f4\u7a33\u5065\u6c34\u5370\u65b9\u6848\u7684\u91cd\u8981\u6027\u3002", "method": "DeMark\u91c7\u7528\u4e86\u4e00\u79cd\u9488\u5bf9\u56fe\u50cf\u6c34\u5370\u65b9\u6848\u7684\u67e5\u8be2\u514d\u8d39\u9ed1\u76d2\u653b\u51fb\u65b9\u6cd5\u3002\u5b83\u5229\u7528\u7f16\u7801\u5668-\u89e3\u7801\u5668\u6c34\u5370\u6a21\u578b\u4e2d\u7684\u6f5c\u5728\u7a7a\u95f4\u6f0f\u6d1e\uff0c\u5e94\u7528\u538b\u7f29\u611f\u77e5\u7b97\u6cd5\u5bf9\u6c34\u5370\u8fdb\u884c\u7a00\u758f\u5316\u5904\u7406\uff0c\u4ece\u800c\u5728\u4fdd\u6301\u771f\u5b9e\u6027\u548c\u81ea\u7136\u89c6\u89c9\u8d28\u91cf\u7684\u540c\u65f6\uff0c\u524a\u5f31\u4e86\u6c34\u5370\u7684\u68c0\u6d4b\u6548\u679c\u3002", "result": "\u9488\u5bf98\u79cd\u6700\u5148\u8fdb\u7684\u6c34\u5370\u65b9\u6848\uff0cDeMark\u5c06\u6c34\u5370\u68c0\u6d4b\u6210\u529f\u7387\u4ece100%\u964d\u4f4e\u5230\u4e8632.9%\uff0c\u540c\u65f6\u7ef4\u62a4\u4e86\u56fe\u50cf\u7684\u81ea\u7136\u89c6\u89c9\u8d28\u91cf\u3002\u6b64\u5916\uff0c\u8bc4\u4f30\u8868\u660e\u56fe\u50cf\u8d85\u5206\u8fa8\u7387\u3001\u7a00\u758f\u6c34\u5370\u548c\u5bf9\u6297\u8bad\u7ec3\u7b49\u4e09\u9879\u9884\u9632\u7b56\u7565\u5728\u63d0\u9ad8\u6c34\u5370\u7a33\u5065\u6027\u65b9\u9762\u57fa\u672c\u65e0\u6548\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u8868\u660e\uff0c\u5f53\u524d\u7684\u7f16\u7801\u5668-\u89e3\u7801\u5668\u6c34\u5370\u65b9\u6848\u5bf9\u4e8e\u6f5c\u5728\u7a7a\u95f4\u64cd\u4f5c\u4ecd\u7136\u5b58\u5728\u8106\u5f31\u6027\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u52a0\u7a33\u5065\u7684\u6c34\u5370\u65b9\u6cd5\u6765\u63d0\u5347\u68c0\u6d4b\u6df1\u5ea6\u4f2a\u9020\u7684\u80fd\u529b\u3002"}}
{"id": "2601.16529", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.16529", "abs": "https://arxiv.org/abs/2601.16529", "authors": ["Dongshen Peng", "Yi Wang", "Carl Preiksaitis", "Christian Rose"], "title": "SycoEval-EM: Sycophancy Evaluation of Large Language Models in Simulated Clinical Encounters for Emergency Care", "comment": "11 pages, 5 figures", "summary": "Large language models (LLMs) show promise in clinical decision support yet risk acquiescing to patient pressure for inappropriate care. We introduce SycoEval-EM, a multi-agent simulation framework evaluating LLM robustness through adversarial patient persuasion in emergency medicine. Across 20 LLMs and 1,875 encounters spanning three Choosing Wisely scenarios, acquiescence rates ranged from 0-100\\%. Models showed higher vulnerability to imaging requests (38.8\\%) than opioid prescriptions (25.0\\%), with model capability poorly predicting robustness. All persuasion tactics proved equally effective (30.0-36.0\\%), indicating general susceptibility rather than tactic-specific weakness. Our findings demonstrate that static benchmarks inadequately predict safety under social pressure, necessitating multi-turn adversarial testing for clinical AI certification.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.16500", "categories": ["cs.CR", "cs.AR"], "pdf": "https://arxiv.org/pdf/2601.16500", "abs": "https://arxiv.org/abs/2601.16500", "authors": ["Kai Li", "Jiahao Lu", "Fu Yao", "Guang Zeng", "Dongsheng Liu", "Shengfei Gu", "Zhengpeng Zhao", "Jiachen Wang"], "title": "A High Performance and Efficient Post-Quantum Crypto-Processor for FrodoKEM", "comment": "13 pages, 11 figures", "summary": "FrodoKEM is a lattice-based post-quantum key encapsulation mechanism (KEM). It has been considered for standardization by the International Organization for Standardization (ISO) due to its robust security profile. However, its hardware implementation exhibits a weakness of high latency and heavy resource burden, hindering its practical application. Moreover, diverse usage scenarios call for comprehensive functionality. To address these challenges, this paper presents a high-performance and efficient crypto-processor for FrodoKEM. A multiple-instruction overlapped execution scheme is introduced to enable efficient multi-module scheduling and minimize operational latency. Furthermore, a high-speed, reconfigurable parallel multiplier array is integrated to handle intensive matrix computations under diverse computation patterns, significantly enhancing hardware efficiency. In addition, a compact memory scheduling strategy shortens the lifespan of intermediate matrices, thereby reducing overall storage requirements. The proposed design provides full support for all FrodoKEM security levels and protocol phases. It consumes 13467 LUTs, 6042 FFs, and 14 BRAMs on an Artix-7 FPGA and achieves the fastest reported execution time. Compared with state-of-the-art hardware implementations, our design improves the area-time product (ATP) by 1.75-2.00 times.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.16549", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.16549", "abs": "https://arxiv.org/abs/2601.16549", "authors": ["Meet Raval", "Tejul Pandit", "Dhvani Upadhyay"], "title": "LLM is Not All You Need: A Systematic Evaluation of ML vs. Foundation Models for text and image based Medical Classification", "comment": "9 pages, 5 figures, 3 tables, paper accepted in AAIML'26 conference", "summary": "The combination of multimodal Vision-Language Models (VLMs) and Large Language Models (LLMs) opens up new possibilities for medical classification. This work offers a rigorous, unified benchmark by using four publicly available datasets covering text and image modalities (binary and multiclass complexity) that contrasts traditional Machine Learning (ML) with contemporary transformer-based techniques. We evaluated three model classes for each task: Classical ML (LR, LightGBM, ResNet-50), Prompt-Based LLMs/VLMs (Gemini 2.5), and Fine-Tuned PEFT Models (LoRA-adapted Gemma3 variants). All experiments used consistent data splits and aligned metrics. According to our results, traditional machine learning (ML) models set a high standard by consistently achieving the best overall performance across most medical categorization tasks. This was especially true for structured text-based datasets, where the classical models performed exceptionally well. In stark contrast, the LoRA-tuned Gemma variants consistently showed the worst performance across all text and image experiments, failing to generalize from the minimal fine-tuning provided. However, the zero-shot LLM/VLM pipelines (Gemini 2.5) had mixed results; they performed poorly on text-based tasks, but demonstrated competitive performance on the multiclass image task, matching the classical ResNet-50 baseline. These results demonstrate that in many medical categorization scenarios, established machine learning models continue to be the most reliable option. The experiment suggests that foundation models are not universally superior and that the effectiveness of Parameter-Efficient Fine-Tuning (PEFT) is highly dependent on the adaptation strategy, as minimal fine-tuning proved detrimental in this study.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.16506", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.16506", "abs": "https://arxiv.org/abs/2601.16506", "authors": ["Xianya Fang", "Xianying Luo", "Yadong Wang", "Xiang Chen", "Yu Tian", "Zequn Sun", "Rui Liu", "Jun Fang", "Naiqiang Tan", "Yuanning Cui", "Sheng-Jun Huang"], "title": "SafeThinker: Reasoning about Risk to Deepen Safety Beyond Shallow Alignment", "comment": null, "summary": "Despite the intrinsic risk-awareness of Large Language Models (LLMs), current defenses often result in shallow safety alignment, rendering models vulnerable to disguised attacks (e.g., prefilling) while degrading utility. To bridge this gap, we propose SafeThinker, an adaptive framework that dynamically allocates defensive resources via a lightweight gateway classifier. Based on the gateway's risk assessment, inputs are routed through three distinct mechanisms: (i) a Standardized Refusal Mechanism for explicit threats to maximize efficiency; (ii) a Safety-Aware Twin Expert (SATE) module to intercept deceptive attacks masquerading as benign queries; and (iii) a Distribution-Guided Think (DDGT) component that adaptively intervenes during uncertain generation. Experiments show that SafeThinker significantly lowers attack success rates across diverse jailbreak strategies without compromising utility, demonstrating that coordinating intrinsic judgment throughout the generation process effectively balances robustness and practicality.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.16649", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.16649", "abs": "https://arxiv.org/abs/2601.16649", "authors": ["Amin Rakhsha", "Thomas Hehn", "Pietro Mazzaglia", "Fabio Valerio Massoli", "Arash Behboodi", "Tribhuvanesh Orekondy"], "title": "LUMINA: Long-horizon Understanding for Multi-turn Interactive Agents", "comment": null, "summary": "Large language models can perform well on many isolated tasks, yet they continue to struggle on multi-turn, long-horizon agentic problems that require skills such as planning, state tracking, and long context processing. In this work, we aim to better understand the relative importance of advancing these underlying capabilities for success on such tasks. We develop an oracle counterfactual framework for multi-turn problems that asks: how would an agent perform if it could leverage an oracle to perfectly perform a specific task? The change in the agent's performance due to this oracle assistance allows us to measure the criticality of such oracle skill in the future advancement of AI agents. We introduce a suite of procedurally generated, game-like tasks with tunable complexity. These controlled environments allow us to provide precise oracle interventions, such as perfect planning or flawless state tracking, and make it possible to isolate the contribution of each oracle without confounding effects present in real-world benchmarks. Our results show that while some interventions (e.g., planning) consistently improve performance across settings, the usefulness of other skills is dependent on the properties of the environment and language model. Our work sheds light on the challenges of multi-turn agentic environments to guide the future efforts in the development of AI agents and language models.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.16560", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.16560", "abs": "https://arxiv.org/abs/2601.16560", "authors": ["Ruisheng Shi", "Yuxuan Liang", "Zijun Guo", "Qin Wang", "Lina Lan", "Chenfeng Wang", "Zhuoyi Zheng"], "title": "Eclipse Attacks on Ethereum's Peer-to-Peer Network", "comment": "Accepted by WWW'26", "summary": "Eclipse attacks isolate blockchain nodes by monopolizing their peer-to-peer connections. The attacks were extensively studied in Bitcoin (SP'15, SP'20, CCS'21, SP'23) and Monero (NDSS'25), but their practicality against Ethereum nodes remains underexplored, particularly in the post-Merge settings.\n  We present the first end-to-end implementation of an eclipse attack targeting Ethereum (2.0 version) execution-layer nodes. Our attack exploits the bootstrapping and peer management logic of Ethereum to fully isolate a node upon restart. We introduce a multi-stage strategy that majorly includes (i) poisoning the node's discovery table via unsolicited messages, (ii) infiltrating Ethereum's DNS-based peerlist by identifying and manipulating the official DNS crawler, and (iii) hijacking idle incoming connection slots across the network to block benign connections. Our DNS list poisoning is the first in the cryptocurrency context and requires only 28 IP addresses over 100 days. Slots hijacking raises outgoing redirection success from 45\\% to 95\\%. We validate our approach through controlled experiments on Ethereum's Sepolia testnet and broad measurements on the mainnet. Our findings demonstrate that over 80\\% of public nodes do not leave sufficient idle capacity for effective slots occupation, highlighting the feasibility and severity of the threat. We further propose concrete countermeasures and responsibly disclosed all findings to Ethereum's security team.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.16685", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.16685", "abs": "https://arxiv.org/abs/2601.16685", "authors": ["Suzhong Fu", "Jingqi Dong", "Xuan Ding", "Rui Sun", "Yiming Yang", "Shuguang Cui", "Zhen Li"], "title": "AgentsEval: Clinically Faithful Evaluation of Medical Imaging Reports via Multi-Agent Reasoning", "comment": null, "summary": "Evaluating the clinical correctness and reasoning fidelity of automatically generated medical imaging reports remains a critical yet unresolved challenge. Existing evaluation methods often fail to capture the structured diagnostic logic that underlies radiological interpretation, resulting in unreliable judgments and limited clinical relevance. We introduce AgentsEval, a multi-agent stream reasoning framework that emulates the collaborative diagnostic workflow of radiologists. By dividing the evaluation process into interpretable steps including criteria definition, evidence extraction, alignment, and consistency scoring, AgentsEval provides explicit reasoning traces and structured clinical feedback. We also construct a multi-domain perturbation-based benchmark covering five medical report datasets with diverse imaging modalities and controlled semantic variations. Experimental results demonstrate that AgentsEval delivers clinically aligned, semantically faithful, and interpretable evaluations that remain robust under paraphrastic, semantic, and stylistic perturbations. This framework represents a step toward transparent and clinically grounded assessment of medical report generation systems, fostering trustworthy integration of large language models into clinical practice.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.16589", "categories": ["cs.CR", "cs.AI", "cs.ET"], "pdf": "https://arxiv.org/pdf/2601.16589", "abs": "https://arxiv.org/abs/2601.16589", "authors": ["Pablo Sorrentino", "Stjepan Picek", "Ihsen Alouani", "Nikolaos Athanasios Anagnostopoulos", "Francesco Regazzoni", "Lejla Batina", "Tamalika Banerjee", "Fatih Turkmen"], "title": "Emerging Threats and Countermeasures in Neuromorphic Systems: A Survey", "comment": "Survey paper on security and privacy in neuromorphic and in-memory computing systems (35 pages, 11 figures, 6 tables)", "summary": "Neuromorphic computing mimics brain-inspired mechanisms through spiking neurons and energy-efficient processing, offering a pathway to efficient in-memory computing (IMC). However, these advancements raise critical security and privacy concerns. As the adoption of bio-inspired architectures and memristive devices increases, so does the urgency to assess the vulnerability of these emerging technologies to hardware and software attacks. Emerging architectures introduce new attack surfaces, particularly due to asynchronous, event-driven processing and stochastic device behavior. The integration of memristors into neuromorphic hardware and software implementations in spiking neural networks offers diverse possibilities for advanced computing architectures, including their role in security-aware applications. This survey systematically analyzes the security landscape of neuromorphic systems, covering attack methodologies, side-channel vulnerabilities, and countermeasures. We focus on both hardware and software concerns relevant to spiking neural networks (SNNs) and hardware primitives, such as Physical Unclonable Functions (PUFs) and True Random Number Generators (TRNGs) for cryptographic and secure computation applications. We approach this analysis from diverse perspectives, from attack methodologies to countermeasure strategies that integrate efficiency and protection in brain-inspired hardware. This review not only maps the current landscape of security threats but provides a foundation for developing secure and trustworthy neuromorphic architectures.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.16725", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.16725", "abs": "https://arxiv.org/abs/2601.16725", "authors": ["Meituan LongCat Team", "Anchun Gui", "Bei Li", "Bingyang Tao", "Bole Zhou", "Borun Chen", "Chao Zhang", "Chao Zhang", "Chen Gao", "Chen Zhang", "Chengcheng Han", "Chenhui Yang", "Chuyu Zhang", "Cong Chen", "Cunguang Wang", "Daoru Pan", "Defei Bu", "Dengchang Zhao", "Di Xiu", "Dishan Liu", "Dongyu Ru", "Dunwei Tu", "Fan Wu", "Fengcheng Yuan", "Fengcun Li", "Gang Xu", "Guanyu Wu", "Guoyuan Lin", "Haibin Wang", "Hansi Yang", "Hao Yang", "Haonan Yan", "Haoxiang Ma", "Haoxing Wen", "Hongyan Hao", "Hongyin Tang", "Hongyu Zang", "Hongzhi Ni", "Hui Su", "Jiacheng Zhang", "Jiahong Zhou", "Jiahuan Li", "Jiaming Wang", "Jian Yang", "Jianfei Zhang", "Jianhao Xu", "Jianing Wang", "Jiapeng Zhu", "Jiaqi Sun", "Jiarong Shi", "Jiarui Zhao", "Jingang Wang", "Jinluan Yang", "Jinrui Ding", "Jinwei Xiao", "Jiyuan He", "Juncan Xu", "Kefeng Zhang", "Keheng Wang", "Li Wei", "Lianhui Ma", "Lin Qiu", "Lingbing Kong", "Lingchuan Liu", "Linsen Guo", "Mengshen Zhu", "Mengxia Shen", "Mingyang Zhu", "Peiguang Li", "Peng Pei", "Pengcheng Jia", "Pengtao Zhang", "Peng Zhao", "Qi Gu", "Qiong Huang", "Qiyuan Duan", "Quanchi Weng", "Rongxiang Weng", "Rongzhi Zhang", "Rumei Li", "Shanglin Lei", "Shengnan An", "Shijun Dai", "Shuaikang Liu", "Shuang Zhou", "Shuo Wang", "Songyuan Zhao", "Tao Liang", "Tianhao Hu", "Tianze Chen", "Wei Liu", "Wei Shi", "Wei Wang", "Weifeng Tang", "Wenjie Shi", "Wenlong Zhu", "Wentao Chen", "Wentao Shi", "Xi Su", "Xiangcheng Liu", "Xiandi Ma", "Xiangyu Xi", "Xiangyuan Liu", "Xiangzhou Huang", "Xiao Liu", "Xiaodong Cai", "Xiaolong Chen", "Xiaowei Shi", "Xiaoyu Li", "Xin Chen", "Xingchen Liu", "Xuan Huang", "Xuezhi Cao", "Xunliang Cai", "Yan Chen", "Yang Bai", "Yang Liu", "Yang Yang", "Yang Zheng", "Yaoming Wang", "Yaoming Zhu", "Yaqi Huo", "Yanyu Chen", "Yaorui Shi", "Yerui Sun", "Yi Zhang", "Yihao Chen", "Yi-Kai Zhang", "Yifan Lu", "Yifan Zhao", "Yitao Zhai", "Yongjing Yin", "Yongwei Zhou", "Youshao Xiao", "Yuchuan Dai", "Yuchen Xie", "Yuchen Yu", "Yufei Zhang", "Yuhuai Wei", "Yulei Qian", "Yunfan Liang", "Yunke Zhao", "Yuwei Jiang", "Yuxin Bian", "Yuxin Chen", "Yuxin Liu", "Yue Xu", "Yueqing Sun", "Zeyang Yu", "Zhao Yang", "Zhengsheng Huang", "Zhengyu Chen", "Zhijian Liu", "Zhikang Xia", "Zhimin Lin", "Zhiyuan Yao", "Zhuofan Chen", "Zhuowen Han", "Zijian Zhang", "Ziran Li", "Ziwen Wang", "Ziyuan Zhuang"], "title": "LongCat-Flash-Thinking-2601 Technical Report", "comment": null, "summary": "We introduce LongCat-Flash-Thinking-2601, a 560-billion-parameter open-source Mixture-of-Experts (MoE) reasoning model with superior agentic reasoning capability. LongCat-Flash-Thinking-2601 achieves state-of-the-art performance among open-source models on a wide range of agentic benchmarks, including agentic search, agentic tool use, and tool-integrated reasoning. Beyond benchmark performance, the model demonstrates strong generalization to complex tool interactions and robust behavior under noisy real-world environments. Its advanced capability stems from a unified training framework that combines domain-parallel expert training with subsequent fusion, together with an end-to-end co-design of data construction, environments, algorithms, and infrastructure spanning from pre-training to post-training. In particular, the model's strong generalization capability in complex tool-use are driven by our in-depth exploration of environment scaling and principled task construction. To optimize long-tailed, skewed generation and multi-turn agentic interactions, and to enable stable training across over 10,000 environments spanning more than 20 domains, we systematically extend our asynchronous reinforcement learning framework, DORA, for stable and efficient large-scale multi-environment training. Furthermore, recognizing that real-world tasks are inherently noisy, we conduct a systematic analysis and decomposition of real-world noise patterns, and design targeted training procedures to explicitly incorporate such imperfections into the training process, resulting in improved robustness for real-world applications. To further enhance performance on complex reasoning tasks, we introduce a Heavy Thinking mode that enables effective test-time scaling by jointly expanding reasoning depth and width through intensive parallel thinking.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.16681", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.16681", "abs": "https://arxiv.org/abs/2601.16681", "authors": ["Xing Su", "Hao Wu", "Hanzhong Liang", "Yunlin Jiang", "Yuxi Cheng", "Yating Liu", "Fengyuan Xu"], "title": "From Transactions to Exploits: Automated PoC Synthesis for Real-World DeFi Attacks", "comment": "14 pages, 10 figures", "summary": "Blockchain systems are increasingly targeted by on-chain attacks that exploit contract vulnerabilities to extract value rapidly and stealthily, making systematic analysis and reproduction highly challenging. In practice, reproducing such attacks requires manually crafting proofs-of-concept (PoCs), a labor-intensive process that demands substantial expertise and scales poorly. In this work, we present the first automated framework for synthesizing verifiable PoCs directly from on-chain attack executions. Our key insight is that attacker logic can be recovered from low-level transaction traces via trace-driven reverse engineering, and then translated into executable exploits by leveraging the code-generation capabilities of large language models (LLMs). To this end, we propose TracExp, which localizes attack-relevant execution contexts from noisy, multi-contract traces and introduces a novel dual-decompiler to transform concrete executions into semantically enriched exploit pseudocode. Guided by this representation, TracExp synthesizes PoCs and refines them to preserve exploitability-relevant semantics. We evaluate TracExp on 321 real-world attacks over the past 20 months. TracExp successfully synthesizes PoCs for 93% of incidents, with 58.78% being directly verifiable, at an average cost of only \\$0.07 per case. Moreover, TracExp enabled the release of a large number of previously unavailable PoCs to the community, earning a $900 bounty and demonstrating strong practical impact.", "AI": {"tldr": "TracExp \u662f\u4e00\u4e2a\u81ea\u52a8\u5316\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u4ea4\u6613\u8ddf\u8e2a\u9006\u5411\u5de5\u7a0b\u548c\u4ee3\u7801\u751f\u6210\u529f\u80fd\uff0c\u76f4\u63a5\u4ece\u94fe\u4e0a\u653b\u51fb\u6267\u884c\u4e2d\u5408\u6210\u53ef\u9a8c\u8bc1\u7684\u6982\u5ff5\u8bc1\u660e (PoC)\uff0c\u540c\u65f6\u964d\u4f4e\u4e86\u5408\u6210\u6210\u672c\uff0c\u63d0\u9ad8\u4e86\u653b\u51fb\u518d\u73b0\u7684\u6548\u679c\u3002", "motivation": "\u76ee\u524d\u5728\u533a\u5757\u94fe\u7cfb\u7edf\u4e2d\uff0c\u653b\u51fb\u8005\u5229\u7528\u5408\u540c\u6f0f\u6d1e\u8fdb\u884c\u5feb\u901f\u3001\u9690\u853d\u7684\u653b\u51fb\uff0c\u5bfc\u81f4\u7cfb\u7edf\u7684\u5206\u6790\u548c\u518d\u73b0\u53d8\u5f97\u975e\u5e38\u56f0\u96be\u3002\u8fd9\u79cd\u653b\u51fb\u9700\u8981\u624b\u52a8\u6784\u5efa\u6982\u5ff5\u8bc1\u660e\u7684\u8fc7\u7a0b\u8017\u65f6\u8d39\u529b\uff0c\u4e14\u9700\u6c42\u8f83\u9ad8\u7684\u4e13\u4e1a\u77e5\u8bc6\uff0c\u96be\u4ee5\u6269\u5c55\u3002", "method": "TracExp \u901a\u8fc7\u4ece\u4f4e\u7ea7\u4ea4\u6613\u8ddf\u8e2a\u4e2d\u6062\u590d\u653b\u51fb\u8005\u7684\u903b\u8f91\uff0c\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4ee3\u7801\u751f\u6210\u80fd\u529b\u5c06\u5176\u8f6c\u6362\u4e3a\u53ef\u6267\u884c\u7684\u6f0f\u6d1e\u5229\u7528\uff0c\u901a\u8fc7\u6807\u5fd7\u6027\u6267\u884c\u4e0a\u4e0b\u6587\u7684\u672c\u5730\u5316\u548c\u5f15\u5165\u65b0\u578b\u53cc\u91cd\u53cd\u6c47\u7f16\u5668\u6765\u751f\u6210\u8bed\u4e49\u589e\u5f3a\u7684\u6f0f\u6d1e\u5229\u7528\u4f2a\u4ee3\u7801\u3002", "result": "TracExp \u5728\u8fc7\u53bb 20 \u4e2a\u6708\u7684 321 \u8d77\u5b9e\u9645\u653b\u51fb\u4e2d\uff0c\u6210\u529f\u5408\u6210 PoC \u8fbe\u5230\u4e86 93%\uff0c\u5176\u4e2d 58.78% \u53ef\u76f4\u63a5\u9a8c\u8bc1\uff0c\u5e73\u5747\u6210\u672c\u4ec5\u4e3a\u6bcf\u8d77\u6848\u4ef6 70 \u7f8e\u5206\u3002TracExp \u8fd8\u4f7f\u5f97\u5927\u91cf\u672a\u516c\u5f00\u7684\u6982\u5ff5\u8bc1\u660e\u5f97\u4ee5\u91ca\u653e\uff0c\u6536\u5230\u4e86 900 \u7f8e\u5143\u7684\u60ac\u8d4f\u91d1\uff0c\u663e\u793a\u51fa\u5f3a\u5927\u7684\u5b9e\u9645\u5f71\u54cd\u3002", "conclusion": "TracExp \u4e3a\u7406\u89e3\u548c\u9632\u8303\u533a\u5757\u94fe\u653b\u51fb\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u5e76\u4e14\u5728\u6982\u5ff5\u9a8c\u8bc1\u5408\u6210\u7684\u81ea\u52a8\u5316\u548c\u6210\u672c\u6548\u76ca\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\u3002"}}
{"id": "2601.16806", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.16806", "abs": "https://arxiv.org/abs/2601.16806", "authors": ["Lu Yihe", "Barbara Webb"], "title": "An Efficient Insect-inspired Approach for Visual Point-goal Navigation", "comment": null, "summary": "In this work we develop a novel insect-inspired agent for visual point-goal navigation. This combines abstracted models of two insect brain structures that have been implicated, respectively, in associative learning and path integration. We draw an analogy between the formal benchmark of the Habitat point-goal navigation task and the ability of insects to learn and refine visually guided paths around obstacles between a discovered food location and their nest. We demonstrate that the simple insect-inspired agent exhibits performance comparable to recent SOTA models at many orders of magnitude less computational cost. Testing in a more realistic simulated environment shows the approach is robust to perturbations.", "AI": {"tldr": "\u8be5\u5de5\u4f5c\u5f00\u53d1\u4e86\u4e00\u79cd\u6a21\u4eff\u6606\u866b\u7684\u65b0\u578b\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u7ed3\u5408\u5904\u7406\u5173\u8054\u5b66\u4e60\u548c\u8def\u5f84\u6574\u5408\u7684\u6606\u866b\u5927\u8111\u7ed3\u6784\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u4e0e\u6807\u51c6\u57fa\u51c6\u4efb\u52a1\u7c7b\u4f3c\u7684\u8868\u73b0\uff0c\u4f46\u8ba1\u7b97\u6210\u672c\u663e\u8457\u964d\u4f4e\u3002", "motivation": "\u7814\u7a76\u6a21\u4eff\u6606\u866b\u8def\u5f84\u5bfc\u822a\u80fd\u529b\u7684\u65b9\u6cd5\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u673a\u5668\u4eba\u89c6\u89c9\u5bfc\u5411\u5bfc\u822a\u4efb\u52a1\uff0c\u4ee5\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\u5e76\u63d0\u9ad8\u4efb\u52a1\u6267\u884c\u7684\u9c81\u68d2\u6027\u3002", "method": "\u5f00\u53d1\u4e86\u65b0\u9896\u7684\u6606\u866b\u542f\u53d1\u5f0f\u667a\u80fd\u4f53\uff0c\u8be5\u667a\u80fd\u4f53\u57fa\u4e8e\u4e24\u79cd\u6606\u866b\u5927\u8111\u7ed3\u6784\u7684\u6a21\u578b\u8fdb\u884c\u6784\u5efa\u3002", "result": "\u6606\u866b\u542f\u53d1\u5f0f\u667a\u80fd\u4f53\u5728\u89c6\u89c9\u5bfc\u5411\u5bfc\u822a\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u4e0e\u6700\u65b0\u7684\u6700\u4f18\u6a21\u578b\u76f8\u5f53\uff0c\u4f46\u5728\u8ba1\u7b97\u6210\u672c\u4e0a\u8981\u4f4e\u5f88\u591a\u3002\u5e76\u5728\u4e00\u4e2a\u66f4\u73b0\u5b9e\u7684\u6a21\u62df\u73af\u5883\u4e2d\u8fdb\u884c\u4e86\u6d4b\u8bd5\uff0c\u663e\u793a\u51fa\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u9a8c\u8bc1\u4e86\u6606\u866b\u542f\u53d1\u5f0f\u6a21\u578b\u5728\u89c6\u89c9\u5bfc\u5411\u5bfc\u822a\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\uff0c\u4e3a\u672a\u6765\u51cf\u5c11\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u548c\u63d0\u9ad8\u5bfc\u822a\u80fd\u529b\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2601.16795", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.16795", "abs": "https://arxiv.org/abs/2601.16795", "authors": ["Kenan Begovic", "Abdulaziz Al-Ali", "Qutaibah Malluhi"], "title": "Building a Robust Risk-Based Access Control System to Combat Ransomware's Capability to Encrypt: A Machine Learning Approach", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Ransomware core capability, unauthorized encryption, demands controls that identify and block malicious cryptographic activity without disrupting legitimate use. We present a probabilistic, risk-based access control architecture that couples machine learning inference with mandatory access control to regulate encryption on Linux in real time. The system builds a specialized dataset from the native ftrace framework using the function_graph tracer, yielding high-resolution kernel-function execution traces augmented with resource and I/O counters. These traces support both a supervised classifier and interpretable rules that drive an SELinux policy via lightweight booleans, enabling context-sensitive permit/deny decisions at the moment encryption begins. Compared to approaches centered on sandboxing, hypervisor introspection, or coarse system-call telemetry, the function-level tracing we adopt provides finer behavioral granularity than syscall-only telemetry while avoiding the virtualization/VMI overhead of sandbox-based approaches. Our current user-space prototype has a non-trivial footprint under burst I/O; we quantify it and recognize that a production kernel-space solution should aim to address this. We detail dataset construction, model training and rule extraction, and the run-time integration that gates file writes for suspect encryption while preserving benign cryptographic workflows. During evaluation, the two-layer composition retains model-level detection quality while delivering rule-like responsiveness; we also quantify operational footprint and outline engineering steps to reduce CPU and memory overhead for enterprise deployment. The result is a practical path from behavioral tracing and learning to enforceable, explainable, and risk-proportionate encryption control on production Linux systems.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u5b9e\u73b0\u51fa\u8272\u7684\u98ce\u9669\u5173\u8054\u548c\u89e3\u91ca\u80fd\u529b\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u57fa\u4e8e\u51fd\u6570\u7684\u5b9e\u65f6\u52a0\u5bc6\u63a7\u5236\u67b6\u6784\uff0c\u80fd\u591f\u6709\u6548\u8bc6\u522b\u548c\u963b\u65ad\u6076\u610f\u52a0\u5bc6\u6d3b\u52a8\uff0c\u540c\u65f6\u4e0d\u5f71\u54cd\u5408\u6cd5\u4f7f\u7528\u3002", "motivation": "\u9274\u4e8e\u52d2\u7d22\u8f6f\u4ef6\u53ca\u52a0\u5bc6\u52d2\u7d22\u7684\u9700\u6c42\uff0c\u4f5c\u8005\u8bc6\u522b\u5230\u4e86\u73b0\u6709\u63a7\u5236\u624b\u6bb5\u7684\u4e0d\u8db3\uff0c\u65e8\u5728\u8bbe\u8ba1\u4e00\u79cd\u65e2\u80fd\u63d0\u9ad8\u68c0\u6d4b\u7cbe\u5ea6\u53c8\u80fd\u4fdd\u6301\u4f4e\u8d44\u6e90\u6d88\u8017\u7684\u52a0\u5bc6\u63a7\u5236\u65b9\u6cd5\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u63a8\u7406\u4e0e\u5f3a\u5236\u8bbf\u95ee\u63a7\u5236\u7684\u7efc\u5408\u65b9\u6cd5\uff0c\u5728Linux\u5185\u6838\u4e2d\u5b9e\u73b0\u4e86\u7ec6\u7c92\u5ea6\u7684\u51fd\u6570\u7ea7\u52a0\u5bc6\u884c\u4e3a\u8ddf\u8e2a\uff0c\u901a\u8fc7\u5c06\u51fd\u6570_graph\u8ddf\u8e2a\u5668\u4e0e\u5185\u6838\u51fd\u6570\u6267\u884c\u9ad8\u5206\u8fa8\u7387\u8f68\u8ff9\u76f8\u7ed3\u5408\uff0c\u5efa\u7acb\u4e86\u4e13\u7528\u4e8e\u5206\u7c7b\u6a21\u578b\u7684\u52a8\u6001\u6570\u636e\u96c6\u3002", "result": "\u7814\u7a76\u6784\u5efa\u4e86\u4e00\u4e2a\u5b9e\u9a8c\u539f\u578b\uff0c\u8bc1\u660e\u4e86\u80fd\u591f\u5b9e\u65f6\u76d1\u63a7\u5e76\u51b3\u7b56\u5bf9\u7591\u4f3c\u52a0\u5bc6\u884c\u4e3a\u7684\u5141\u8bb8\u6216\u62d2\u7edd\uff0c\u5728\u4e0d\u5f71\u54cd\u5408\u6cd5\u4f7f\u7528\u7684\u540c\u65f6\uff0c\u5c55\u73b0\u51fa\u4e0e\u7ec6\u7c92\u5ea6\u884c\u4e3a\u6a21\u578b\u76f8\u5e94\u7684\u68c0\u6d4b\u51c6\u786e\u6027\uff0c\u540c\u65f6\u5f3a\u8c03\u4e86\u5728\u4f01\u4e1a\u90e8\u7f72\u4e2d\u8fdb\u4e00\u6b65\u51cf\u5c11\u786c\u4ef6\u8d44\u6e90\u6d88\u8017\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u57fa\u4e8e\u4ee5\u4e0a\u7814\u7a76\u65b9\u6cd5\uff0c\u8be5\u5de5\u4f5c\u6700\u7ec8\u7814\u53d1\u51fa\u4e86\u4e00\u79cd\u65e2\u80fd\u6ee1\u8db3\u98ce\u9669\u68c0\u6d4b\u9700\u6c42\uff0c\u53c8\u80fd\u4fdd\u6301\u7cfb\u7edf\u6027\u80fd\u7684\u52a0\u5bc6\u63a7\u5236\u7cfb\u7edf\uff0c\u4e3a\u4f01\u4e1a\u53ca\u751f\u4ea7\u73af\u5883\u4e2d\u7684Linux\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u3002"}}
{"id": "2601.16853", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.16853", "abs": "https://arxiv.org/abs/2601.16853", "authors": ["Ian B. de Haan", "Peter van der Putten", "Max van Duijn"], "title": "Reasoning Promotes Robustness in Theory of Mind Tasks", "comment": "14 pages, 2 figures", "summary": "Large language models (LLMs) have recently shown strong performance on Theory of Mind (ToM) tests, prompting debate about the nature and true performance of the underlying capabilities. At the same time, reasoning-oriented LLMs trained via reinforcement learning with verifiable rewards (RLVR) have achieved notable improvements across a range of benchmarks. This paper examines the behavior of such reasoning models in ToM tasks, using novel adaptations of machine psychological experiments and results from established benchmarks. We observe that reasoning models consistently exhibit increased robustness to prompt variations and task perturbations. Our analysis indicates that the observed gains are more plausibly attributed to increased robustness in finding the correct solution, rather than to fundamentally new forms of ToM reasoning. We discuss the implications of this interpretation for evaluating social-cognitive behavior in LLMs.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u4f7f\u7528\u589e\u5f3a\u5b66\u4e60\u5f3a\u5316\u5956\u52b1\u8bad\u7ec3\u7684\u63a8\u7406\u6a21\u578b\u5728\u7406\u8bba\u62df\u6001\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u8fd9\u4e9b\u6a21\u578b\u7684\u7a33\u5065\u6027\u6709\u6240\u63d0\u5347\uff0c\u4f46\u8fd9\u4e00\u63d0\u5347\u66f4\u53ef\u80fd\u662f\u7531\u4e8e\u627e\u5230\u6b63\u786e\u7b54\u6848\u7684\u7a33\u5065\u6027\u589e\u52a0\uff0c\u800c\u975e\u5168\u65b0\u7684\u7406\u8bba\u62df\u6001\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u8bba\u6587\u65e8\u5728\u63a2\u8ba8\u5f3a\u5316\u5b66\u4e60\u5f3a\u5316\u5956\u52b1\u8bad\u7ec3\u7684\u63a8\u7406\u6a21\u578b\u5728\u7406\u8bba\u62df\u6001\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u4ee5\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u793e\u4f1a\u8ba4\u77e5\u884c\u4e3a\u65b9\u9762\u7684\u8868\u73b0\u3002", "method": "\u901a\u8fc7\u673a\u5668\u5fc3\u7406\u5b9e\u9a8c\u7684\u65b0\u578b\u6539\u7f16\u4ee5\u53ca\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u7684\u7ed3\u679c\u6765\u5206\u6790\u6a21\u578b\u5728\u7406\u8bba\u62df\u6001\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u63a8\u7406\u6a21\u578b\u5728\u5404\u79cd\u63d0\u793a\u53d8\u5316\u548c\u4efb\u52a1\u6270\u52a8\u4e2d\u7684\u8868\u73b0\u66f4\u7a33\u5065\uff0c\u5e76\u4e14\u8fd9\u79cd\u589e\u76ca\u66f4\u6709\u53ef\u80fd\u5f52\u56e0\u4e8e\u627e\u5230\u6b63\u786e\u7b54\u6848\u7684\u7a33\u5065\u6027\uff0c\u800c\u4e0d\u662f\u771f\u6b63\u5177\u5907\u4e86\u65b0\u578b\u7684\u7406\u8bba\u62df\u6001\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "\u8bba\u6587\u8ba4\u4e3a\uff0c\u5728\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u793e\u4f1a\u8ba4\u77e5\u884c\u4e3a\u65f6\uff0c\u5e94\u8be5\u66f4\u591a\u5173\u6ce8\u6a21\u578b\u7684\u7a33\u5065\u6027\u8868\u73b0\uff0c\u800c\u975e\u5176\u662f\u5426\u8fdb\u884c\u4e86\u5168\u65b0\u7684\u7406\u8bba\u62df\u6001\u63a8\u7406\u3002"}}
