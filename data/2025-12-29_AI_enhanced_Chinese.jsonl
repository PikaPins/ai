{"id": "2512.21358", "categories": ["cs.CR", "cs.IT"], "pdf": "https://arxiv.org/pdf/2512.21358", "abs": "https://arxiv.org/abs/2512.21358", "authors": ["Natasha Fernandes", "Annabelle McIver", "Parastoo Sadeghi"], "title": "Composition Theorems for f-Differential Privacy", "comment": "32 pages, 11 figures", "summary": "\"f differential privacy\" (fDP) is a recent definition for privacy privacy which can offer improved predictions of \"privacy loss\". It has been used to analyse specific privacy mechanisms, such as the popular Gaussian mechanism. In this paper we show how fDP's foundation in statistical hypothesis testing implies equivalence to the channel model of Quantitative Information Flow. We demonstrate this equivalence by a Galois connection between two partially ordered sets. This equivalence enables novel general composition theorems for fDP, supporting improved analysis for complex privacy designs.", "AI": {"tldr": "\u672c\u6587\u5c55\u793a\u4e86 fDP\uff08f \u68af\u5ea6\u9690\u79c1\uff09\u7684\u7edf\u8ba1\u5047\u8bbe\u68c0\u9a8c\u57fa\u7840\u4f7f\u5176\u7b49\u540c\u4e8e\u5b9a\u91cf\u4fe1\u606f\u6d41\u7684\u4fe1\u9053\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u683c\u5965\u5c14\u683c\u8fde\u63a5\u4e3a\u4e24\u4e2a\u504f\u5e8f\u96c6\u5efa\u7acb\u4e86\u7b49\u4ef7\u5173\u7cfb\u3002\u8fd9\u4e00\u7b49\u4ef7\u5173\u7cfb\u4f7f\u5f97\u80fd\u591f\u4e3a fDP \u5efa\u7acb\u65b0\u7684\u901a\u7528\u7ec4\u5408\u5b9a\u7406\uff0c\u652f\u6301\u590d\u6742\u9690\u79c1\u8bbe\u8ba1\u7684\u6539\u8fdb\u5206\u6790\u3002", "motivation": "\u4e3a\u4e86\u66f4\u597d\u5730\u5206\u6790\u590d\u6742\u9690\u79c1\u673a\u5236\uff0c\u5e76\u63d0\u4f9b\u66f4\u51c6\u786e\u7684\u9690\u79c1\u635f\u5931\u9884\u6d4b\u3002", "method": "\u901a\u8fc7\u5efa\u7acb fDP \u548c\u4fe1\u606f\u6d41\u4fe1\u9053\u6a21\u578b\u4e4b\u95f4\u7684\u683c\u5965\u5c14\u683c\u8fde\u63a5\u6765\u8bc1\u660e\u4e24\u8005\u7b49\u4ef7\u3002\u7136\u540e\uff0c\u5229\u7528\u8fd9\u79cd\u7b49\u4ef7\u6027\uff0c\u6784\u9020\u65b0\u7684\u7ec4\u5408\u5b9a\u7406\u6765\u652f\u6301\u5bf9\u590d\u6742\u9690\u79c1\u8bbe\u8ba1\u7684\u5206\u6790\u3002", "result": "\u53d1\u73b0\u4e86 fDP \u548c\u4fe1\u9053\u6a21\u578b\u4e4b\u95f4\u7684\u7b49\u4ef7\u6027\uff0c\u63d0\u51fa\u4e86\u66f4\u901a\u7528\u7684\u7ec4\u5408\u5b9a\u7406\uff0c\u589e\u5f3a\u4e86\u5bf9\u590d\u6742\u9690\u79c1\u8bbe\u8ba1\u7684\u5206\u6790\u80fd\u529b\u3002", "conclusion": "fDP \u53ef\u4ee5\u4f5c\u4e3a\u4e00\u79cd\u5f3a\u5927\u7684\u5de5\u5177\uff0c\u7528\u4e8e\u5206\u6790\u548c\u7ec4\u5408\u590d\u6742\u7684\u9690\u79c1\u4fdd\u62a4\u673a\u5236\uff0c\u5e76\u6709\u52a9\u4e8e\u66f4\u597d\u5730\u7406\u89e3\u9690\u79c1\u635f\u5931\u3002"}}
{"id": "2512.21362", "categories": ["cs.CR", "cs.AR"], "pdf": "https://arxiv.org/pdf/2512.21362", "abs": "https://arxiv.org/abs/2512.21362", "authors": ["Behnam Farnaghinejad", "Antonio Porsia", "Annachiara Ruospo", "Alessandro Savino", "Stefano Di Carlo", "Ernesto Sanchez"], "title": "Power Side-Channel Analysis of the CVA6 RISC-V Core at the RTL Level Using VeriSide", "comment": null, "summary": "Security in modern RISC-V processors demands more than functional correctness: It requires resilience to side-channel attacks. This paper evaluates the vulnerability of the side channel of the CVA6 RISC-V core by analyzing software-based AES encryption uses an RTL-level power profiling framework called VeriSide. This work represents that this design's Correlation Power Analysis (CPA) reveals significant leakage, enabling key recovery. These findings underscore the importance of early-stage RTL assessments in shaping future secure RISC-V designs.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5bf9CVA6 RISC-V\u5185\u6838\u57fa\u4e8e\u8f6f\u4ef6\u7684AES\u52a0\u5bc6\u8fdb\u884c RTL\u5c42\u7ea7\u7684\u529f\u8017\u5206\u6790\uff0c\u63ed\u793a\u4e86\u5176\u5728\u4fa7\u4fe1\u9053\u653b\u51fb\u4e0b\u7684\u663e\u8457\u6f0f\u6d1e\uff0c\u5e76\u63d0\u9192\u8bbe\u8ba1\u8005\u5e94\u5728\u65e9\u671f\u9636\u6bb5\u8fdb\u884cRTL\u8bc4\u4f30\u4ee5\u786e\u4fdd\u672a\u6765\u7684\u5b89\u5168\u8bbe\u8ba1\u3002", "motivation": "\u73b0\u4ee3RISC-V\u5904\u7406\u5668\u7684\u5b89\u5168\u9700\u6c42\u4e0d\u4ec5\u9650\u4e8e\u529f\u80fd\u6b63\u786e\u6027\uff0c\u8fd8\u5fc5\u987b\u5177\u5907\u62b5\u6297\u4fa7\u4fe1\u9053\u653b\u51fb\u7684\u80fd\u529b\u3002\u9488\u5bf9CVA6 RISC-V\u5185\u6838\uff0c\u5728\u8f6f\u4ef6\u5c42\u9762\u5bf9AES\u52a0\u5bc6\u7b97\u6cd5\u8fdb\u884c\u529f\u8017\u5206\u6790\uff0c\u4ee5\u8bc4\u4f30\u5176\u4fa7\u4fe1\u9053\u5b89\u5168\u98ce\u9669\uff0c\u63ed\u793a\u4e86\u6f5c\u5728\u7684\u5b89\u5168\u9690\u60a3\u3002", "method": "\u91c7\u7528VeriSide\u8fd9\u4e00RTL\u5c42\u7ea7\u7684\u529f\u8017\u5206\u6790\u6846\u67b6\uff0c\u5bf9\u8f6f\u4ef6\u5b9e\u73b0\u7684AES\u52a0\u5bc6\u7b97\u6cd5\u8fdb\u884c\u8be6\u7ec6\u5206\u6790\uff0c\u68c0\u6d4b\u5176\u5728\u4fa7\u4fe1\u9053\u653b\u51fb\u4e0b\u7684\u6f0f\u6d1e\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0cCVA6\u8bbe\u8ba1\u4e2d\u5b58\u5728\u663e\u8457\u7684\u6cc4\u6f0f\u73b0\u8c61\uff0c\u901a\u8fc7\u76f8\u5173\u6027\u529f\u7387\u5206\u6790(CPA)\u80fd\u591f\u6210\u529f\u6062\u590d\u5bc6\u94a5\u3002\u8fd9\u8868\u660e\u9700\u8981\u5728\u8bbe\u8ba1\u521d\u671f\u5c31\u8fdb\u884c\u8be6\u7ec6\u7684RTL\u5c42\u7ea7\u8bc4\u4f30\u3002", "conclusion": "\u8be5\u7814\u7a76\u5f3a\u8c03\u4e86\u5728RISC-V\u5904\u7406\u5668\u8bbe\u8ba1\u8fc7\u7a0b\u4e2d\u8fdb\u884c\u65e9\u671fRTL\u8bc4\u4f30\u7684\u91cd\u8981\u6027\uff0c\u4ee5\u786e\u4fdd\u672a\u6765\u7684\u5b89\u5168\u6027\u8bbe\u8ba1\u80fd\u591f\u6709\u6548\u9632\u5fa1\u4fa7\u4fe1\u9053\u653b\u51fb\u3002"}}
{"id": "2512.21368", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.21368", "abs": "https://arxiv.org/abs/2512.21368", "authors": ["Arsalan Vahi"], "title": "Key Length-Oriented Classification of Lightweight Cryptographic Algorithms for IoT Security", "comment": null, "summary": "The successful deployment of the Internet of Things (IoT) applications relies heavily on their robust security, and lightweight cryptography is considered an emerging solution in this context. While existing surveys have been examining lightweight cryptographic techniques from the perspective of hardware and software implementations or performance evaluation, there is a significant gap in addressing different security aspects specific to the IoT environment. This study aims to bridge this gap. This research presents a thorough survey focused on the security evaluation of symmetric lightweight ciphers commonly used in IoT systems. The objective of this study is to provide a holistic understanding of lightweight ciphers, emphasizing their security strength, which is an essential consideration for real-time and resource-constrained applications. Furthermore, we propose two taxonomies: one for classifying IoT applications based on their inherent characteristics, and another for evaluating security levels based on key size. Our findings indicate that key size is a critical parameter in the security of lightweight ciphers. Ciphers employing keys shorter than 128 bits are considered less secure or even insecure for protecting sensitive data", "AI": {"tldr": "\u8be5\u7814\u7a76\u5bf9\u7269\u8054\u7f51\u73af\u5883\u4e2d\u5e38\u7528\u7684\u8f7b\u91cf\u7ea7\u5bc6\u7801\u7b97\u6cd5\u7684\u5b89\u5168\u6027\u8fdb\u884c\u4e86\u5168\u9762\u8bc4\u4f30\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u5173\u4e8e\u5bc6\u94a5\u5927\u5c0f\u7684\u5206\u7c7b\u6cd5\uff0c\u5f3a\u8c03\u5bc6\u94a5\u957f\u5ea6\u5728\u8f7b\u91cf\u7ea7\u5bc6\u7801\u5b89\u5168\u6027\u4e2d\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u9274\u4e8e\u7269\u8054\u7f51\u5e94\u7528\u7684\u5b89\u5168\u9700\u6c42\u4ee5\u53ca\u73b0\u6709\u6587\u732e\u5728\u786c\u4ef6\u3001\u8f6f\u4ef6\u5b9e\u73b0\u6216\u6027\u80fd\u8bc4\u4f30\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e9b\u9886\u57df\u7684\u7a7a\u767d\u3002", "method": "\u7814\u7a76\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u6587\u732e\u7efc\u8ff0\uff0c\u5e76\u63d0\u51fa\u4e86\u4e24\u79cd\u5206\u7c7b\u6cd5\uff1a\u4e00\u79cd\u7528\u4e8e\u6839\u636e\u81ea\u8eab\u7279\u6027\u5206\u7c7b\u7269\u8054\u7f51\u5e94\u7528\uff0c\u53e6\u4e00\u79cd\u7528\u4e8e\u8bc4\u4f30\u57fa\u4e8e\u5bc6\u94a5\u5927\u5c0f\u7684\u5b89\u5168\u6027\u7ea7\u522b\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5bc6\u94a5\u957f\u5ea6\u662f\u8f7b\u91cf\u7ea7\u5bc6\u7801\u5b89\u5168\u6027\u7684\u5173\u952e\u53c2\u6570\uff0c\u4f7f\u7528\u77ed\u4e8e128\u4f4d\u5bc6\u94a5\u7684\u5bc6\u7801\u88ab\u8ba4\u4e3a\u662f\u4e0d\u5b89\u5168\u7684\uff0c\u4e0d\u9002\u7528\u4e8e\u4fdd\u62a4\u654f\u611f\u4fe1\u606f\u3002", "conclusion": "\u7814\u7a76\u4e3a\u667a\u80fd\u7269\u8054\u7f51\u7cfb\u7edf\u7684\u8f7b\u91cf\u7ea7\u52a0\u5bc6\u89e3\u51b3\u65b9\u6848\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u7406\u89e3\uff0c\u5e76\u4e14\u8fd8\u6307\u51fa\u4e86\u5728\u9009\u62e9\u8f7b\u91cf\u7ea7\u52a0\u5bc6\u65b9\u6848\u65f6\u9700\u8981\u8003\u8651\u7684\u5173\u952e\u5b89\u5168\u53c2\u6570\u3002"}}
{"id": "2512.21365", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.21365", "abs": "https://arxiv.org/abs/2512.21365", "authors": ["Chung-Chin Shih", "Ti-Rong Wu", "Ting Han Wei", "Yu-Shan Hsu", "Hung Guei", "I-Chen Wu"], "title": "A Study of Solving Life-and-Death Problems in Go Using Relevance-Zone Based Solvers", "comment": "Accepted by IEEE Transactions on Games", "summary": "This paper analyzes the behavior of solving Life-and-Death (L&D) problems in the game of Go using current state-of-the-art computer Go solvers with two techniques: the Relevance-Zone Based Search (RZS) and the relevance-zone pattern table. We examined the solutions derived by relevance-zone based solvers on seven L&D problems from the renowned book \"Life and Death Dictionary\" written by Cho Chikun, a Go grandmaster, and found several interesting results. First, for each problem, the solvers identify a relevance-zone that highlights the critical areas for solving. Second, the solvers discover a series of patterns, including some that are rare. Finally, the solvers even find different answers compared to the given solutions for two problems. We also identified two issues with the solver: (a) it misjudges values of rare patterns, and (b) it tends to prioritize living directly rather than maximizing territory, which differs from the behavior of human Go players. We suggest possible approaches to address these issues in future work. Our code and data are available at https://rlg.iis.sinica.edu.tw/papers/study-LD-RZ.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u4f7f\u7528\u5f53\u524d\u9886\u5148\u8ba1\u7b97\u673a\u56f4\u68cb\u89e3\u9898\u5668\uff08RZS\u548c\u76f8\u5173\u533a\u57df\u6a21\u5f0f\u8868\uff09\u89e3\u51b3\u56f4\u68cb\u751f\u6b7b\u95ee\u9898\u7684\u884c\u4e3a\uff0c\u5e76\u53d1\u73b0\u4e86\u89e3\u51b3\u65b9\u6848\u3001\u5173\u952e\u533a\u57df\u3001\u65b0\u9896\u6a21\u5f0f\u548c\u4e0e\u4eba\u7c7b\u884c\u4e3a\u7684\u5dee\u5f02\u3002", "motivation": "\u63a2\u8ba8\u8ba1\u7b97\u673a\u56f4\u68cb\u89e3\u9898\u5668\u5728\u89e3\u51b3\u56f4\u68cb\u751f\u6b7b\u95ee\u9898\u4e2d\u7684\u8868\u73b0\uff0c\u63ed\u793a\u5176\u4f18\u52bf\u4e0e\u4e0d\u8db3\uff0c\u5e0c\u671b\u672a\u6765\u80fd\u591f\u6539\u8fdb\u7b97\u6cd5\u3002", "method": "\u4f7f\u7528\u5148\u8fdb\u7684\u8ba1\u7b97\u673a\u56f4\u68cb\u89e3\u9898\u5668\uff0c\u7ed3\u5408Relevance-Zone Based Search\uff08RZS\uff09\u548c\u76f8\u5173\u533a\u57df\u6a21\u5f0f\u8868\u7684\u6280\u672f\u6765\u5206\u6790\u56f4\u68cb\u751f\u6b7b\u95ee\u9898\u3002", "result": "\u53d1\u73b0\u4e86\u89e3\u51b3\u65b9\u6848\u7684\u5173\u952e\u533a\u57df\u3001\u65b0\u9896\u7684\u6a21\u5f0f\u4ee5\u53ca\u4e0e\u4eba\u7c7b\u89e3\u9898\u65b9\u6cd5\u7684\u5dee\u5f02\u3002", "conclusion": "\u6307\u51fa\u4e86\u89e3\u9898\u5668\u7684\u4e24\u9879\u4e0d\u8db3\uff0c\u5e76\u63d0\u4f9b\u53ef\u80fd\u7684\u89e3\u51b3\u65b9\u6848\u7684\u65b9\u5411\u3002"}}
{"id": "2512.21377", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.21377", "abs": "https://arxiv.org/abs/2512.21377", "authors": ["Adwa Alangari", "Ohoud Alharbi"], "title": "A Systematic Review of Technical Defenses Against Software-Based Cheating in Online Multiplayer Games", "comment": null, "summary": "This systematic literature review surveys technical defenses against software-based cheating in online multiplayer games. Categorizing existing approach-es into server-side detection, client-side anti-tamper, kernel-level anti-cheat drivers, and hardware-assisted TEEs. Each category is evaluated in terms of detection effectiveness, perfor-mance overhead, privacy im-pact, and scalability. The analy-sis highlights key trade-offs, particularly between the high visibility of kernel-level solutions and their privacy and stability risks, versus the low intrusive-ness but limited insight of server-side methods. Overall, the re-view emphasizes the ongoing arms race with cheaters and the need for robust, adversary-resistant anti-cheat designs.", "AI": {"tldr": "\u8be5\u5143\u6587\u732e\u56de\u987e\u7cfb\u7edf\u5730\u7814\u7a76\u4e86\u5728\u7ebf\u591a\u4eba\u6e38\u620f\u4e2d\u8f6f\u4ef6\u4f5c\u5f0a\u7684\u6280\u672f\u9632\u5fa1\u63aa\u65bd\uff0c\u5c06\u73b0\u6709\u65b9\u6cd5\u5206\u4e3a\u670d\u52a1\u5668\u7aef\u68c0\u6d4b\u3001\u5ba2\u6237\u7aef\u9632\u7be1\u6539\u3001\u5185\u6838\u7ea7\u53cd\u4f5c\u5f0a\u9a71\u52a8\u548c\u786c\u4ef6\u8f85\u52a9\u7684\u5b89\u5168\u73af\u5883\u56db\u7c7b\u3002\u8bc4\u4f30\u4e86\u6bcf\u7c7b\u65b9\u6cd5\u5728\u68c0\u6d4b\u6709\u6548\u6027\u3001\u6027\u80fd\u5f00\u9500\u3001\u9690\u79c1\u5f71\u54cd\u548c\u53ef\u6269\u5c55\u6027\u65b9\u9762\u7684\u8868\u73b0\uff0c\u7a81\u51fa\u4e86\u5173\u952e\u6743\u8861\u3002", "motivation": "\u4e3a\u4e86\u5bf9\u6297\u5728\u7ebf\u591a\u4eba\u6e38\u620f\u4e2d\u65e5\u76ca\u4e25\u91cd\u7684\u4f5c\u5f0a\u884c\u4e3a\uff0c\u7814\u7a76\u73b0\u6709\u7684\u6280\u672f\u9632\u5fa1\u63aa\u65bd\uff0c\u4ee5\u4fbf\u8fdb\u4e00\u6b65\u4f18\u5316\u548c\u8bbe\u8ba1\u66f4\u4e3a robust \u7684\u53cd\u4f5c\u5f0a\u7cfb\u7edf\u3002", "method": "\u5c06\u73b0\u6709\u7684\u53cd\u4f5c\u5f0a\u6280\u672f\u65b9\u6cd5\u8fdb\u884c\u5206\u7c7b\uff0c\u5e76\u5bf9\u6bcf\u4e2a\u7c7b\u522b\u5728\u68c0\u6d4b\u6709\u6548\u6027\u3001\u6027\u80fd\u5f00\u9500\u3001\u9690\u79c1\u5f71\u54cd\u548c\u53ef\u6269\u5c55\u6027\u65b9\u9762\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5185\u6838\u7ea7\u89e3\u51b3\u65b9\u6848\u867d\u7136\u6548\u80fd\u9ad8\uff0c\u4f46\u9690\u79c1\u548c\u7a33\u5b9a\u6027\u98ce\u9669\u8f83\u9ad8\uff1b\u800c\u670d\u52a1\u5668\u7aef\u65b9\u6cd5\u867d\u7136\u4f4e\u4fb5\u5165\u4f46\u6d1e\u5bdf\u529b\u6709\u9650\u3002\u5f3a\u8c03\u4e86\u53cd\u4f5c\u5f0a\u8bbe\u8ba1\u7684\u6301\u7eed\u519b\u5907\u7ade\u8d5b\u3002", "conclusion": "\u7ed3\u8bba\u6307\u51fa\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u4e3a robust \u7684\u53cd\u4f5c\u5f0a\u8bbe\u8ba1\u65b9\u6848\uff0c\u4ee5\u5e94\u5bf9\u4e0d\u65ad\u53d8\u5316\u7684\u4f5c\u5f0a\u5a01\u80c1\u3002"}}
{"id": "2512.21421", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.21421", "abs": "https://arxiv.org/abs/2512.21421", "authors": ["Junfang Luo", "Mengjun Hu", "Keyun Qin"], "title": "Three-way decision with incomplete information based on similarity and satisfiability", "comment": null, "summary": "Three-way decision is widely applied with rough set theory to learn classification or decision rules. The approaches dealing with complete information are well established in the literature, including the two complementary computational and conceptual formulations. The computational formulation uses equivalence relations, and the conceptual formulation uses satisfiability of logic formulas. In this paper, based on a briefly review of these two formulations, we generalize both formulations into three-way decision with incomplete information that is more practical in real-world applications. For the computational formulation, we propose a new measure of similarity degree of objects as a generalization of equivalence relations. Based on it, we discuss two approaches to three-way decision using alpha-similarity classes and approximability of objects, respectively. For the conceptual formulation, we propose a measure of satisfiability degree of formulas as a quantitative generalization of satisfiability with complete information. Based on it, we study two approaches to three-way decision using alpha-meaning sets of formulas and confidence of formulas, respectively. While using similarity classes is a common method of analyzing incomplete information in the literature, the proposed concept of approximability and the two approaches in conceptual formulation point out new promising directions.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u56de\u987e\u7b49\u4ef7\u5173\u7cfb\u548c\u6ee1\u8db3\u903b\u8f91\u516c\u5f0f\u7684\u6982\u5ff5\u5f62\u5f0f\uff0c\u5c06\u8fd9\u4e24\u79cd\u5f62\u5f0f\u63a8\u5e7f\u5230\u5e26\u6709\u4e0d\u5b8c\u6574\u4fe1\u606f\u7684\u4e09\u5143\u51b3\u7b56\uff0c\u8fdb\u4e00\u6b65\u63d0\u51fa\u76f8\u4f3c\u5ea6\u5ea6\u91cf\u548c\u6ee1\u8db3\u5ea6\u5ea6\u91cf\uff0c\u5e76\u63a2\u8ba8\u4e86\u57fa\u4e8e\u03b1\u76f8\u4f3c\u7c7b\u3001\u5bf9\u8c61\u7684\u8fd1\u4f3c\u6027\u548c\u03b1\u610f\u4e49\u96c6\u3001\u516c\u5f0f\u7684\u4fe1\u5fc3\u5ea6\u7684\u4e24\u79cd\u65b9\u6cd5\u3002", "motivation": "\u6587\u7ae0\u65e8\u5728\u5c06\u7ecf\u5178\u4e09\u5143\u51b3\u7b56\u65b9\u6cd5\u63a8\u5e7f\u5230\u5904\u7406\u4e0d\u5b8c\u6574\u4fe1\u606f\u7684\u60c5\u51b5\uff0c\u7531\u4e8e\u4e0d\u5b8c\u6574\u4fe1\u606f\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u666e\u904d\u6027\uff0c\u8fd9\u4e00\u63a8\u5e7f\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002", "method": "1. \u5bf9\u6709\u9650\u4e09\u5143\u51b3\u7b56\u7684\u7b49\u4ef7\u5173\u7cfb\u5f62\u5f0f\u8fdb\u884c\u4e86\u6982\u5ff5\u4e0a\u7684\u6269\u5c55\uff0c\u63d0\u51fa\u4e86\u76f8\u4f3c\u5ea6\u5ea6\u91cf\u548c\u57fa\u4e8e\u76f8\u4f3c\u5ea6\u7c7b\u7684\u65b9\u6cd5\u30022. \u5bf9\u6709\u9650\u4e09\u5143\u51b3\u7b56\u7684\u903b\u8f91\u516c\u5f0f\u5f62\u5f0f\u8fdb\u884c\u4e86\u91cf\u5316\u6269\u5c55\uff0c\u63d0\u51fa\u6ee1\u8db3\u5ea6\u5ea6\u91cf\u548c\u57fa\u4e8e\u610f\u4e49\u96c6\u548c\u4fe1\u5fc3\u5ea6\u7684\u65b9\u6cd5\u3002", "result": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u76f8\u4f3c\u5ea6\u7c7b\u548c\u5bf9\u8c61\u8fd1\u4f3c\u6027\u7684\u4e24\u79cd\u4e09\u5143\u51b3\u7b56\u65b9\u6cd5\uff0c\u4ee5\u53ca\u57fa\u4e8e\u610f\u4e49\u96c6\u548c\u516c\u5f0f\u7684\u4fe1\u5fc3\u5ea6\u7684\u4e24\u79cd\u4e09\u5143\u51b3\u7b56\u65b9\u6cd5\u3002", "conclusion": "\u7814\u7a76\u5c55\u793a\u4e86\u5bf9\u4e09\u5143\u51b3\u7b56\u65b9\u6cd5\u5728\u5904\u7406\u4e0d\u5b8c\u6574\u4fe1\u606f\u573a\u666f\u4e0b\u7684\u65b0\u89c1\u89e3\u548c\u6f5c\u5728\u53d1\u5c55\u65b9\u5411\u3002"}}
{"id": "2512.21482", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.21482", "abs": "https://arxiv.org/abs/2512.21482", "authors": ["Fanwei Zeng", "Changtao Miao", "Jing Huang", "Zhiya Tan", "Shutao Gong", "Xiaoming Yu", "Yang Wang", "Huazhe Tan", "Weibin Yao", "Jianshu Li"], "title": "LogicLens: Visual-Logical Co-Reasoning for Text-Centric Forgery Analysis", "comment": "11 pages, 5 figures, 3 tables", "summary": "Sophisticated text-centric forgeries, fueled by rapid AIGC advancements, pose a significant threat to societal security and information authenticity. Current methods for text-centric forgery analysis are often limited to coarse-grained visual analysis and lack the capacity for sophisticated reasoning. Moreover, they typically treat detection, grounding, and explanation as discrete sub-tasks, overlooking their intrinsic relationships for holistic performance enhancement. To address these challenges, we introduce LogicLens, a unified framework for Visual-Textual Co-reasoning that reformulates these objectives into a joint task. The deep reasoning of LogicLens is powered by our novel Cross-Cues-aware Chain of Thought (CCT) mechanism, which iteratively cross-validates visual cues against textual logic. To ensure robust alignment across all tasks, we further propose a weighted multi-task reward function for GRPO-based optimization. Complementing this framework, we first designed the PR$^2$ (Perceiver, Reasoner, Reviewer) pipeline, a hierarchical and iterative multi-agent system that generates high-quality, cognitively-aligned annotations. Then, we constructed RealText, a diverse dataset comprising 5,397 images with fine-grained annotations, including textual explanations, pixel-level segmentation, and authenticity labels for model training. Extensive experiments demonstrate the superiority of LogicLens across multiple benchmarks. In a zero-shot evaluation on T-IC13, it surpasses the specialized framework by 41.4% and GPT-4o by 23.4% in macro-average F1 score. Moreover, on the challenging dense-text T-SROIE dataset, it establishes a significant lead over other MLLM-based methods in mF1, CSS, and the macro-average F1. Our dataset, model, and code will be made publicly available.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.21524", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.21524", "abs": "https://arxiv.org/abs/2512.21524", "authors": ["Lichao Wu", "Mohamadreza Rostami", "Huimin Li", "Nikhilesh Singh", "Ahmad-Reza Sadeghi"], "title": "GoldenFuzz: Generative Golden Reference Hardware Fuzzing", "comment": "Accepted by NDSS'26", "summary": "Modern hardware systems, driven by demands for high performance and application-specific functionality, have grown increasingly complex, introducing large surfaces for bugs and security-critical vulnerabilities. Fuzzing has emerged as a scalable solution for discovering such flaws. Yet, existing hardware fuzzers suffer from limited semantic awareness, inefficient test refinement, and high computational overhead due to reliance on slow device simulation.\n  In this paper, we present GoldenFuzz, a novel two-stage hardware fuzzing framework that partially decouples test case refinement from coverage and vulnerability exploration. GoldenFuzz leverages a fast, ISA-compliant Golden Reference Model (GRM) as a ``digital twin'' of the Device Under Test (DUT). It fuzzes the GRM first, enabling rapid, low-cost test case refinement, accelerating deep architectural exploration and vulnerability discovery on DUT. During the fuzzing pipeline, GoldenFuzz iteratively constructs test cases by concatenating carefully chosen instruction blocks that balance the subtle inter- and intra-instructions quality. A feedback-driven mechanism leveraging insights from both high- and low-coverage samples further enhances GoldenFuzz's capability in hardware state exploration. Our evaluation of three RISC-V processors, RocketChip, BOOM, and CVA6, demonstrates that GoldenFuzz significantly outperforms existing fuzzers in achieving the highest coverage with minimal test case length and computational overhead. GoldenFuzz uncovers all known vulnerabilities and discovers five new ones, four of which are classified as highly severe with CVSS v3 severity scores exceeding seven out of ten. It also identifies two previously unknown vulnerabilities in the commercial BA51-H core extension.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.21540", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.21540", "abs": "https://arxiv.org/abs/2512.21540", "authors": ["Yanhao Li", "Lu Ma", "Jiaran Zhang", "Lexiang Tang", "Wentao Zhang", "Guibo Luo"], "title": "Leash: Adaptive Length Penalty and Reward Shaping for Efficient Large Reasoning Model", "comment": null, "summary": "Existing approaches typically rely on fixed length penalties, but such penalties are hard to tune and fail to adapt to the evolving reasoning abilities of LLMs, leading to suboptimal trade-offs between accuracy and conciseness. To address this challenge, we propose Leash (adaptive LEngth penAlty and reward SHaping), a reinforcement learning framework for efficient reasoning in LLMs. We formulate length control as a constrained optimization problem and employ a Lagrangian primal-dual method to dynamically adjust the penalty coefficient. When generations exceed the target length, the penalty is intensified; when they are shorter, it is relaxed. This adaptive mechanism guides models toward producing concise reasoning without sacrificing task performance. Experiments on Deepseek-R1-Distill-Qwen-1.5B and Qwen3-4B-Thinking-2507 show that Leash reduces the average reasoning length by 60% across diverse tasks - including in-distribution mathematical reasoning and out-of-distribution domains such as coding and instruction following - while maintaining competitive performance. Our work thus presents a practical and effective paradigm for developing controllable and efficient LLMs that balance reasoning capabilities with computational budgets.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.21525", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.21525", "abs": "https://arxiv.org/abs/2512.21525", "authors": ["Keshav Sinha", "Sumitra", "Richa Kumari", "Akashdeep Bhardwaj", "Shawon Rahman"], "title": "Enhancing Distributed Authorization With Lagrange Interpolation And Attribute-Based Encryption", "comment": "In terms of content, the paper meets the requirements of the journal. This paper provides an opportunity for the author to conduct a more detailed experiment and present the results. By doing so, the author's idea and algorithm can be improved. The experiment can be conducted under a variety of conditions", "summary": "In todays security landscape, every user wants to access large amounts of data with confidentiality and authorization. To maintain confidentiality, various researchers have proposed several techniques. However, to access secure data, researchers use access control lists to grant authentication and provide authorization. The above several steps will increase the server's computation overhead and response time. To cope with these two problems, we proposed multiparty execution on the server. In this paper, we introduce two different approaches. The first approach is encryption, utilizing the Involution Function Based Stream Cipher to encrypt the file data. The second approach is key distribution, using the Shamir secret sharing scheme to divide and distribute the symmetric key to every user. The decryption process required key reconstruction, which used second order Lagrange interpolation to reconstruct the secret keys from the hidden points. The process will reduce the server's computational overhead. The results are evaluated based on the encryption and decryption time, throughput, computational overhead, and security analysis. In the future, the proposed mechanism will be used to share large-scale, secure data within the organization.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.21578", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.21578", "abs": "https://arxiv.org/abs/2512.21578", "authors": ["Ali Sahami", "Sudhanshu Garg", "Andrew Wang", "Chaitanya Kulkarni", "Farhad Farahani", "Sean Yun-Shiuan Chuang", "Jian Wan", "Srinivasan Manoharan", "Uma Kona", "Nitin Sharma", "Linsey Pang", "Prakhar Mehrotra", "Jessica Clark", "Mark Moyou"], "title": "NEMO-4-PAYPAL: Leveraging NVIDIA's Nemo Framework for empowering PayPal's Commerce Agent", "comment": null, "summary": "We present the development and optimization of PayPal's Commerce Agent, powered by NEMO-4-PAYPAL, a multi-agent system designed to revolutionize agentic commerce on the PayPal platform. Through our strategic partnership with NVIDIA, we leveraged the NeMo Framework for LLM model fine-tuning to enhance agent performance. Specifically, we optimized the Search and Discovery agent by replacing our base model with a fine-tuned Nemotron small language model (SLM).\n  We conducted comprehensive experiments using the llama3.1-nemotron-nano-8B-v1 architecture, training LoRA-based models through systematic hyperparameter sweeps across learning rates, optimizers (Adam, AdamW), cosine annealing schedules, and LoRA ranks. Our contributions include: (1) the first application of NVIDIA's NeMo Framework to commerce-specific agent optimization, (2) LLM powered fine-tuning strategy for retrieval-focused commerce tasks, (3) demonstration of significant improvements in latency and cost while maintaining agent quality, and (4) a scalable framework for multi-agent system optimization in production e-commerce environments. Our results demonstrate that the fine-tuned Nemotron SLM effectively resolves the key performance issue in the retrieval component, which represents over 50\\% of total agent response time, while maintaining or enhancing overall system performance.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.21583", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.21583", "abs": "https://arxiv.org/abs/2512.21583", "authors": ["Zelin Zang", "Wenyi Gu", "Siqi Ma", "Dan Yang", "Yue Shen", "Zhu Zhang", "Guohui Fan", "Wing-Kuen Ling", "Fuji Yang"], "title": "A Medical Multimodal Diagnostic Framework Integrating Vision-Language Models and Logic Tree Reasoning", "comment": null, "summary": "With the rapid growth of large language models (LLMs) and vision-language models (VLMs) in medicine, simply integrating clinical text and medical imaging does not guarantee reliable reasoning. Existing multimodal models often produce hallucinations or inconsistent chains of thought, limiting clinical trust. We propose a diagnostic framework built upon LLaVA that combines vision-language alignment with logic-regularized reasoning. The system includes an input encoder for text and images, a projection module for cross-modal alignment, a reasoning controller that decomposes diagnostic tasks into steps, and a logic tree generator that assembles stepwise premises into verifiable conclusions. Evaluations on MedXpertQA and other benchmarks show that our method improves diagnostic accuracy and yields more interpretable reasoning traces on multimodal tasks, while remaining competitive on text-only settings. These results suggest a promising step toward trustworthy multimodal medical AI.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.21663", "categories": ["cs.CR", "cs.ET"], "pdf": "https://arxiv.org/pdf/2512.21663", "abs": "https://arxiv.org/abs/2512.21663", "authors": ["Aditya Mitra", "Sibi Chakkaravarthy Sethuraman"], "title": "Verifiable Passkey: The Decentralized Authentication Standard", "comment": null, "summary": "Passwordless authentication has revolutionized the way we authenticate across various websites and services. FIDO2 Passkeys, is one of the most-widely adopted standards of passwordless authentication that promises phishing-resistance. However, like any other authentication system, passkeys require the user details to be saved on a centralized server, also known as Relying Party (RP) Server. This has led users to create a new passkey for every new online account. While this just works for a limited number of online accounts, the limited storage space of secure storage modules like TPM or a physical security key limits the number of passkeys a user can have. For example, Yubico Yubikey 5 (firmware 5.0 - 5.6) offers to store only 25 passkeys, while firmware 5.7+ allows to store upto 100 [1]. To overcome this problem, one of the widely adopted approaches is to use Federated Authentication with Single Sign On (SSO). This allows the user to create a passkey for the Identity Provider (IdP) and use the IdP to authenticate to all service providers. This proves to be a significant privacy risk since the IdP can potentially track users across different services. To overcome these limitations, this paper introduces a novel standard 'Verifiable Passkey' that allows the user to use Passkeys created for a Verifiable Credential issuer across any platform without risking privacy or user tracking.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.21681", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.21681", "abs": "https://arxiv.org/abs/2512.21681", "authors": ["Tian Li", "Bo Lin", "Shangwen Wang", "Yusong Tan"], "title": "Exploring the Security Threats of Retriever Backdoors in Retrieval-Augmented Code Generation", "comment": null, "summary": "Retrieval-Augmented Code Generation (RACG) is increasingly adopted to enhance Large Language Models for software development, yet its security implications remain dangerously underexplored. This paper conducts the first systematic exploration of a critical and stealthy threat: backdoor attacks targeting the retriever component, which represents a significant supply-chain vulnerability. It is infeasible to assess this threat realistically, as existing attack methods are either too ineffective to pose a real danger or are easily detected by state-of-the-art defense mechanisms spanning both latent-space analysis and token-level inspection, which achieve consistently high detection rates. To overcome this barrier and enable a realistic analysis, we first developed VenomRACG, a new class of potent and stealthy attack that serves as a vehicle for our investigation. Its design makes poisoned samples statistically indistinguishable from benign code, allowing the attack to consistently maintain low detectability across all evaluated defense mechanisms. Armed with this capability, our exploration reveals a severe vulnerability: by injecting vulnerable code equivalent to only 0.05% of the entire knowledge base size, an attacker can successfully manipulate the backdoored retriever to rank the vulnerable code in its top-5 results in 51.29% of cases. This translates to severe downstream harm, causing models like GPT-4o to generate vulnerable code in over 40% of targeted scenarios, while leaving the system's general performance intact. Our findings establish that retriever backdooring is not a theoretical concern but a practical threat to the software development ecosystem that current defenses are blind to, highlighting the urgent need for robust security measures.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.21623", "categories": ["cs.AI", "cs.MA", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2512.21623", "abs": "https://arxiv.org/abs/2512.21623", "authors": ["Takahide Suzuki", "Kazuki Nakanishi", "Takashi Fujiwara", "Hideyuki Shimizu"], "title": "Democratizing Drug Discovery with an Orchestrated, Knowledge-Driven Multi-Agent Team for User-Guided Therapeutic Design", "comment": "51 pages, 4 figures (with supplementary information)", "summary": "Therapeutic discovery remains a formidable challenge, impeded by the fragmentation of specialized domains and the execution gap between computational design and physiological validation. Although generative AI offers promise, current models often function as passive assistants rather than as autonomous executors. Here, we introduce OrchestRA, a human-in-the-loop multi-agent platform that unifies biology, chemistry, and pharmacology into an autonomous discovery engine. Unlike static code generators, our agents actively execute simulations and reason the results to drive iterative optimization. Governed by an Orchestrator, a Biologist Agent leverages deep reasoning over a massive knowledge graph (>10 million associations) to pinpoint high-confidence targets; a Chemist Agent autonomously detects structural pockets for de novo design or drug repositioning; and a Pharmacologist Agent evaluates candidates via rigorous physiologically based pharmacokinetic (PBPK) simulations. This architecture establishes a dynamic feedback loop where pharmacokinetic and toxicity profiles directly trigger structural reoptimization. By seamlessly integrating autonomous execution with human guidance, OrchestRA democratizes therapeutic design, transforming drug discovery from a stochastic search to a programmable evidence-based engineering discipline.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.21698", "categories": ["cs.CR", "cs.MM", "eess.IV"], "pdf": "https://arxiv.org/pdf/2512.21698", "abs": "https://arxiv.org/abs/2512.21698", "authors": ["A V Uday Kiran Kandala"], "title": "Raster Domain Text Steganography: A Unified Framework for Multimodal Secure Embedding", "comment": null, "summary": "This work introduces a unified raster domain steganographic framework, termed as the Glyph Perturbation Cardinality (GPC) framework, capable of embedding heterogeneous data such as text, images, audio, and video directly into the pixel space of rendered textual glyphs. Unlike linguistic or structural text based steganography, the proposed method operates exclusively after font rasterization, modifying only the bitmap produced by a deterministic text rendering pipeline. Each glyph functions as a covert encoding unit, where a payload value is expressed through the cardinality of minimally perturbed interior ink pixels. These minimal intensity increments remain visually imperceptible while forming a stable and decodable signal. The framework is demonstrated for text to text embedding and generalized to multimodal inputs by normalizing image intensities, audio derived scalar features, and video frame values into bounded integer sequences distributed across glyphs. Decoding is achieved by re-rasterizing the cover text, subtracting canonical glyph rasters, and recovering payload values via pixel count analysis. The approach is computationally lightweight, and grounded in deterministic raster behavior, enabling ordinary text to serve as a visually covert medium for multimodal data embedding.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.21626", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.21626", "abs": "https://arxiv.org/abs/2512.21626", "authors": ["Hong Xie", "Haoran Gu", "Yanying Huang", "Tao Tan", "Defu Lian"], "title": "Multiple-play Stochastic Bandits with Prioritized Arm Capacity Sharing", "comment": "17 pages", "summary": "This paper proposes a variant of multiple-play stochastic bandits tailored to resource allocation problems arising from LLM applications, edge intelligence, etc. The model is composed of $M$ arms and $K$ plays. Each arm has a stochastic number of capacities, and each unit of capacity is associated with a reward function. Each play is associated with a priority weight. When multiple plays compete for the arm capacity, the arm capacity is allocated in a larger priority weight first manner. Instance independent and instance dependent regret lower bounds of $\u03a9( \u03b1_1 \u03c3\\sqrt{KM T} )$ and $\u03a9(\u03b1_1 \u03c3^2 \\frac{M}\u0394 \\ln T)$ are proved, where $\u03b1_1$ is the largest priority weight and $\u03c3$ characterizes the reward tail. When model parameters are given, we design an algorithm named \\texttt{MSB-PRS-OffOpt} to locate the optimal play allocation policy with a computational complexity of $O(MK^3)$. Utilizing \\texttt{MSB-PRS-OffOpt} as a subroutine, an approximate upper confidence bound (UCB) based algorithm is designed, which has instance independent and instance dependent regret upper bounds matching the corresponding lower bound up to factors of $ \\sqrt{K \\ln KT }$ and $\u03b1_1 K^2$ respectively. To this end, we address nontrivial technical challenges arising from optimizing and learning under a special nonlinear combinatorial utility function induced by the prioritized resource sharing mechanism.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.21737", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.21737", "abs": "https://arxiv.org/abs/2512.21737", "authors": ["Deepak", "Rahul Balout", "Anupam Golder", "Suparna Kundu", "Angshuman Karmakar", "Debayan Das"], "title": "Machine Learning Power Side-Channel Attack on SNOW-V", "comment": "This paper has already been accepted in the VLSID 2026 Conference", "summary": "This paper demonstrates a power analysis-based Side-Channel Analysis (SCA) attack on the SNOW-V encryption algorithm, which is a 5G mobile communication security standard candidate. Implemented on an STM32 microcontroller, power traces captured with a ChipWhisperer board were analyzed, with Test Vector Leakage Assessment (TVLA) confirming exploitable leakage. Profiling attacks using Linear Discriminant Analysis (LDA) and Fully Connected Neural Networks (FCN) achieved efficient key recovery, with FCN achieving > 5X lower minimum traces to disclosure (MTD) compared to the state-of-the-art Correlational Power Analysis (CPA) assisted with LDA. The results highlight the vulnerability of SNOW-V to machine learning-based SCA and the need for robust countermeasures.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.21699", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.21699", "abs": "https://arxiv.org/abs/2512.21699", "authors": ["Eranga Bandara", "Tharaka Hewa", "Ross Gore", "Sachin Shetty", "Ravi Mukkamala", "Peter Foytik", "Abdul Rahman", "Safdar H. Bouk", "Xueping Liang", "Amin Hass", "Sachini Rajapakse", "Ng Wee Keong", "Kasun De Zoysa", "Aruna Withanage", "Nilaan Loganathan"], "title": "Towards Responsible and Explainable AI Agents with Consensus-Driven Reasoning", "comment": null, "summary": "Agentic AI represents a major shift in how autonomous systems reason, plan, and execute multi-step tasks through the coordination of Large Language Models (LLMs), Vision Language Models (VLMs), tools, and external services. While these systems enable powerful new capabilities, increasing autonomy introduces critical challenges related to explainability, accountability, robustness, and governance, especially when agent outputs influence downstream actions or decisions. Existing agentic AI implementations often emphasize functionality and scalability, yet provide limited mechanisms for understanding decision rationale or enforcing responsibility across agent interactions. This paper presents a Responsible(RAI) and Explainable(XAI) AI Agent Architecture for production-grade agentic workflows based on multi-model consensus and reasoning-layer governance. In the proposed design, a consortium of heterogeneous LLM and VLM agents independently generates candidate outputs from a shared input context, explicitly exposing uncertainty, disagreement, and alternative interpretations. A dedicated reasoning agent then performs structured consolidation across these outputs, enforcing safety and policy constraints, mitigating hallucinations and bias, and producing auditable, evidence-backed decisions. Explainability is achieved through explicit cross-model comparison and preserved intermediate outputs, while responsibility is enforced through centralized reasoning-layer control and agent-level constraints. We evaluate the architecture across multiple real-world agentic AI workflows, demonstrating that consensus-driven reasoning improves robustness, transparency, and operational trust across diverse application domains. This work provides practical guidance for designing agentic AI systems that are autonomous and scalable, yet responsible and explainable by construction.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.21762", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.21762", "abs": "https://arxiv.org/abs/2512.21762", "authors": ["Kurtis Chow", "Omar Samiullah", "Vinesh Sridhar", "Hewen Zhang"], "title": "Assessing the Effectiveness of Membership Inference on Generative Music", "comment": "10 pages, 3 figures, 3 tables", "summary": "Generative AI systems are quickly improving, now able to produce believable output in several modalities including images, text, and audio. However, this fast development has prompted increased scrutiny concerning user privacy and the use of copyrighted works in training. A recent attack on machine-learning models called membership inference lies at the crossroads of these two concerns. The attack is given as input a set of records and a trained model and seeks to identify which of those records may have been used to train the model. On one hand, this attack can be used to identify user data used to train a model, which may violate their privacy especially in sensitive applications such as models trained on medical data. On the other hand, this attack can be used by rights-holders as evidence that a company used their works without permission to train a model.\n  Remarkably, it appears that no work has studied the effect of membership inference attacks (MIA) on generative music. Given that the music industry is worth billions of dollars and artists would stand to gain from being able to determine if their works were being used without permission, we believe this is a pressing issue to study. As such, in this work we begin a preliminary study into whether MIAs are effective on generative music. We study the effect of several existing attacks on MuseGAN, a popular and influential generative music model. Similar to prior work on generative audio MIAs, our findings suggest that music data is fairly resilient to known membership inference techniques.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.21775", "categories": ["cs.AI", "cs.CY", "cs.DB"], "pdf": "https://arxiv.org/pdf/2512.21775", "abs": "https://arxiv.org/abs/2512.21775", "authors": ["Matyas Bohacek", "Ignacio Vilanova Echavarri"], "title": "Compliance Rating Scheme: A Data Provenance Framework for Generative AI Datasets", "comment": null, "summary": "Generative Artificial Intelligence (GAI) has experienced exponential growth in recent years, partly facilitated by the abundance of large-scale open-source datasets. These datasets are often built using unrestricted and opaque data collection practices. While most literature focuses on the development and applications of GAI models, the ethical and legal considerations surrounding the creation of these datasets are often neglected. In addition, as datasets are shared, edited, and further reproduced online, information about their origin, legitimacy, and safety often gets lost. To address this gap, we introduce the Compliance Rating Scheme (CRS), a framework designed to evaluate dataset compliance with critical transparency, accountability, and security principles. We also release an open-source Python library built around data provenance technology to implement this framework, allowing for seamless integration into existing dataset-processing and AI training pipelines. The library is simultaneously reactive and proactive, as in addition to evaluating the CRS of existing datasets, it equally informs responsible scraping and construction of new datasets.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.21813", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.21813", "abs": "https://arxiv.org/abs/2512.21813", "authors": ["Nimra Akram", "Atif Ahmad", "Sean B Maynard"], "title": "Organizational Learning in Industry 4.0: Applying Crossan's 4I Framework with Double Loop Learning", "comment": "10 pages", "summary": "The Advanced Dynamic Security Learning (DSL) Process Model is an Industry 4.0 cybersecurity incident response architecture proposed in this paper. This model addresses proactive and reflective cybersecurity governance across complex cyber-physical systems by combining Argyris and Sch\u00f6n's double-loop learning theory with Crossan's 4I organizational learning framework. Given that 65% of industrial companies suffer ransomware attacks annually and many of them lack cybersecurity awareness, this reveals the gravity of cyber threats. Feedforward and feedback learning loops in this paradigm help promote strategic transformation and ongoing growth. The DSL model helps Industry 4.0 organizations adapt to growing challenges posed by the projected 18.8 billion IoT devices by bridging operational obstacles and promoting systemic resilience. This research presents a scalable, methodical cybersecurity maturity approach based on a comprehensive analysis of the literature and a qualitative study.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.21782", "categories": ["cs.AI", "cond-mat.mtrl-sci", "cs.LG", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2512.21782", "abs": "https://arxiv.org/abs/2512.21782", "authors": ["Yuanqi Du", "Botao Yu", "Tianyu Liu", "Tony Shen", "Junwu Chen", "Jan G. Rittig", "Kunyang Sun", "Yikun Zhang", "Zhangde Song", "Bo Zhou", "Cassandra Masschelein", "Yingze Wang", "Haorui Wang", "Haojun Jia", "Chao Zhang", "Hongyu Zhao", "Martin Ester", "Teresa Head-Gordon", "Carla P. Gomes", "Huan Sun", "Chenru Duan", "Philippe Schwaller", "Wengong Jin"], "title": "Accelerating Scientific Discovery with Autonomous Goal-evolving Agents", "comment": null, "summary": "There has been unprecedented interest in developing agents that expand the boundary of scientific discovery, primarily by optimizing quantitative objective functions specified by scientists. However, for grand challenges in science , these objectives are only imperfect proxies. We argue that automating objective function design is a central, yet unmet requirement for scientific discovery agents. In this work, we introduce the Scientific Autonomous Goal-evolving Agent (SAGA) to amend this challenge. SAGA employs a bi-level architecture in which an outer loop of LLM agents analyzes optimization outcomes, proposes new objectives, and converts them into computable scoring functions, while an inner loop performs solution optimization under the current objectives. This bi-level design enables systematic exploration of the space of objectives and their trade-offs, rather than treating them as fixed inputs. We demonstrate the framework through a broad spectrum of applications, including antibiotic design, inorganic materials design, functional DNA sequence design, and chemical process design, showing that automating objective formulation can substantially improve the effectiveness of scientific discovery agents.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.21827", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.21827", "abs": "https://arxiv.org/abs/2512.21827", "authors": ["Xuanyu Chen", "Yue Zheng", "Junqing Zhang", "Guanxiong Shen", "Chip-Hong Chang"], "title": "Securing Cross-Domain Internet of Drones: An RFF-PUF Allied Authenticated Key Exchange Protocol With Over-the-Air Enrollment", "comment": null, "summary": "The Internet of Drones (IoD) is an emerging and crucial paradigm enabling advanced applications that require seamless, secure communication across heterogeneous and untrusted domains. In such environments, access control and the transmission of sensitive data pose significant security challenges for IoD systems, necessitating the design of lightweight mutual authentication and key exchange protocols. Existing solutions are often hampered by high computation overhead, reliance on third parties, the requirement for secret storage in resource-constrained drones, and the need for a strictly controlled enrollment environment. These limitations make them impractical for dynamic cross-domain deployment. To address these limitations, we propose a lightweight mutual authentication mechanism that integrates Radio Frequency Fingerprint (RFF) and Physical Unclonable Function (PUF) technologies for secure drone-to-drone (D2D) and drone-to-ground station server (D2G) communication. RFF-based device identification is used to achieve over-the-air (OTA) enrollment, while the PUF serves as the root of trust for establishing mutual authentication among communication parties. Additionally, the on-the-fly key generation capability of the PUF is co-designed with One-Time-Pad (OTP) encryption to realize ephemeral keying and eliminate the need for storing secrets within drones. Both informal security analysis and ProVerif-based formal security verification comprehensively demonstrate the resilience of our protocol against common security attacks. The proposed protocol also outperforms existing IoD authentication schemes in terms of security features, as well as computation, communication, and storage overhead.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.21907", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.21907", "abs": "https://arxiv.org/abs/2512.21907", "authors": ["Kenny Workman", "Zhen Yang", "Harihara Muralidharan", "Hannah Le"], "title": "SpatialBench: Can Agents Analyze Real-World Spatial Biology Data?", "comment": "10 pages, 9 figures, 4 tables; NeurIPS 2024 format", "summary": "Spatial transcriptomics assays are rapidly increasing in scale and complexity, making computational analysis a major bottleneck in biological discovery. Although frontier AI agents have improved dramatically at software engineering and general data analysis, it remains unclear whether they can extract biological insight from messy, real-world spatial datasets. We introduce SpatialBench, a benchmark of 146 verifiable problems derived from practical spatial analysis workflows spanning five spatial technologies and seven task categories. Each problem provides a snapshot of experimental data immediately prior to an analysis step and a deterministic grader that evaluates recovery of a key biological result. Benchmark data on frontier models shows that base model accuracy remains low (20-38% across model families), with strong model-task and model-platform interactions. Harness design has a large empirical effect on performance, indicating that tools, prompts, control flow, and execution environment should be evaluated and improved as first-class objects. SpatialBench serves both as a measurement tool and a diagnostic lens for developing agents that can interact with real spatial datasets faithfully, transparently, and reproducibly.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.22106", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.22106", "abs": "https://arxiv.org/abs/2512.22106", "authors": ["Zubair Shah", "Noaman Khan"], "title": "Pruning as a Game: Equilibrium-Driven Sparsification of Neural Networks", "comment": "Preprint. Under review / to be submitted to a conference", "summary": "Neural network pruning is widely used to reduce model size and computational cost. Yet, most existing methods treat sparsity as an externally imposed constraint, enforced through heuristic importance scores or training-time regularization. In this work, we propose a fundamentally different perspective: pruning as an equilibrium outcome of strategic interaction among model components. We model parameter groups such as weights, neurons, or filters as players in a continuous non-cooperative game, where each player selects its level of participation in the network to balance contribution against redundancy and competition. Within this formulation, sparsity emerges naturally when continued participation becomes a dominated strategy at equilibrium. We analyze the resulting game and show that dominated players collapse to zero participation under mild conditions, providing a principled explanation for pruning behavior. Building on this insight, we derive a simple equilibrium-driven pruning algorithm that jointly updates network parameters and participation variables without relying on explicit importance scores. This work focuses on establishing a principled formulation and empirical validation of pruning as an equilibrium phenomenon, rather than exhaustive architectural or large-scale benchmarking. Experiments on standard benchmarks demonstrate that the proposed approach achieves competitive sparsity-accuracy trade-offs while offering an interpretable, theory-grounded alternative to existing pruning methods.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.22090", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.22090", "abs": "https://arxiv.org/abs/2512.22090", "authors": ["Quentin Michaud", "Sara Ramezanian", "Dhouha Ayed", "Olivier Levillain", "Joaquin Garcia-Alfaro"], "title": "Abstraction of Trusted Execution Environments as the Missing Layer for Broad Confidential Computing Adoption: A Systematization of Knowledge", "comment": null, "summary": "Trusted Execution Environments (TEEs) protect sensitive code and data from the operating system, hypervisor, or other untrusted software. Different solutions exist, each proposing different features. Abstraction layers aim to unify the ecosystem, allowing application developers and system administrators to leverage confidential computing as broadly and efficiently as possible. We start with an overview of representative available TEE technologies. We describe and summarize each TEE ecosystem, classifying them in different categories depending on their main design choices. Then, we propose a systematization of knowledge focusing on different abstraction layers around each design choice. We describe the underlying technologies of each design, as well as the inner workings and features of each abstraction layer. Our study reveals opportunities for improving existing abstraction layer solutions. It also highlights WebAssembly, a promising approach that supports the largest set of features. We close with a discussion on future directions for research, such as how future abstraction layers may evolve and integrate with the confidential computing ecosystem.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
