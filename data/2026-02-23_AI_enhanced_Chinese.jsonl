{"id": "2602.17805", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.17805", "abs": "https://arxiv.org/abs/2602.17805", "authors": ["Andr\u00e9 Augusto", "Christof Ferreira Torres", "Andr\u00e9 Vasconcelos", "Miguel Correia"], "title": "Exploiting Liquidity Exhaustion Attacks in Intent-Based Cross-Chain Bridges", "comment": "13 pages, 11 figures", "summary": "Intent-based cross-chain bridges have emerged as an alternative to traditional interoperability protocols by allowing off-chain entities (\\emph{solvers}) to immediately fulfill users' orders by fronting their own liquidity. While improving user experience, this approach introduces new systemic risks, such as solver liquidity concentration and delayed settlement. In this paper, we propose a new class of attacks called \\emph{liquidity exhaustion attacks} and a replay-based parameterized attack simulation framework. We analyze 3.5 million cross-chain intents that moved \\$9.24B worth of tokens between June and November 2025 across three major protocols (Mayan Swift, Across, and deBridge), spanning nine blockchains.\n  For rational attackers, our results show that protocols with higher solver profitability, such as deBridge, are vulnerable under current parameters: 210 historical attack instances yield a mean net profit of \\$286.14, with 80.5\\% of attacks profitable. In contrast, Across remains robust in all tested configurations due to low solver margins and very high liquidity, while Mayan Swift is generally secure but becomes vulnerable under stress-test conditions. Under byzantine attacks, we show that it is possible to suppress availability across all protocols, causing dozens of failed intents and solver profit losses of up to \\$978 roughly every 16 minutes. Finally, we propose an optimized attack strategy that exploits patterns in the data to reduce attack costs by up to 90.5\\% compared to the baseline, lowering the barrier to liquidity exhaustion attacks.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4e86\u8de8\u94fe\u8ba2\u5355\u586b\u5145\u534f\u8bae\u4e2d\u7684\u6d41\u52a8\u6027\u8017\u5c3d\u653b\u51fb\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53c2\u6570\u7684\u91cd\u64ad\u653b\u51fb\u6a21\u62df\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u4e0d\u540c\u534f\u8bae\u5728\u4e0d\u540c\u653b\u51fb\u6761\u4ef6\u4e0b\u7684\u8106\u5f31\u6027\u3002", "motivation": "\u4e3a\u4e86\u63ed\u793a\u589e\u91cf\u94fe\u6865\u5e26\u6765\u7684\u65b0\u578b\u7cfb\u7edf\u6027\u98ce\u9669\uff0c\u5982\u6d41\u52a8\u6027\u96c6\u4e2d\u548c\u7ed3\u7b97\u5ef6\u8fdf\uff0c\u5e76\u8bc4\u4f30\u5b83\u4eec\u5728\u653b\u51fb\u4e0b\u7684\u8868\u73b0\u3002", "method": "\u901a\u8fc7\u6a21\u62df\u5404\u79cd\u653b\u51fb\uff0c\u5206\u6790\u5927\u89c4\u6a21\u7684\u771f\u5b9e\u8ba2\u5355\u6570\u636e\uff0c\u5305\u62ec\u8ba1\u7b97\u653b\u51fb\u6210\u672c\u548c\u8bc4\u4f30\u534f\u8bae\u5b89\u5168\u6027\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5177\u6709\u8f83\u9ad8\u89e3\u7b97\u5546\u5229\u6da6\u7684\u534f\u8bae\u5728\u5f53\u524d\u53c2\u6570\u4e0b\u5bb9\u6613\u906d\u53d7\u6d41\u52a8\u6027\u8017\u5c3d\u653b\u51fb\uff1bAcross\u534f\u8bae\u8868\u73b0\u51fa\u8f83\u9ad8\u5b89\u5168\u6027\uff0c\u800cMayan Swift\u5728\u538b\u529b\u6d4b\u8bd5\u4e2d\u53d8\u5f97\u8106\u5f31\u3002\u540c\u65f6\uff0c\u7814\u7a76\u5c55\u793a\u4e86\u5728\u62dc\u5360\u5ead\u653b\u51fb\u4e0b\uff0c\u6240\u6709\u534f\u8bae\u90fd\u53ef\u80fd\u906d\u53d7\u5e7f\u6cdb\u53ef\u7528\u6027\u635f\u5931\uff0c\u5bfc\u81f4\u5927\u91cf\u5931\u8d25\u7684\u8de8\u94fe\u8ba2\u5355\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4f18\u5316\u7684\u653b\u51fb\u7b56\u7565\uff0c\u5229\u7528\u6570\u636e\u6a21\u5f0f\u964d\u4f4e\u6210\u672c\uff0c\u964d\u4f4e\u6d41\u52a8\u6027\u8017\u5c3d\u653b\u51fb\u7684\u95e8\u69db\u3002"}}
{"id": "2602.17900", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.17900", "abs": "https://arxiv.org/abs/2602.17900", "authors": ["Victor Duarte Melo"], "title": "Symfrog-512: High-Capacity Sponge-Based AEAD Cipher (1024-bit State)", "comment": "This work presents Symfrog-512, a sponge-based AEAD scheme with a 1024-bit permutation. A full specification, rationale, and reference implementation are included. The submission is exploratory and intended for public review and community cryptanalysis", "summary": "This submission includes a complete reference implementation together with deterministic test vectors and a reproducible benchmark suite. All source code, build instructions, and regression artifacts are publicly available in the project repository, enabling independent verification and reimplementation of the scheme. The AEAD construction is fully specified, including domain separation, rate and capacity choices, tag generation, and the exact file format used by the reference CLI. Reported performance numbers are produced by the built in benchmark tool under documented hardware and compiler settings. All security claims are made strictly within the ideal permutation model following standard sponge and duplex bounds, and no stronger guarantees are asserted for the concrete permutation beyond the documented analysis and empirical behavior. The implementation aims for constant time behavior with respect to secret dependent operations, although no formal side channel proof is provided. The project is released under the MIT license, and external cryptanalysis, feedback, and reproducibility checks are explicitly encouraged.", "AI": {"tldr": "\u672c\u63d0\u4ea4\u9644\u5e26\u4e86\u5b8c\u6574\u7684\u53c2\u8003\u5b9e\u73b0\u3001\u786e\u5b9a\u6027\u6d4b\u8bd5\u5411\u91cf\u548c\u53ef\u91cd\u590d\u7684\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\uff0c\u6240\u6709\u6e90\u4ee3\u7801\u548c\u6784\u5efa\u8bf4\u660e\u5747\u5df2\u5728\u9879\u76ee\u4ed3\u5e93\u4e2d\u516c\u5f00\u3002\u6027\u80fd\u6570\u636e\u5728\u7279\u5b9a\u786c\u4ef6\u548c\u7f16\u8bd1\u5668\u8bbe\u7f6e\u4e0b\u7531\u5185\u7f6e\u57fa\u51c6\u5de5\u5177\u751f\u6210\u3002\u9879\u76ee\u9075\u5faaMIT\u8bb8\u53ef\u8bc1\u53d1\u5e03\uff0c\u5e76\u6b22\u8fce\u5916\u90e8\u52a0\u5bc6\u5206\u6790\u3001\u53cd\u9988\u53ca\u91cd\u73b0\u5df2\u884c\u6027\u68c0\u67e5\u3002", "motivation": "\u672c\u6587\u7684\u4e3b\u8981\u52a8\u673a\u662f\u63d0\u4f9b\u4e00\u4e2a\u5b8c\u6574\u7684\u53c2\u8003\u5b9e\u73b0\uff0c\u4ee5\u53ca\u786e\u4fdd\u7ed3\u679c\u7684\u53ef\u9a8c\u8bc1\u6027\u548c\u91cd\u73b0\u5b9e\u9a8c\u6027\uff0c\u540c\u65f6\u660e\u786e\u58f0\u660e\u5b89\u5168\u65ad\u8a00\u4ec5\u9650\u4e8e\u7406\u60f3\u7f6e\u6362\u6a21\u578b\uff0c\u5e76\u5f3a\u8c03\u5728\u672a\u63d0\u4f9b\u6b63\u5f0f\u9632\u4fa7\u4fe1\u9053\u8bc1\u660e\u7684\u60c5\u51b5\u4e0b\uff0c\u65e8\u5728\u5b9e\u73b0\u79d8\u5bc6\u4f9d\u8d56\u64cd\u4f5c\u7684\u5e38\u91cf\u65f6\u95f4\u884c\u4e3a\u3002", "method": "\u8be5\u65b9\u6cd5\u5305\u62ec\u5b8c\u6574\u7684\u4ee3\u7801\u5b9e\u73b0\u3001\u6d4b\u8bd5\u5411\u91cf\u548c\u57fa\u51c6\u6d4b\u8bd5\u5de5\u5177\u3002\u6e90\u4ee3\u7801\u3001\u6784\u5efa\u6307\u5357\u548c\u56de\u5f52\u6570\u636e\u516c\u5f00\u5728\u9879\u76ee\u4ed3\u5e93\u4e2d\u3002\u6027\u80fd\u6570\u636e\u901a\u8fc7\u5185\u5efa\u7684\u57fa\u51c6\u5de5\u5177\u5728\u7279\u5b9a\u786c\u4ef6\u548c\u7f16\u8bd1\u5668\u8bbe\u7f6e\u4e0b\u751f\u6210\u3002", "result": "\u7ed3\u679c\u5c55\u793a\u4e86AEAD\u6784\u9020\u7684\u5b8c\u6574\u89c4\u8303\uff0c\u5305\u62ec\u57df\u5206\u79bb\u3001\u901f\u7387\u548c\u5bb9\u91cf\u9009\u62e9\u3001\u6807\u7b7e\u751f\u6210\u548c\u53c2\u8003\u547d\u4ee4\u884c\u754c\u9762\u7684\u6587\u4ef6\u683c\u5f0f\u3002\u6027\u80fd\u6570\u636e\u53cd\u6620\u4e86\u5728\u7ed9\u5b9a\u786c\u4ef6\u548c\u7f16\u8bd1\u5668\u914d\u7f6e\u4e0b\u7684\u5177\u4f53\u8868\u73b0\u3002\u5b89\u5168\u6027\u58f0\u660e\u4e25\u683c\u9650\u5b9a\u5728\u7406\u60f3\u7f6e\u6362\u6a21\u578b\u8303\u56f4\u5185\uff0c\u5e76\u672a\u505a\u51fa\u66f4\u5f3a\u7684\u7406\u8bba\u4fdd\u8bc1\u3002", "conclusion": "\u7ed3\u8bba\u662f\u8be5\u9879\u76ee\u7684\u5b9e\u73b0\u76ee\u6807\u662f\u79d8\u5bc6\u4f9d\u8d56\u64cd\u4f5c\u7684\u65f6\u95f4\u5e38\u91cf\u884c\u4e3a\uff0c\u5c3d\u7ba1\u672a\u63d0\u4f9b\u6b63\u5f0f\u7684\u4fa7\u4fe1\u9053\u5b89\u5168\u8bc1\u660e\u3002\u9879\u76ee\u4ee5MIT\u8bb8\u53ef\u8bc1\u5f00\u653e\uff0c\u5e76\u9f13\u52b1\u5916\u90e8\u7684\u52a0\u5bc6\u5206\u6790\u548c\u53cd\u9988\u3002"}}
{"id": "2602.17826", "categories": ["cs.AI", "cs.LG", "cs.SC"], "pdf": "https://arxiv.org/pdf/2602.17826", "abs": "https://arxiv.org/abs/2602.17826", "authors": ["Marcelo Labre"], "title": "Ontology-Guided Neuro-Symbolic Inference: Grounding Language Models with Mathematical Domain Knowledge", "comment": "Submitted to NeuS 2026. Supplementary materials and code: https://doi.org/10.5281/zenodo.18665030", "summary": "Language models exhibit fundamental limitations -- hallucination, brittleness, and lack of formal grounding -- that are particularly problematic in high-stakes specialist fields requiring verifiable reasoning. I investigate whether formal domain ontologies can enhance language model reliability through retrieval-augmented generation. Using mathematics as proof of concept, I implement a neuro-symbolic pipeline leveraging the OpenMath ontology with hybrid retrieval and cross-encoder reranking to inject relevant definitions into model prompts. Evaluation on the MATH benchmark with three open-source models reveals that ontology-guided context improves performance when retrieval quality is high, but irrelevant context actively degrades it -- highlighting both the promise and challenges of neuro-symbolic approaches.", "AI": {"tldr": "\u901a\u8fc7\u7ed3\u5408\u5f62\u5f0f\u9886\u57df\u672c\u4f53\uff0c\u7814\u7a76\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u795e\u7ecf\u7b26\u53f7\u7ba1\u9053\uff0c\u65e8\u5728\u63d0\u9ad8\u8bed\u8a00\u6a21\u578b\u5728\u9700\u8981\u53ef\u9a8c\u8bc1\u63a8\u7406\u7684\u4e13\u4e1a\u9886\u57df\u4e2d\u7684\u53ef\u9760\u6027\u3002\u867d\u7136\u76f8\u5173\u9886\u57df\u7684\u77e5\u8bc6\u80fd\u591f\u6539\u5584\u6a21\u578b\u6027\u80fd\uff0c\u4f46\u4e0d\u76f8\u5173\u7684\u80cc\u666f\u4fe1\u606f\u4f1a\u635f\u5bb3\u5176\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u5e7b\u89c9\u3001\u8106\u5f31\u6027\u548c\u7f3a\u4e4f\u5f62\u5f0f\u57fa\u7840\u7b49\u6839\u672c\u9650\u5236\uff0c\u5728\u9ad8\u98ce\u9669\u7684\u4e13\u4e1a\u9886\u57df\u4e2d\u5c24\u4e3a\u7a81\u51fa\uff0c\u8fd9\u4e9b\u9886\u57df\u9700\u8981\u53ef\u9a8c\u8bc1\u7684\u63a8\u7406\u3002\u7814\u7a76\u8005\u65e8\u5728\u63a2\u8ba8\u662f\u5426\u53ef\u4ee5\u901a\u8fc7\u5f15\u5165\u6b63\u5f0f\u9886\u57df\u7684\u672c\u4f53\u6765\u589e\u5f3a\u8bed\u8a00\u6a21\u578b\u7684\u53ef\u9760\u6027\u3002", "method": "\u7814\u7a76\u8005\u5229\u7528\u6570\u5b66\u9886\u57df\u4f5c\u4e3a\u6982\u5ff5\u9a8c\u8bc1\u573a\u666f\uff0c\u8bbe\u8ba1\u4e86\u4e00\u79cd\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u548c\u8de8\u7f16\u7801\u5668\u91cd\u6392\u5e8f\u7684\u795e\u7ecf\u7b26\u53f7\u7ba1\u9053\uff0c\u8be5\u7ba1\u9053\u5229\u7528\u4e86OpenMath\u672c\u4f53\uff0c\u4ee5\u6ce8\u5165\u4e0e\u4e4b\u76f8\u5173\u7684\u5b9a\u4e49\u81f3\u6a21\u578b\u63d0\u793a\u4e2d\u3002", "result": "\u5728MATH\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4f7f\u7528\u8fd9\u9879\u65b9\u6cd5\u6539\u8fdb\u4e0a\u4e0b\u6587\u6027\u80fd\u5728\u9ad8\u8d28\u91cf\u68c0\u7d22\u65f6\u6709\u6240\u63d0\u5347\uff0c\u4f46\u5728\u65e0\u5173\u80cc\u666f\u4e0b\u5219\u6548\u679c\u660e\u663e\u4e0b\u964d\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u672c\u4f53\u5bfc\u5411\u7684\u4e0a\u4e0b\u6587\u6709\u52a9\u4e8e\u63d0\u9ad8\u795e\u7ecf\u7b26\u53f7\u6a21\u578b\u7684\u6027\u80fd\uff0c\u4f46\u4e5f\u63ed\u793a\u4e86\u8fd9\u79cd\u65b9\u6cd5\u9762\u4e34\u7684\u6311\u6218\u3002"}}
{"id": "2602.17831", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17831", "abs": "https://arxiv.org/abs/2602.17831", "authors": ["Simon Henniger", "Gabriel Poesia"], "title": "The Token Games: Evaluating Language Model Reasoning with Puzzle Duels", "comment": "Project website: https://token-games.ai/", "summary": "Evaluating the reasoning capabilities of Large Language Models is increasingly challenging as models improve. Human curation of hard questions is highly expensive, especially in recent benchmarks using PhD-level domain knowledge to challenge the most capable models. Even then, there is always a concern about whether these questions test genuine reasoning or if similar problems have been seen during training. Here, we take inspiration from 16th-century mathematical duels to design The Token Games (TTG): an evaluation framework where models challenge each other by creating their own puzzles. We leverage the format of Programming Puzzles - given a Python function that returns a boolean, find inputs that make it return True - to flexibly represent problems and enable verifying solutions. Using results from pairwise duels, we then compute Elo ratings, allowing us to compare models relative to each other. We evaluate 10 frontier models on TTG, and closely match the ranking from existing benchmarks such as Humanity's Last Exam, without involving any human effort in creating puzzles. We also find that creating good puzzles is still a highly challenging task for current models, not measured by previous benchmarks. Overall, our work suggests new paradigms for evaluating reasoning that cannot be saturated by design, and that allow testing models for other skills like creativity and task creation alongside problem solving.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86The Token Games (TTG) \u6846\u67b6\uff0c\u8ba9\u5927\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u76f8\u4e92\u6311\u6218\u6765\u521b\u5efa\u548c\u89e3\u51b3\u95ee\u9898\uff0c\u4ee5\u6b64\u8bc4\u4f30\u5b83\u4eec\u7684\u63a8\u7406\u80fd\u529b\u3002\u7814\u7a76\u5c55\u793a\u4e8610\u79cd\u524d\u6cbf\u6a21\u578b\u7684\u8868\u73b0\uff0c\u5e76\u53d1\u73b0\u5373\u4f7f\u662f\u8fd9\u4e9b\u6a21\u578b\uff0c\u521b\u5efa\u597d\u7684\u8c1c\u9898\u4ecd\u7136\u662f\u4e00\u4e2a\u6781\u5177\u6311\u6218\u7684\u4efb\u52a1\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u51c6\u6d4b\u8bd5\u4f7f\u7528\u590d\u6742\u7684\u9886\u57df\u77e5\u8bc6\u6765\u6311\u6218\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u53ef\u80fd\u5b58\u5728\u8bad\u7ec3\u4e2d\u9047\u5230\u8fc7\u7c7b\u4f3c\u95ee\u9898\u7684\u504f\u89c1\u3002\u7814\u7a76\u8005\u501f\u9274\u5386\u53f2\u4e0a\u7684\u6570\u5b66\u5bf9\u51b3\uff0c\u521b\u9020\u4e86\u4e00\u4e2a\u65b0\u7684\u8bc4\u4ef7\u6846\u67b6\uff0c\u65e8\u5728\u66f4\u5168\u9762\u5730\u6d4b\u8bd5\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002", "method": "\u7814\u7a76\u8005\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u7f16\u7a0b\u8c1c\u9898\u7684\u6311\u6218\u673a\u5236\uff0c\u6a21\u578b\u901a\u8fc7\u521b\u5efa\u548c\u89e3\u51b3\u8fd9\u4e9b\u8c1c\u9898\u6765\u8fdb\u884c\u76f8\u4e92\u6311\u6218\u3002\u8c1c\u9898\u7684\u5f62\u5f0f\u4e3a\u7ed9\u5b9a\u4e00\u4e2a\u63a5\u6536\u5e03\u5c14\u503c\u7684Python\u51fd\u6570\uff0c\u627e\u5230\u4f7f\u5176\u8fd4\u56deTrue\u7684\u8f93\u5165\u3002\u7814\u7a76\u4f7f\u7528Elo\u8bc4\u7ea7\u4f53\u7cfb\u6765\u6bd4\u8f83\u6a21\u578b\u4e4b\u95f4\u7684\u76f8\u5bf9\u8868\u73b0\u3002", "result": "\u7814\u7a76\u5728TTG\u6846\u67b6\u4e0b\u6d4b\u8bd5\u4e8610\u79cd\u524d\u6cbf\u6a21\u578b\uff0c\u7ed3\u679c\u663e\u793a\u8fd9\u4e9b\u6a21\u578b\u7684\u76f8\u5bf9\u6392\u540d\u4e0e\u73b0\u6709\u57fa\u51c6\u4e00\u81f4\u3002\u540c\u65f6\uff0c\u7814\u7a76\u8fd8\u8868\u660e\uff0c\u5373\u4f7f\u662f\u8fd9\u4e9b\u5148\u8fdb\u6a21\u578b\uff0c\u521b\u9020\u9ad8\u8d28\u91cf\u8c1c\u9898\u4e5f\u4ecd\u7136\u662f\u4e00\u9879\u6311\u6218\u3002", "conclusion": "\u7814\u7a76\u63d0\u51fa\u7684\u65b0\u6846\u67b6TTG\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u7684\u8bc4\u4f30\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7684\u65b9\u6cd5\uff0c\u4e0d\u4ec5\u6d4b\u91cf\u4e86\u89e3\u51b3\u95ee\u9898\u7684\u80fd\u529b\uff0c\u8fd8\u8003\u5bdf\u4e86\u6a21\u578b\u7684\u521b\u9020\u529b\u548c\u4efb\u52a1\u751f\u6210\u7684\u80fd\u529b\u3002\u8fd9\u79cd\u65b9\u6cd5\u6709\u671b\u51cf\u5c11\u5bf9\u4eba\u5de5\u8bbe\u8ba1\u8c1c\u9898\u7684\u4f9d\u8d56\u3002"}}
{"id": "2602.18079", "categories": ["cs.CR", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.18079", "abs": "https://arxiv.org/abs/2602.18079", "authors": ["Masoud Jamshidiyan Tehrani", "Marco Gabriel", "Jinhan Kim", "Paolo Tonella"], "title": "Dynamic Deception: When Pedestrians Team Up to Fool Autonomous Cars", "comment": null, "summary": "Many adversarial attacks on autonomous-driving perception models fail to cause system-level failures once deployed in a full driving stack. The main reason for such ineffectiveness is that once deployed in a system (e.g., within a simulator), attacks tend to be spatially or temporally short-lived, due to the vehicle's dynamics, hence rarely influencing the vehicle behaviour. In this paper, we address both limitations by introducing a system-level attack in which multiple dynamic elements (e.g., two pedestrians) carry adversarial patches (e.g., on cloths) and jointly amplify their effect through coordination and motion. We evaluate our attacks in the CARLA simulator using a state-of-the-art autonomous driving agent. At the system level, single-pedestrian attacks fail in all runs (out of 10), while dynamic collusion by two pedestrians induces full vehicle stops in up to 50\\% of runs, with static collusion yielding no successful attack at all. These results show that system-level failures arise only when adversarial signals persist over time and are amplified through coordinated actors, exposing a gap between model-level robustness and end-to-end safety.", "AI": {"tldr": "\u6b64\u7814\u7a76\u901a\u8fc7\u5728\u6a21\u62df\u5668\u4e2d\u4f7f\u7528\u52a8\u6001\u534f\u4f5c\u7684\u591a\u4e2a\u76ee\u6807\uff08\u4f8b\u5982\u4e24\u540d\u884c\u4eba\uff09\u6765\u63d0\u5347\u9488\u5bf9\u81ea\u52a8\u9a7e\u9a76\u611f\u77e5\u6a21\u578b\u7684\u653b\u51fb\u6548\u679c\uff0c\u4ece\u800c\u9996\u6b21\u63ed\u793a\u4e86\u6a21\u578b\u7ea7\u9c81\u68d2\u6027\u4e0e\u7aef\u5230\u7aef\u5b89\u5168\u6027\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "motivation": "\u5f53\u524d\u81ea\u52a8\u9a7e\u9a76\u611f\u77e5\u6a21\u578b\u7684\u8bb8\u591a\u5bf9\u6297\u653b\u51fb\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u65e0\u6cd5\u5bfc\u81f4\u6574\u4f53\u7cfb\u7edf\u5d29\u6e83\uff0c\u4e3b\u8981\u662f\u56e0\u4e3a\u8fd9\u4e9b\u653b\u51fb\u5728\u73b0\u5b9e\u7cfb\u7edf\u4e2d\u901a\u5e38\u4f1a\u56e0\u4e3a\u8f66\u8f86\u7684\u52a8\u529b\u5b66\u6548\u5e94\u800c\u53d8\u5f97\u7a7a\u95f4\u6216\u65f6\u95f4\u4e0a\u5f88\u77ed\u6682\uff0c\u56e0\u6b64\u5f88\u5c11\u5f71\u54cd\u8f66\u8f86\u884c\u4e3a\u3002", "method": "\u7814\u7a76\u901a\u8fc7\u5728CARLA\u6a21\u62df\u5668\u4e2d\u4f7f\u7528\u4e00\u4e2a\u5305\u542b\u4e24\u4e2a\u884c\u4eba\u643a\u5e26\u542b\u6709\u5bf9\u6297\u6a21\u5f0f\u7684\u8863\u7269\u5e76\u534f\u540c\u884c\u52a8\u7684\u65b0\u65b9\u6cd5\uff0c\u4ee5\u9a8c\u8bc1\u9488\u5bf9\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684\u653b\u51fb\u6548\u679c\u3002", "result": "\u5355\u4e00\u884c\u4eba\u653b\u51fb\u5728\u6240\u6709\u8bd5\u9a8c\uff0810\u6b21\uff09\u4e2d\u5747\u672a\u6210\u529f\uff0c\u800c\u4e24\u540d\u884c\u4eba\u7684\u52a8\u6001\u534f\u4f5c\u653b\u51fb\u5bfc\u81f4\u8f66\u8f86\u5b8c\u5168\u505c\u6b62\u7684\u6bd4\u4f8b\u8fbe\u523050%\uff0c\u9759\u6b62\u534f\u4f5c\u7684\u76ee\u6807\u5219\u6ca1\u6709\u6210\u529f\u653b\u51fb\uff0c\u7814\u7a76\u6210\u679c\u8868\u660e\u4e86\u6301\u4e45\u7684\u5bf9\u6297\u4fe1\u53f7\u901a\u8fc7\u534f\u8c03\u884c\u4e3a\u5f97\u5230\u589e\u5f3a\u540e\u624d\u80fd\u5f15\u53d1\u6574\u4e2a\u7cfb\u7edf\u7684\u5931\u8d25\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u81ea\u52a8\u9a7e\u9a76\u5728\u6a21\u578b\u5c42\u9762\u5bf9\u6297\u653b\u51fb\u7684\u7a33\u5065\u6027\u4e0e\u7aef\u5230\u7aef\u5b89\u5168\u6027\u80fd\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u5f3a\u8c03\u4e86\u9488\u5bf9\u52a8\u6001\u534f\u4f5c\u653b\u51fb\u7684\u5b89\u5168\u6027\u95ee\u9898\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2602.18082", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.18082", "abs": "https://arxiv.org/abs/2602.18082", "authors": ["Diego Soi", "Silvia Lucia Sanna", "Lorenzo Pisu", "Leonardo Regano", "Giorgio Giacinto"], "title": "AndroWasm: an Empirical Study on Android Malware Obfuscation through WebAssembly", "comment": null, "summary": "In recent years, stealthy Android malware has increasingly adopted sophisticated techniques to bypass automatic detection mechanisms and harden manual analysis. Adversaries typically rely on obfuscation, anti-repacking, steganography, poisoning, and evasion techniques to AI-based tools, and in-memory execution to conceal malicious functionality.\n  In this paper, we investigate WebAssembly (Wasm) as a novel technique for hiding malicious payloads and evading traditional static analysis and signature-matching mechanisms. While Wasm is typically employed to render specific gaming activities and interact with the native components in web browsers, we provide an in-depth analysis on the mechanisms Android may employ to include Wasm modules in its execution pipeline. Additionally, we provide Proofs-of-Concept to demonstrate a threat model in which an attacker embeds and executes malicious routines, effectively bypassing IoC detection by industrial state-of-the-art tools, like VirusTotal and MobSF.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86WebAssembly\u4f5c\u4e3a\u4e00\u79cd\u65b0\u578b\u6280\u672f\uff0c\u7528\u4e8e\u9690\u85cf\u6076\u610f\u8f7d\u8377\u548c\u9003\u907f\u4f20\u7edf\u9759\u6001\u5206\u6790\u548c\u7b7e\u540d\u5339\u914d\u673a\u5236\uff0c\u63d0\u4f9bPoC\u5c55\u793a\u653b\u51fb\u8005\u5982\u4f55\u901a\u8fc7\u5c06\u6076\u610f\u529f\u80fd\u5d4c\u5165\u5e76\u6267\u884c\u6765\u7ed5\u8fc7\u5de5\u4e1a\u7ea7\u6700\u5148\u8fdb\u7684\u5de5\u5177\uff0c\u5982VirusTotal\u548cMobSF\u3002", "motivation": "\u867d\u7136WebAssembly\uff08Wasm\uff09\u901a\u5e38\u7528\u4e8e\u6e32\u67d3\u7279\u5b9a\u7684\u5a31\u4e50\u6d3b\u52a8\u5e76\u5728\u6d4f\u89c8\u5668\u4e2d\u4e0e\u539f\u751f\u7ec4\u4ef6\u4ea4\u4e92\uff0c\u4f46\u672c\u6587\u6df1\u5165\u5206\u6790\u4e86\u5176\u88abAndroid\u6076\u610f\u8f6f\u4ef6\u5229\u7528\u4ee5\u5305\u62ecWasm\u6a21\u5757\u5728\u5185\u7684\u6267\u884c\u7ba1\u9053\u4e2d\u7684\u673a\u5236\u3002\u9274\u4e8e\u5f53\u524d\u53cd\u75c5\u6bd2\u5de5\u5177\u5728\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u73b0\u6709\u6280\u672f\u65e0\u6cd5\u5b8c\u5168\u8bc6\u522bWasm\u5305\u88c5\u7684\u6076\u610f\u4ee3\u7801\uff0c\u56e0\u6b64\u63d0\u51fa\u65b0\u7684\u5a01\u80c1\u6a21\u578b\u4ee5\u5c55\u793a\u5982\u4f55\u9690\u85cf\u5e76\u6267\u884c\u6076\u610f\u529f\u80fd\u3002", "method": "\u901a\u8fc7\u5bf9WebAssembly\u548cAndroid\u6076\u610f\u8f6f\u4ef6\u6280\u672f\u7684\u6df1\u5165\u5206\u6790\uff0c\u7ed3\u5408\u5b9e\u4f8b\u8bc1\u660e\u653b\u51fb\u8005\u5982\u4f55\u5229\u7528WebAssembly\u7684\u7279\u6027\u8fdb\u884c\u6076\u610f\u884c\u4e3a\u3002", "result": "\u672c\u6587\u63ed\u793a\u4e86WebAssembly\u5982\u4f55\u88ab\u7528\u4e8e\u9690\u85cf\u6076\u610f\u4ee3\u7801\u6267\u884c\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u5a01\u80c1\u6a21\u578b\u4ee5\u8868\u660e\u73b0\u6709\u68c0\u6d4b\u6280\u672f\u53ef\u80fd\u65e0\u6cd5\u8bc6\u522b\u8fd9\u4e9b\u9690\u85cf\u7684\u6076\u610f\u4ee3\u7801\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u7814\u7a76\u65b0\u7684\u5206\u6790\u6280\u672f\u6765\u68c0\u6d4bWebAssembly\u4e2d\u6f5c\u5728\u6076\u610f\u884c\u4e3a\u7684\u91cd\u8981\u6027\uff0c\u4e3a\u62b5\u5fa1\u9ad8\u7ea7\u6301\u7eed\u7684\u5a01\u80c1\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\u3002"}}
{"id": "2602.17990", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17990", "abs": "https://arxiv.org/abs/2602.17990", "authors": ["Madhav Kanda", "Pedro Las-Casas", "Alok Gautam Kumbhare", "Rodrigo Fonseca", "Sharad Agarwal"], "title": "WorkflowPerturb: Calibrated Stress Tests for Evaluating Multi-Agent Workflow Metrics", "comment": null, "summary": "LLM-based systems increasingly generate structured workflows for complex tasks. In practice, automatic evaluation of these workflows is difficult, because metric scores are often not calibrated, and score changes do not directly communicate the severity of workflow degradation. We introduce WorkflowPerturb, a controlled benchmark for studying workflow evaluation metrics. It works by applying realistic, controlled perturbations to golden workflows. WorkflowPerturb contains 4,973 golden workflows and 44,757 perturbed variants across three perturbation types (Missing Steps, Compressed Steps, and Description Changes), each applied at severity levels of 10%, 30%, and 50%. We benchmark multiple metric families and analyze their sensitivity and calibration using expected score trajectories and residuals. Our results characterize systematic differences across metric families and support severity-aware interpretation of workflow evaluation scores. Our dataset will be released upon acceptance.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.18270", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.18270", "abs": "https://arxiv.org/abs/2602.18270", "authors": ["Kevin Hermann", "Sven Peldszus", "Thorsten Berger"], "title": "Many Tools, Few Exploitable Vulnerabilities: A Survey of 246 Static Code Analyzers for Security", "comment": null, "summary": "Static security analysis is a widely used technique for detecting software vulnerabilities across a wide range of weaknesses, application domains, and programming languages. While prior work surveyed static analyzes for specific weaknesses or application domains, no overview of the entire security landscape exists. We present a systematic literature review of 246 static security analyzers concerning their targeted vulnerabilities, application domains, analysis techniques, evaluation methods, and limitations. We observe that most analyzers focus on a limited set of weaknesses, that the vulnerabilities they detect are rarely exploitable, and that evaluations use custom benchmarks that are too small to enable robust assessment.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.18025", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.18025", "abs": "https://arxiv.org/abs/2602.18025", "authors": ["Haruki Abe", "Takayuki Osa", "Yusuke Mukuta", "Tatsuya Harada"], "title": "Cross-Embodiment Offline Reinforcement Learning for Heterogeneous Robot Datasets", "comment": "ICLR 2026", "summary": "Scalable robot policy pre-training has been hindered by the high cost of collecting high-quality demonstrations for each platform. In this study, we address this issue by uniting offline reinforcement learning (offline RL) with cross-embodiment learning. Offline RL leverages both expert and abundant suboptimal data, and cross-embodiment learning aggregates heterogeneous robot trajectories across diverse morphologies to acquire universal control priors. We perform a systematic analysis of this offline RL and cross-embodiment paradigm, providing a principled understanding of its strengths and limitations. To evaluate this offline RL and cross-embodiment paradigm, we construct a suite of locomotion datasets spanning 16 distinct robot platforms. Our experiments confirm that this combined approach excels at pre-training with datasets rich in suboptimal trajectories, outperforming pure behavior cloning. However, as the proportion of suboptimal data and the number of robot types increase, we observe that conflicting gradients across morphologies begin to impede learning. To mitigate this, we introduce an embodiment-based grouping strategy in which robots are clustered by morphological similarity and the model is updated with a group gradient. This simple, static grouping substantially reduces inter-robot conflicts and outperforms existing conflict-resolution methods.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.18285", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.18285", "abs": "https://arxiv.org/abs/2602.18285", "authors": ["Said Varlioglu", "Nelly Elsayed", "Murat Ozer", "Zag ElSayed", "John M. Emmert"], "title": "Detecting PowerShell-based Fileless Cryptojacking Attacks Using Machine Learning", "comment": "30 papges, Under Review", "summary": "With the emergence of remote code execution (RCE) vulnerabilities in ubiquitous libraries and advanced social engineering techniques, threat actors have started conducting widespread fileless cryptojacking attacks. These attacks have become effective with stealthy techniques based on PowerShell-based exploitation in Windows OS environments. Even if attacks are detected and malicious scripts removed, processes may remain operational on victim endpoints, creating a significant challenge for detection mechanisms. In this paper, we conducted an experimental study with a collected dataset on detecting PowerShell-based fileless cryptojacking scripts. The results showed that Abstract Syntax Tree (AST)-based fine-tuned CodeBERT achieved a high recall rate, proving the importance of the use of AST integration and fine-tuned pre-trained models for programming language.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.18304", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.18304", "abs": "https://arxiv.org/abs/2602.18304", "authors": ["Darsh Asher", "Farshad Dizani", "Joshua Kalyanapu", "Rosario Cammarota", "Aydin Aysu", "Samira Mirbagher Ajorpaz"], "title": "FeatureBleed: Inferring Private Enriched Attributes From Sparsity-Optimized AI Accelerators", "comment": "4 pages, 3 figures, 3 tables, Journal :- IEEE CAL", "summary": "Backend enrichment is now widely deployed in sensitive domains such as product recommendation pipelines, healthcare, and finance, where models are trained on confidential data and retrieve private features whose values influence inference behavior while remaining hidden from the API caller. This paper presents the first hardware-level backend retrieval data-stealing attack, showing that accelerator optimizations designed for performance can directly undermine data confidentiality and bypass state-of-the-art privacy defenses.\n  Our attack, FEATUREBLEED, exploits zero-skipping in AI accelerators to infer private backend-retrieved features solely through end-to-end timing, without relying on power analysis, DVFS manipulation, or shared-cache side channels. We evaluate FEATUREBLEED on three datasets spanning medical and non-medical domains: Texas-100X (clinical records), OrganAMNIST (medical imaging), and Census-19 (socioeconomic data). We further evaluate FEATUREBLEED across three hardware backends (Intel AVX, Intel AMX, and NVIDIA A100) and three model architectures (DNNs, CNNs, and hybrid CNN-MLP pipelines), demonstrating that the leakage generalizes across CPU and GPU accelerators, data modalities, and application domains, with an adversarial advantage of up to 98.87 percentage points.\n  Finally, we identify the root cause of the leakage as sparsity-driven zero-skipping in modern hardware. We quantify the privacy-performance-power trade-off: disabling zero-skipping increases Intel AMX per-operation energy by up to 25 percent and incurs 100 percent performance overhead. We propose a padding-based defense that masks timing leakage by equalizing responses to the worst-case execution time, achieving protection with only 7.24 percent average performance overhead and no additional power cost.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.18201", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.18201", "abs": "https://arxiv.org/abs/2602.18201", "authors": ["Joseph Bingham", "Netanel Arussy", "Dvir Aran"], "title": "SOMtime the World Ain$'$t Fair: Violating Fairness Using Self-Organizing Maps", "comment": "10 pages, 2 figures, preprint", "summary": "Unsupervised representations are widely assumed to be neutral with respect to sensitive attributes when those attributes are withheld from training. We show that this assumption is false. Using SOMtime, a topology-preserving representation method based on high-capacity Self-Organizing Maps, we demonstrate that sensitive attributes such as age and income emerge as dominant latent axes in purely unsupervised embeddings, even when explicitly excluded from the input. On two large-scale real-world datasets (the World Values Survey across five countries and the Census-Income dataset), SOMtime recovers monotonic orderings aligned with withheld sensitive attributes, achieving Spearman correlations of up to 0.85, whereas PCA and UMAP typically remain below 0.23 (with a single exception reaching 0.31), and against t-SNE and autoencoders which achieve at most 0.34. Furthermore, unsupervised segmentation of SOMtime embeddings produces demographically skewed clusters, demonstrating downstream fairness risks without any supervised task. These findings establish that \\textit{fairness through unawareness} fails at the representation level for ordinal sensitive attributes and that fairness auditing must extend to unsupervised components of machine learning pipelines. We have made the code available at~ https://github.com/JosephBingham/SOMtime", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.18370", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.18370", "abs": "https://arxiv.org/abs/2602.18370", "authors": ["Benjamin Dowling", "Prosanta Gope", "Mehr U Nisa", "Bhagya Wimalasiri"], "title": "Drawing the LINE: Cryptographic Analysis and Security Improvements for the LINE E2EE Protocol", "comment": null, "summary": "LINE has emerged as one of the most popular communication platforms in many East Asian countries, including Thailand and Japan, with millions of active users. Therefore, it is essential to understand its security guarantees. In this work, we present the first provable security analysis of the LINE version two (LINEv2) messaging protocol, focusing on its cryptographic guarantees in a real-world setting. We capture the architecture and security of the LINE messaging protocol by modifying the Multi-Stage Key Exchange (MSKE) model, a framework for analysing cryptographic protocols under adversarial conditions. While LINEv2 achieves basic security properties such as key indistinguishability and message authentication, we highlight the lack of forward secrecy (FS) and post-compromise security (PCS). To address this, we introduce a stronger version of the LINE protocol, introducing FS and PCS to LINE, analysing and benchmarking our results.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.18291", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.18291", "abs": "https://arxiv.org/abs/2602.18291", "authors": ["Zhuoran Li", "Hai Zhong", "Xun Wang", "Qingxin Xia", "Lihua Zhang", "Longbo Huang"], "title": "Diffusing to Coordinate: Efficient Online Multi-Agent Diffusion Policies", "comment": null, "summary": "Online Multi-Agent Reinforcement Learning (MARL) is a prominent framework for efficient agent coordination. Crucially, enhancing policy expressiveness is pivotal for achieving superior performance. Diffusion-based generative models are well-positioned to meet this demand, having demonstrated remarkable expressiveness and multimodal representation in image generation and offline settings. Yet, their potential in online MARL remains largely under-explored. A major obstacle is that the intractable likelihoods of diffusion models impede entropy-based exploration and coordination. To tackle this challenge, we propose among the first \\underline{O}nline off-policy \\underline{MA}RL framework using \\underline{D}iffusion policies (\\textbf{OMAD}) to orchestrate coordination. Our key innovation is a relaxed policy objective that maximizes scaled joint entropy, facilitating effective exploration without relying on tractable likelihood. Complementing this, within the centralized training with decentralized execution (CTDE) paradigm, we employ a joint distributional value function to optimize decentralized diffusion policies. It leverages tractable entropy-augmented targets to guide the simultaneous updates of diffusion policies, thereby ensuring stable coordination. Extensive evaluations on MPE and MAMuJoCo establish our method as the new state-of-the-art across $10$ diverse tasks, demonstrating a remarkable $2.5\\times$ to $5\\times$ improvement in sample efficiency.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.07152", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07152", "abs": "https://arxiv.org/abs/2602.07152", "authors": ["Kristopher W. Reese", "Taylor Kulp-McDowall", "Michael Majurski", "Tim Blattner", "Derek Juba", "Peter Bajcsy", "Antonio Cardone", "Philippe Dessauw", "Alden Dima", "Anthony J. Kearsley", "Melinda Kleczynski", "Joel Vasanth", "Walid Keyrouz", "Chace Ashcraft", "Neil Fendley", "Ted Staley", "Trevor Stout", "Josh Carney", "Greg Canal", "Will Redman", "Aurora Schmidt", "Cameron Hickert", "William Paul", "Jared Markowitz", "Nathan Drenkow", "David Shriver", "Marissa Connor", "Keltin Grimes", "Marco Christiani", "Hayden Moore", "Jordan Widjaja", "Kasimir Gabert", "Uma Balakrishnan", "Satyanadh Gundimada", "John Jacobellis", "Sandya Lakkur", "Vitus Leung", "Jon Roose", "Casey Battaglino", "Farinaz Koushanfar", "Greg Fields", "Xihe Gu", "Yaman Jandali", "Xinqiao Zhang", "Akash Vartak", "Tim Oates", "Ben Erichson", "Michael Mahoney", "Rauf Izmailov", "Xiangyu Zhang", "Guangyu Shen", "Siyuan Cheng", "Shiqing Ma", "XiaoFeng Wang", "Haixu Tang", "Di Tang", "Xiaoyi Chen", "Zihao Wang", "Rui Zhu", "Susmit Jha", "Xiao Lin", "Manoj Acharya", "Wenchao Li", "Chao Chen"], "title": "Trojans in Artificial Intelligence (TrojAI) Final Report", "comment": null, "summary": "The Intelligence Advanced Research Projects Activity (IARPA) launched the TrojAI program to confront an emerging vulnerability in modern artificial intelligence: the threat of AI Trojans. These AI trojans are malicious, hidden backdoors intentionally embedded within an AI model that can cause a system to fail in unexpected ways, or allow a malicious actor to hijack the AI model at will. This multi-year initiative helped to map out the complex nature of the threat, pioneered foundational detection methods, and identified unsolved challenges that require ongoing attention by the burgeoning AI security field. This report synthesizes the program's key findings, including methodologies for detection through weight analysis and trigger inversion, as well as approaches for mitigating Trojan risks in deployed models. Comprehensive test and evaluation results highlight detector performance, sensitivity, and the prevalence of \"natural\" Trojans. The report concludes with lessons learned and recommendations for advancing AI security research.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
