{"id": "2601.10754", "categories": ["cs.CR", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.10754", "abs": "https://arxiv.org/abs/2601.10754", "authors": ["Hsuen-Chi Chiu", "Jeremy Foote"], "title": "Chatting with Confidants or Corporations? Privacy Management with AI Companions", "comment": null, "summary": "AI chatbots designed as emotional companions blur the boundaries between interpersonal intimacy and institutional software, creating a complex, multi-dimensional privacy environment. Drawing on Communication Privacy Management theory and Masur's horizontal (user-AI) and vertical (user-platform) privacy framework, we conducted in-depth interviews with fifteen users of companion AI platforms such as Replika and Character.AI. Our findings reveal that users blend interpersonal habits with institutional awareness: while the non-judgmental, always-available nature of chatbots fosters emotional safety and encourages self-disclosure, users remain mindful of institutional risks and actively manage privacy through layered strategies and selective sharing. Despite this, many feel uncertain or powerless regarding platform-level data control. Anthropomorphic design further blurs privacy boundaries, sometimes leading to unintentional oversharing and privacy turbulence. These results extend privacy theory by highlighting the unique interplay of emotional and institutional privacy management in human-AI companionship.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u7528\u6237\u8bbf\u8c08\u53d1\u73b0\uff0cAI\u804a\u5929\u673a\u5668\u4eba\u4f5c\u4e3a\u60c5\u611f\u4f34\u4fa3\u65f6\uff0c\u7528\u6237\u5728\u4eab\u53d7\u60c5\u611f\u5b89\u5168\u7684\u540c\u65f6\u4f1a\u8c28\u614e\u7ba1\u7406\u9690\u79c1\uff0c\u4f46\u5e73\u53f0\u7ea7\u522b\u7684\u6570\u636e\u63a7\u5236\u6743\u95ee\u9898\u4ecd\u7136\u5b58\u5728\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u63a2\u8ba8AI\u804a\u5929\u673a\u5668\u4eba\u4f5c\u4e3a\u60c5\u611f\u4f34\u4fb6\u65f6\uff0c\u7528\u6237\u5982\u4f55\u5e73\u8861\u4eba\u9645\u4ea4\u5f80\u4e2d\u7684\u60c5\u611f\u9700\u6c42\u548c\u673a\u6784\u5c42\u9762\u7684\u9690\u79c1\u7ba1\u7406\u3002", "method": "\u91c7\u7528\u6df1\u5ea6\u8bbf\u8c08\u7684\u65b9\u5f0f\uff0c\u7814\u7a76\u8005\u57fa\u4e8e\u6c9f\u901a\u9690\u79c1\u7ba1\u7406\u7406\u8bba\u548cMasur\u7684\u7528\u6237-AI\u548c\u7528\u6237-\u5e73\u53f0\u9690\u79c1\u6846\u67b6\uff0c\u5bf915\u540d\u4f7f\u7528Replika\u548cCharacter.AI\u7b49\u60c5\u611fAI\u5e73\u53f0\u7684\u7528\u6237\u8fdb\u884c\u4e86\u8bbf\u8c08\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u7528\u6237\u5728\u4f7f\u7528\u804a\u5929\u673a\u5668\u4eba\u65f6\u503e\u5411\u4e8e\u7ed3\u5408\u4eba\u9645\u4ea4\u5f80\u4e2d\u7684\u4e60\u60ef\u548c\u673a\u6784\u5c42\u9762\u7684\u8b66\u89c9\u6027\uff0c\u5c3d\u7ba1\u673a\u5668\u4eba\u7684\u975e\u8bc4\u5224\u6027\u548c\u968f\u65f6\u53ef\u7528\u6027\u4fc3\u8fdb\u4e86\u60c5\u611f\u5f00\u653e\uff0c\u4f46\u7528\u6237\u4f9d\u7136\u5173\u6ce8\u9690\u79c1\u98ce\u9669\uff0c\u5e76\u91c7\u53d6\u591a\u5c42\u7ea7\u7b56\u7565\u8fdb\u884c\u9690\u79c1\u7ba1\u7406\u3002\u7136\u800c\uff0c\u7528\u6237\u5bf9\u4e8e\u5e73\u53f0\u7ea7\u522b\u7684\u6570\u636e\u63a7\u5236\u611f\u4e0d\u786e\u5b9a\u6216\u65e0\u529b\uff0c\u800c\u62df\u4eba\u5316\u8bbe\u8ba1\u8fdb\u4e00\u6b65\u6a21\u7cca\u4e86\u9690\u79c1\u754c\u9650\uff0c\u5bfc\u81f4\u65e0\u610f\u7684\u9690\u79c1\u8fc7\u5ea6\u62ab\u9732\u3002", "conclusion": "\u7814\u7a76\u7ed3\u8bba\u6307\u51fa\uff0cAI\u4f34\u4fa3\u673a\u5668\u4eba\u7684\u4f7f\u7528\u6269\u5c55\u4e86\u9690\u79c1\u7406\u8bba\uff0c\u7a81\u663e\u4e86\u4eba\u9645\u60c5\u611f\u9690\u79c1\u7ba1\u7406\u548c\u673a\u6784\u5c42\u9762\u9690\u79c1\u7ba1\u7406\u7684\u590d\u6742\u4e92\u52a8\u3002"}}
{"id": "2601.10848", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.10848", "abs": "https://arxiv.org/abs/2601.10848", "authors": ["Xinrui Zhang", "Pincan Zhao", "Jason Jaskolka", "Heng Li", "Rongxing Lu"], "title": "SecMLOps: A Comprehensive Framework for Integrating Security Throughout the MLOps Lifecycle", "comment": null, "summary": "Machine Learning (ML) has emerged as a pivotal technology in the operation of large and complex systems, driving advancements in fields such as autonomous vehicles, healthcare diagnostics, and financial fraud detection. Despite its benefits, the deployment of ML models brings significant security challenges, such as adversarial attacks, which can compromise the integrity and reliability of these systems. To address these challenges, this paper builds upon the concept of Secure Machine Learning Operations (SecMLOps), providing a comprehensive framework designed to integrate robust security measures throughout the entire ML operations (MLOps) lifecycle. SecMLOps builds on the principles of MLOps by embedding security considerations from the initial design phase through to deployment and continuous monitoring. This framework is particularly focused on safeguarding against sophisticated attacks that target various stages of the MLOps lifecycle, thereby enhancing the resilience and trustworthiness of ML applications. A detailed advanced pedestrian detection system (PDS) use case demonstrates the practical application of SecMLOps in securing critical MLOps. Through extensive empirical evaluations, we highlight the trade-offs between security measures and system performance, providing critical insights into optimizing security without unduly impacting operational efficiency. Our findings underscore the importance of a balanced approach, offering valuable guidance for practitioners on how to achieve an optimal balance between security and performance in ML deployments across various domains.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Secure Machine Learning Operations\uff08SecMLOps\uff09\u6846\u67b6\uff0c\u65e8\u5728\u901a\u8fc7\u5d4c\u5165\u5b89\u5168\u8003\u8651\u6765\u589e\u5f3a\u6574\u4e2aMLOps\u751f\u547d\u5468\u671f\u4e2d\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u3002\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\uff0c\u5c55\u793a\u4e86\u8be5\u6846\u67b6\u5728\u9ad8\u7ea7\u884c\u4eba\u68c0\u6d4b\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\uff0c\u5e76\u8ba8\u8bba\u4e86\u5b89\u5168\u63aa\u65bd\u4e0e\u7cfb\u7edf\u6027\u80fd\u4e4b\u95f4\u7684\u6743\u8861\u3002", "motivation": "\u53d7ML\u6a21\u578b\u90e8\u7f72\u5e26\u6765\u91cd\u8981\u5b89\u5168\u6311\u6218\u7684\u9a71\u52a8\uff0c\u672c\u6587\u65e8\u5728\u63d0\u4f9b\u4e00\u4e2a\u6574\u5408\u4e86\u5b89\u5168\u63aa\u65bd\u7684\u6846\u67b6\uff0c\u4ee5\u5e94\u5bf9\u5bf9\u6297\u653b\u51fb\u7b49\u5a01\u80c1\uff0c\u589e\u5f3aML\u5e94\u7528\u7a0b\u5e8f\u7684\u7a33\u5065\u6027\u548c\u53ef\u4fe1\u5ea6\u3002", "method": "\u6784\u5efa\u4e86SecMLOps\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5728MLOps\u751f\u547d\u5468\u671f\u7684\u6240\u6709\u9636\u6bb5\u5d4c\u5165\u4e86\u5b89\u5168\u6027\u8003\u8651\u3002\u901a\u8fc7\u4e00\u4e2a\u8be6\u7ec6\u7684\u9ad8\u7ea7\u884c\u4eba\u68c0\u6d4b\u7cfb\u7edf\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86SecMLOps\u7684\u5b9e\u9645\u5e94\u7528\uff0c\u5e76\u5206\u6790\u4e86\u5b89\u5168\u63aa\u65bd\u548c\u7cfb\u7edf\u6027\u80fd\u4e4b\u95f4\u7684\u6743\u8861\u3002", "result": "\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\uff0c\u672c\u6587\u5c55\u793a\u4e86SecMLOps\u6846\u67b6\u5728\u9ad8\u7ea7\u884c\u4eba\u68c0\u6d4b\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\u6548\u679c\uff0c\u5e76\u63a2\u8ba8\u4e86\u5b89\u5168\u63aa\u65bd\u4e0e\u7cfb\u7edf\u6027\u80fd\u4e4b\u95f4\u7684\u6298\u8877\u3002", "conclusion": "\u672c\u6587\u5f3a\u8c03\u4e86\u5728\u4e0d\u540c\u9886\u57df\u5b9e\u73b0ML\u90e8\u7f72\u5b89\u5168\u6027\u548c\u6027\u80fd\u4e4b\u95f4\u5747\u8861\u7684\u5fc5\u8981\u6027\uff0c\u4e3a\u5b9e\u8df5\u8005\u63d0\u4f9b\u4e86\u5982\u4f55\u5728\u5b89\u5168\u4e0e\u6027\u80fd\u4e4b\u95f4\u53d6\u5f97\u6700\u4f73\u5e73\u8861\u7684\u5b9d\u8d35\u6307\u5bfc\u3002"}}
{"id": "2601.10865", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.10865", "abs": "https://arxiv.org/abs/2601.10865", "authors": ["Jonah Ghebremichael", "Saastha Vasan", "Saad Ullah", "Greg Tystahl", "David Adei", "Christopher Kruegel", "Giovanni Vigna", "William Enck", "Alexandros Kapravelos"], "title": "Multi-Agent Taint Specification Extraction for Vulnerability Detection", "comment": null, "summary": "Static Application Security Testing (SAST) tools using taint analysis are widely viewed as providing higher-quality vulnerability detection results compared to traditional pattern-based approaches. However, performing static taint analysis for JavaScript poses two major challenges. First, JavaScript's dynamic features complicate data flow extraction required for taint tracking. Second, npm's large library ecosystem makes it difficult to identify relevant sources/sinks and establish taint propagation across dependencies. In this paper, we present SemTaint, a multi-agent system that strategically combines the semantic understanding of Large Language Models (LLMs) with traditional static program analysis to extract taint specifications, including sources, sinks, call edges, and library flow summaries tailored to each package. Conceptually, SemTaint uses static program analysis to calculate a call graph and defers to an LLM to resolve call edges that cannot be resolved statically. Further, it uses the LLM to classify sources and sinks for a given CWE. The resulting taint specification is then provided to a SAST tool, which performs vulnerability analysis. We integrate SemTaint with CodeQL, a state-of-the-art SAST tool, and demonstrate its effectiveness by detecting 106 of 162 vulnerabilities previously undetectable by CodeQL. Furthermore, we find 4 novel vulnerabilities in 4 popular npm packages. In doing so, we demonstrate that LLMs can practically enhance existing static program analysis algorithms, combining the strengths of both symbolic reasoning and semantic understanding for improved vulnerability detection.", "AI": {"tldr": "SemTaint \u662f\u4e00\u79cd\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u548c\u4f20\u7edf\u9759\u6001\u7a0b\u5e8f\u5206\u6790\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u80fd\u591f\u6709\u6548\u51cf\u5c11 JavaScript \u56e0\u52a8\u6001\u7279\u6027\u548c\u4f9d\u8d56\u5e93\u9020\u6210\u7684\u5b89\u5168\u5206\u6790\u56f0\u96be\uff0c\u5e76\u63d0\u9ad8\u6f0f\u6d1e\u68c0\u6d4b\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u7684\u9759\u6001\u5e94\u7528\u5b89\u5168\u6d4b\u8bd5\uff08SAST\uff09\u5de5\u5177\u5bf9\u4e8e JavaScript \u7684\u52a8\u6001\u7279\u6027\u548c\u5e9e\u5927\u7684\u5e93\u751f\u6001\u7cfb\u7edf\u96be\u4ee5\u8fdb\u884c\u6709\u6548\u7684\u5b89\u5168\u68c0\u6d4b\uff0cSemTaint \u65e8\u5728\u901a\u8fc7\u5229\u7528 LLM \u7684\u8bed\u4e49\u7406\u89e3\u80fd\u529b\u7ed3\u5408\u4f20\u7edf SAST \u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u3002", "method": "SemTaint \u901a\u8fc7\u9759\u6001\u7a0b\u5e8f\u5206\u6790\u6784\u5efa\u8c03\u7528\u56fe\uff0c\u5e76\u501f\u52a9 LLM \u5904\u7406\u89e3\u6790\u9759\u6001\u65b9\u6cd5\u65e0\u6cd5\u89e3\u51b3\u7684\u8c03\u7528\u8fb9\u3002\u6b64\u5916\uff0c\u5b83\u8fd8\u4f7f\u7528 LLM \u5bf9\u7ed9\u5b9a CWE \u7c7b\u522b\u4e2d\u7684\u6765\u6e90\u548c\u76ee\u6807\u8fdb\u884c\u5206\u7c7b\u3002\u6700\u7ec8\uff0c\u751f\u6210\u7684\u6c61\u70b9\u89c4\u683c\u63d0\u4f9b\u7ed9 SAST \u5de5\u5177\u8fdb\u884c\u6f0f\u6d1e\u5206\u6790\u3002", "result": "\u5728\u4e0e CodeQL \u7684\u96c6\u6210\u6d4b\u8bd5\u4e2d\uff0cSemTaint \u53d1\u73b0\u4e86 162 \u4e2a\u4e4b\u524d\u672a\u88ab\u53d1\u73b0\u7684\u6f0f\u6d1e\u4e2d\u7684 106 \u4e2a\uff0c\u5e76\u5728 4 \u4e2a\u6d41\u884c\u7684 npm \u5305\u4e2d\u53d1\u73b0\u4e86 4 \u4e2a\u65b0\u7684\u6f0f\u6d1e\u3002", "conclusion": "SemTaint \u8bc1\u660e\u4e86 LLM \u7684\u4f7f\u7528\u53ef\u4ee5\u6709\u6548\u589e\u5f3a\u9759\u6001\u7a0b\u5e8f\u5206\u6790\u7b97\u6cd5\uff0c\u63d0\u5347\u6f0f\u6d1e\u68c0\u6d4b\u80fd\u529b\u3002"}}
{"id": "2601.10866", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.10866", "abs": "https://arxiv.org/abs/2601.10866", "authors": ["Yuting Liang", "Ke Yi"], "title": "Adaptive Privacy Budgeting", "comment": null, "summary": "We study the problem of adaptive privacy budgeting under generalized differential privacy. Consider the setting where each user $i\\in [n]$ holds a tuple $x_i\\in U:=U_1\\times \\dotsb \\times U_T$, where $x_i(l)\\in U_l$ represents the $l$-th component of their data. For every $l\\in [T]$ (or a subset), an untrusted analyst wishes to compute some $f_l(x_1(l),\\dots,x_n(l))$, while respecting the privacy of each user. For many functions $f_l$, data from the users are not all equally important, and there is potential to use the privacy budgets of the users strategically, leading to privacy savings that can be used to improve the utility of later queries. In particular, the budgeting should be adaptive to the outputs of previous queries, so that greater savings can be achieved on more typical instances. In this paper, we provide such an adaptive budgeting framework, with various applications demonstrating its applicability.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u5e7f\u4e49\u5dee\u5206\u9690\u79c1\u4e0b\u9002\u5e94\u6027\u9690\u79c1\u9884\u7b97\u95ee\u9898\u3002\u5bf9\u4e8e\u6bcf\u4e2a\u7528\u6237\u7684\u4e0d\u5747\u8861\u6570\u636e\u8d21\u732e\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u80fd\u591f\u6839\u636e\u5148\u524d\u67e5\u8be2\u7ed3\u679c\u8fdb\u884c\u8c03\u6574\u7684\u9002\u5e94\u6027\u9884\u7b97\u6846\u67b6\uff0c\u4ee5\u5b9e\u73b0\u9690\u79c1\u4fdd\u62a4\u4e0b\u7684\u9ad8\u6548\u8ba1\u7b97\u3002", "motivation": "\u76ee\u524d\u7684\u6570\u636e\u5206\u6790\u4e2d\uff0c\u7528\u6237\u6570\u636e\u7684\u91cd\u8981\u7a0b\u5ea6\u5f80\u5f80\u4e0d\u5747\u7b49\uff0c\u4f20\u7edf\u7684\u9690\u79c1\u9884\u7b97\u65b9\u6cd5\u53ef\u80fd\u65e0\u6cd5\u5145\u5206\u5229\u7528\u8fd9\u79cd\u4e0d\u5747\u8861\u6765\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\uff0c\u672c\u6587\u65e8\u5728\u63d0\u4f9b\u4e00\u79cd\u9002\u5e94\u6027\u9690\u79c1\u9884\u7b97\u6846\u67b6\uff0c\u52a8\u6001\u8c03\u6574\u9690\u79c1\u9884\u7b97\uff0c\u6700\u5927\u9650\u5ea6\u5730\u964d\u4f4e\u9690\u79c1\u6210\u672c\uff0c\u63d0\u9ad8\u67e5\u8be2\u7ed3\u679c\u7684\u6709\u7528\u6027\u3002", "method": "\u672c\u6587\u7684\u65b9\u6cd5\u4e3b\u8981\u96c6\u4e2d\u5728\u6784\u5efa\u4e00\u79cd\u9002\u5e94\u6027\u9884\u7b97\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u53ef\u4ee5\u6839\u636e\u7528\u6237\u6570\u636e\u7684\u7279\u5b9a\u8d21\u732e\u4ee5\u53ca\u5148\u524d\u67e5\u8be2\u7684\u8f93\u51fa\u52a8\u6001\u8c03\u6574\u9690\u79c1\u9884\u7b97\uff0c\u4ece\u800c\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u9690\u79c1\u4fdd\u62a4\u8ba1\u7b97\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u56fa\u5b9a\u9690\u79c1\u9884\u7b97\u65b9\u6cd5\u76f8\u6bd4\uff0c\u672c\u6587\u63d0\u51fa\u7684\u9002\u5e94\u6027\u9884\u7b97\u6846\u67b6\u80fd\u591f\u5728\u4e0d\u663e\u8457\u727a\u7272\u9690\u79c1\u4fdd\u62a4\u7684\u524d\u63d0\u4e0b\uff0c\u63d0\u9ad8\u6570\u636e\u67e5\u8be2\u7684\u6709\u7528\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u9002\u5e94\u6027\u9690\u79c1\u9884\u7b97\u6846\u67b6\u4e3a\u5e7f\u4e49\u5dee\u5206\u9690\u79c1\u4e0b\u7684\u6570\u636e\u67e5\u8be2\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2601.10719", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.10719", "abs": "https://arxiv.org/abs/2601.10719", "authors": ["Gerard Yeo", "Svetlana Churina", "Kokil Jaidka"], "title": "Do You Trust Me? Cognitive-Affective Signatures of Trustworthiness in Large Language Models", "comment": null, "summary": "Perceived trustworthiness underpins how users navigate online information, yet it remains unclear whether large language models (LLMs),increasingly embedded in search, recommendation, and conversational systems, represent this construct in psychologically coherent ways. We analyze how instruction-tuned LLMs (Llama 3.1 8B, Qwen 2.5 7B, Mistral 7B) encode perceived trustworthiness in web-like narratives using the PEACE-Reviews dataset annotated for cognitive appraisals, emotions, and behavioral intentions. Across models, systematic layer- and head-level activation differences distinguish high- from low-trust texts, revealing that trust cues are implicitly encoded during pretraining. Probing analyses show linearly de-codable trust signals and fine-tuning effects that refine rather than restructure these representations. Strongest associations emerge with appraisals of fairness, certainty, and accountability-self -- dimensions central to human trust formation online. These findings demonstrate that modern LLMs internalize psychologically grounded trust signals without explicit supervision, offering a representational foundation for designing credible, transparent, and trust-worthy AI systems in the web ecosystem. Code and appendix are available at: https://github.com/GerardYeo/TrustworthinessLLM.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u5206\u6790\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u7c7b\u4f3c\u7f51\u9875\u7684\u53d9\u8ff0\u4e2d\u5982\u4f55\u7f16\u7801\u611f\u77e5\u7684\u53ef\u4fe1\u5ea6\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u9884\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u9690\u5f0f\u5730\u5b66\u4e60\u4e86\u5173\u4e8e\u516c\u6b63\u662f\u3001\u786e\u5b9a\u6027\u548c\u8d23\u4efb\u611f\u7684\u4eba\u7c7b\u5728\u7ebf\u4fe1\u4efb\u5f62\u6210\u7684\u7ef4\u5ea6\u7684\u4fe1\u53f7\uff0c\u8fd9\u4e9b\u4fe1\u53f7\u6709\u52a9\u4e8e\u8bbe\u8ba1\u53ef\u4fe1\u8d56\u3001\u900f\u660e\u548c\u503c\u5f97\u4fe1\u8d56\u7684AI\u7cfb\u7edf\u3002", "motivation": "\u63a2\u8ba8\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u662f\u5426\u5728\u5fc3\u7406\u4e0a\u4ee5\u4e00\u81f4\u7684\u65b9\u5f0f\u5448\u73b0\u611f\u77e5\u7684\u53ef\u4fe1\u5ea6\uff0c\u4ee5\u4e86\u89e3\u5176\u5728\u641c\u7d22\u5f15\u64ce\u3001\u63a8\u8350\u7cfb\u7edf\u548c\u5bf9\u8bdd\u7cfb\u7edf\u4e2d\u7684\u4f5c\u7528\u3002", "method": "\u4f7f\u7528PEACE-Reviews\u6570\u636e\u96c6\u6ce8\u91ca\u7684\u5fc3\u7406\u8ba4\u77e5\u8bc4\u4f30\u3001\u60c5\u611f\u548c\u884c\u4e3a\u610f\u56fe\u5bf9\u6307\u4ee4\u8c03\u6574\u540e\u7684LLMs\uff08Llama 3.1 8B\u3001Qwen 2.5 7B\u3001Mistral 7B\uff09\u8fdb\u884c\u5206\u6790\uff0c\u901a\u8fc7\u63a2\u9488\u5206\u6790\u8bc4\u4f30\u4fe1\u4efb\u4fe1\u53f7\u3002", "result": "\u5c55\u793a\u4e86\u5c42\u7ea7\u548c\u5934\u7ea7\u522b\u6fc0\u6d3b\u5dee\u5f02\u5982\u4f55\u533a\u5206\u9ad8\u53ef\u4fe1\u5ea6\u548c\u4f4e\u53ef\u4fe1\u5ea6\u6587\u672c\uff0c\u63ed\u793a\u4e86\u53ef\u4fe1\u5ea6\u63d0\u793a\u5728\u9884\u8bad\u7ec3\u671f\u95f4\u9690\u5f0f\u7f16\u7801\uff1b\u63a2\u9488\u5206\u6790\u663e\u793a\u7ebf\u6027\u53ef\u89e3\u7684\u4fe1\u4efb\u4fe1\u53f7\u548c\u5fae\u8c03\u6548\u679c\uff0c\u8fd9\u4e9b\u6548\u679c\u7ec6\u5316\u800c\u4e0d\u662f\u91cd\u65b0\u6784\u5efa\u8fd9\u4e9b\u8868\u793a\u3002", "conclusion": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u73b0\u4ee3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6ca1\u6709\u663e\u5f0f\u76d1\u7763\u7684\u60c5\u51b5\u4e0b\u4ee5\u5185\u9690\u7684\u65b9\u5f0f\u5b66\u4e60\u4e86\u5173\u4e8e\u516c\u5e73\u3001\u786e\u5b9a\u6027\u548c\u8d23\u4efb\u611f\u7684\u4eba\u7c7b\u5728\u7ebf\u4fe1\u4efb\u5f62\u6210\u7684\u5fc3\u7406\u57fa\u7840\u4fe1\u53f7\uff0c\u4e3a\u8bbe\u8ba1\u53ef\u4fe1\u8d56\u3001\u900f\u660e\u548c\u503c\u5f97\u4fe1\u8d56\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4ee3\u8868\u6027\u7684\u57fa\u7840\u3002"}}
{"id": "2601.10971", "categories": ["cs.CR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.10971", "abs": "https://arxiv.org/abs/2601.10971", "authors": ["Yipu Dou", "Wang Yang"], "title": "AJAR: Adaptive Jailbreak Architecture for Red-teaming", "comment": null, "summary": "As Large Language Models (LLMs) evolve from static chatbots into autonomous agents capable of tool execution, the landscape of AI safety is shifting from content moderation to action security. However, existing red-teaming frameworks remain bifurcated: they either focus on rigid, script-based text attacks or lack the architectural modularity to simulate complex, multi-turn agentic exploitations. In this paper, we introduce AJAR (Adaptive Jailbreak Architecture for Red-teaming), a proof-of-concept framework designed to bridge this gap through Protocol-driven Cognitive Orchestration. Built upon the robust runtime of Petri, AJAR leverages the Model Context Protocol (MCP) to decouple adversarial logic from the execution loop, encapsulating state-of-the-art algorithms like X-Teaming as standardized, plug-and-play services. We validate the architectural feasibility of AJAR through a controlled qualitative case study, demonstrating its ability to perform stateful backtracking within a tool-use environment. Furthermore, our preliminary exploration of the \"Agentic Gap\" reveals a complex safety dynamic: while tool usage introduces new injection vectors via code execution, the cognitive load of parameter formatting can inadvertently disrupt persona-based attacks. AJAR is open-sourced to facilitate the standardized, environment-aware evaluation of this emerging attack surface. The code and data are available at https://github.com/douyipu/ajar.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aAJAR\u7684\u65b0\u6846\u67b6\uff0c\u65e8\u5728\u901a\u8fc7\u534f\u8bae\u9a71\u52a8\u7684\u8ba4\u77e5\u7f16\u6392\uff08Protocol-driven Cognitive Orchestration\uff09\u8865\u5145\u73b0\u6709\u7684\u7ea2\u961f\u6d4b\u8bd5\u6846\u67b6\u3002AJAR\u57fa\u4e8ePetri\u7684\u8fd0\u884c\u65f6\uff0c\u5e76\u5229\u7528\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\uff08MCP\uff09\u89e3\u8026\u5bf9\u624b\u903b\u8f91\u548c\u6267\u884c\u5faa\u73af\uff0c\u4f7f\u5176\u6210\u4e3a\u4e00\u4e2a\u6807\u51c6\u5316\u3001\u53ef\u63d2\u62d4\u7684\u670d\u52a1\u3002", "motivation": "\u73b0\u6709\u7684\u7ea2\u961f\u6d4b\u8bd5\u6846\u67b6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u8981\u4e48\u5173\u6ce8\u521a\u6027\u7684\u811a\u672c\u5316\u6587\u672c\u653b\u51fb\uff0c\u8981\u4e48\u7f3a\u4e4f\u6a21\u62df\u590d\u6742\u3001\u591a\u8f6e\u81ea\u4e3b\u653b\u51fb\u7684\u6a21\u5757\u5316\u67b6\u6784\u3002\u56e0\u6b64\uff0c\u672c\u6587\u63d0\u51fa\u4e86AJAR\u6846\u67b6\uff0c\u4ee5\u5f25\u5408\u8fd9\u4e2a\u5dee\u8ddd\uff0c\u901a\u8fc7\u534f\u8bae\u9a71\u52a8\u7684\u8ba4\u77e5\u7f16\u6392\u6765\u63d0\u9ad8\u7ea2\u961f\u6d4b\u8bd5\u7684\u7075\u6d3b\u6027\u3002", "method": "AJAR\u6846\u67b6\u5229\u7528Petri\u7684\u8fd0\u884c\u65f6\uff0c\u5e76\u91c7\u7528\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\uff08MCP\uff09\u8fdb\u884c\u89e3\u8026\uff0c\u5c06\u5148\u8fdb\u7684\u7b97\u6cd5\u5982X-Teaming\u6807\u51c6\u5316\u548c\u6a21\u5757\u5316\uff0c\u4ee5\u63d2\u62d4\u5f0f\u670d\u52a1\u5b9e\u73b0\u3002", "result": "\u901a\u8fc7\u63a7\u5236\u6027\u7684\u5b9a\u6027\u6848\u4f8b\u7814\u7a76\uff0c\u9a8c\u8bc1\u4e86AJAR\u6846\u67b6\u7684\u67b6\u6784\u53ef\u884c\u6027\uff0c\u5b83\u80fd\u591f\u5728\u4e00\u4e2a\u5de5\u5177\u4f7f\u7528\u73af\u5883\u4e2d\u6267\u884c\u6709\u72b6\u6001\u56de\u6eaf\u3002\u6b64\u5916\uff0c\u521d\u6b65\u63a2\u8ba8\u4e86\u201c\u80fd\u52a8\u6027\u7f3a\u53e3\u201d\uff0c\u5c55\u793a\u4e86\u5de5\u5177\u4f7f\u7528\u5f15\u5165\u65b0\u7684\u6ce8\u5165\u5411\u91cf\uff0c\u800c\u53c2\u6570\u683c\u5f0f\u5316\u8ba4\u77e5\u8d1f\u62c5\u53ef\u80fd\u610f\u5916\u7834\u574f\u57fa\u4e8e\u89d2\u8272\u7684\u653b\u51fb\u3002", "conclusion": "AJAR\u5f00\u6e90\u4ee5\u4fc3\u8fdb\u5bf9\u8fd9\u4e00\u65b0\u5174\u653b\u51fb\u9762\u7684\u6807\u51c6\u5316\u548c\u73af\u5883\u611f\u77e5\u8bc4\u4f30\u3002\u901a\u8fc7\u4e3a\u7ea2\u961f\u6d4b\u8bd5\u63d0\u4f9b\u4e00\u79cd\u7075\u6d3b\u7684\u65b9\u6cd5\uff0cAJAR\u6709\u52a9\u4e8e\u63d0\u5347AI\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u3002"}}
{"id": "2601.11095", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.11095", "abs": "https://arxiv.org/abs/2601.11095", "authors": ["Grazia D'Onghia", "Antonio Lioy"], "title": "Towards Quantum-Resistant Trusted Computing: Architectures for Post-Quantum Integrity Verification Techniques", "comment": "Author-accepted manuscript of a paper published in the IEEE Symposium on Computers and Communications (ISCC), 2025. DOI: 10.1109/ISCC65549.2025.11326490", "summary": "Trust is the core building block of secure systems, and it is enforced through methods to ensure that a specific system is properly configured and works as expected. In this context, a Root of Trust (RoT) establishes a trusted environment, where both data and code are authenticated via a digital signature based on asymmetric cryptography, which is vulnerable to the threat posed by Quantum Computers (QCs). Firmware, being the first layer of trusted software, faces unique risks due to its longevity and difficult update. The transition of firmware protection to Post-Quantum Cryptography (PQC) is urgent, since it reduces the risk derived from exposing all computing and network devices to quantum-based attacks. This paper offers an analysis of the most common trust techniques and their roadmap towards a Post-Quantum (PQ) world, by investigating the current status of PQC and the challenges posed by such algorithms in existing Trusted Computing (TC) solutions from an integration perspective. Furthermore, this paper proposes an architecture for TC techniques enhanced with PEC, addressing the imperative for immediate adoption of quantum-resistant algorithms.", "AI": {"tldr": "\u672c\u6587\u6982\u8ff0\u4e86\u5f53\u524d\u4fe1\u4efb\u6280\u672f\u53ca\u5176\u5411\u540e\u91cf\u5b50\uff08PQ\uff09\u4e16\u754c\u7684\u8fc7\u6e21\u73b0\u72b6\uff0c\u8ba8\u8bba\u4e86\u540e\u91cf\u5b50\u5bc6\u7801\u5b66\uff08PQC\uff09\u5728\u5f53\u524d\u4fe1\u4efb\u8ba1\u7b97\uff08TC\uff09\u89e3\u51b3\u65b9\u6848\u4e2d\u7684\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u4e86\u589e\u5f3a\u4fe1\u4efb\u8ba1\u7b97\u6280\u672f\u7684\u67b6\u6784\u65b9\u6848\uff0c\u65e8\u5728\u52a0\u901f\u5207\u6362\u5230\u91cf\u5b50\u6297\u6027\u7b97\u6cd5\u3002", "motivation": "\u9274\u4e8e\u6839\u4fe1\u4efb\uff08RoT\uff09\u548c\u4fe1\u4efb\u8ba1\u7b97\uff08TC\uff09\u73af\u5883\u4e2d\u5b58\u5728\u7684\u4f20\u7edf\u5bc6\u7801\u5b66\u9762\u4e34\u7684\u91cf\u5b50\u8ba1\u7b97\uff08QC\uff09\u5a01\u80c1\uff0c\u63d0\u51fa\u5f53\u524d\u6280\u672f\u8def\u5f84\u548c\u540e\u91cf\u5b50\u5bc6\u7801\u5b66\uff08PQC\uff09\u7684\u91cd\u8981\u6027\uff0c\u4ee5\u53ca\u5728TC\u89e3\u51b3\u65b9\u6848\u4e2d\u96c6\u6210PQC\u7684\u5fc5\u8981\u6027\u3002\u8fd9\u5c06\u4f7f\u5f97\u8bbe\u5907\u514d\u53d7\u91cf\u5b50\u57fa\u4e8e\u653b\u51fb\u7684\u98ce\u9669\u3002", "method": "\u901a\u8fc7\u5bf9\u73b0\u6709\u6280\u672f\u72b6\u6001\u548c\u6311\u6218\u7684\u5206\u6790\uff0c\u63a2\u8ba8PQC\u5728\u4fe1\u4efb\u8ba1\u7b97\u73af\u5883\u4e2d\u7684\u5e94\u7528\uff0c\u5e76\u63d0\u51fa\u4e00\u4e2a\u589e\u5f3a\u7684\u67b6\u6784\uff0c\u4ee5\u9002\u5e94\u91cf\u5b50\u6297\u6027\u7b97\u6cd5\u3002", "result": "\u5206\u6790\u5f53\u524dPQC\u7684\u72b6\u6001\u548c\u9762\u4e34\u7684\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u4fe1\u4efb\u8ba1\u7b97\u589e\u5f3a\u67b6\u6784\uff0c\u65e8\u5728\u4fc3\u8fdb\u4ece\u73b0\u6709\u4fe1\u4efb\u8ba1\u7b97\u89e3\u51b3\u65b9\u6848\u5230\u540e\u91cf\u5b50\u4e16\u754c\u7684\u8fc7\u6e21\u3002", "conclusion": "\u6587\u7ae0\u5f3a\u8c03\u4e86\u91cf\u5b50\u6297\u6027\u7b97\u6cd5\u5728\u4fe1\u4efb\u8ba1\u7b97\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u96c6\u6210PQC\u7684\u65b9\u6cd5\uff0c\u4ee5\u589e\u5f3a\u4fe1\u4efb\u8ba1\u7b97\u73af\u5883\u7684\u5b89\u5168\u6027\uff0c\u5e94\u5bf9\u91cf\u5b50\u8ba1\u7b97\u5a01\u80c1\u3002"}}
{"id": "2601.10768", "categories": ["cs.AI", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.10768", "abs": "https://arxiv.org/abs/2601.10768", "authors": ["Nina Bo\u010dkov\u00e1", "Barbora Voln\u00e1", "Mirko Dohnal"], "title": "Optimisation of complex product innovation processes based on trend models with three-valued logic", "comment": null, "summary": "This paper investigates complex product-innovation processes using models grounded in a set of heuristics. Each heuristic is expressed through simple trends -- increasing, decreasing, or constant -- which serve as minimally information-intensive quantifiers, avoiding reliance on numerical values or rough sets. A solution to a trend model is defined as a set of scenarios with possible transitions between them, represented by a transition graph. Any possible future or past behaviour of the system under study can thus be depicted by a path within this graph.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u57fa\u4e8e\u4e00\u96c6\u542f\u53d1\u5f0f\u89c4\u5219\u7684\u590d\u6742\u4ea7\u54c1\u521b\u65b0\u8fc7\u7a0b\uff0c\u901a\u8fc7\u7b80\u5355\u8d8b\u52bf\uff08\u589e\u3001\u51cf\u3001\u7a33\uff09\u5b9a\u4e49\u6a21\u578b\u89e3\uff0c\u5c06\u53ef\u80fd\u7684\u8fc7\u6e21\u60c5\u666f\u7528\u8f6c\u6362\u56fe\u8868\u793a\uff0c\u63cf\u7ed8\u7cfb\u7edf\u7684\u884c\u4e3a\u53d8\u5316\u3002", "motivation": "\u5f53\u524d\u4ea7\u54c1\u521b\u65b0\u8fc7\u7a0b\u590d\u6742\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u7b80\u6d01\u7684\u5efa\u6a21\u65b9\u6cd5\uff0c\u800c\u57fa\u4e8e\u542f\u53d1\u5f0f\u89c4\u5219\u548c\u8d8b\u52bf\u7684\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u907f\u514d\u4f9d\u8d56\u5177\u4f53\u6570\u503c\u6216\u7c97\u7cd9\u96c6\u7684\u91cf\u5316\u624b\u6bb5\u3002", "method": "\u8be5\u7814\u7a76\u91c7\u7528\u542f\u53d1\u5f0f\u89c4\u5219\u548c\u7b80\u5355\u8d8b\u52bf\u6765\u5efa\u6a21\u4ea7\u54c1\u521b\u65b0\u8fc7\u7a0b\uff0c\u5b9a\u4e49\u4e86\u89e3\u4e3a\u53ef\u80fd\u7684\u573a\u666f\u8fc7\u6e21\u96c6\uff0c\u5e76\u901a\u8fc7\u8f6c\u6362\u56fe\u8868\u793a\u8fd9\u4e9b\u8fc7\u6e21\u3002", "result": "\u8be5\u65b9\u6cd5\u53ef\u4ee5\u7b80\u6d01\u5730\u63cf\u7ed8\u7cfb\u7edf\u5728\u672a\u6765\u6216\u8fc7\u53bb\u7684\u5404\u79cd\u53ef\u80fd\u51fa\u73b0\u7684\u884c\u4e3a\u72b6\u6001\u3002", "conclusion": "\u8fd9\u79cd\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u89c6\u89d2\u6765\u7406\u89e3\u590d\u6742\u7684\u4ea7\u54c1\u521b\u65b0\u8fc7\u7a0b\uff0c\u901a\u8fc7\u7b80\u5355\u7684\u8d8b\u52bf\u6a21\u578b\u548c\u542f\u53d1\u5f0f\u89c4\u5219\uff0c\u66f4\u52a0\u76f4\u89c2\u5730\u5c55\u793a\u7cfb\u7edf\u7684\u52a8\u6001\u53d8\u5316\u3002"}}
{"id": "2601.11104", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.11104", "abs": "https://arxiv.org/abs/2601.11104", "authors": ["Grazia D'Onghia", "Diana Gratiela Berbecaru", "Antonio Lioy"], "title": "Shaping a Quantum-Resistant Future: Strategies for Post-Quantum PKI", "comment": "Author-accepted manuscript of a paper published in the 2024 IEEE Symposium on Computers and Communications (ISCC), Paris, France, 2024, pp. 1-6, doi: 10.1109/ISCC61673.2024.10733624", "summary": "As the quantum computing era approaches, securing classical cryptographic protocols becomes imperative. Public key cryptography is widely used for signature and key exchange but it is the type of cryptography more threatened by quantum computing. Its application typically requires support via a public-key certificate, which is a signed data structure and must therefore face twice the quantum challenge: for the certified keys and for the signature itself. We present the latest developments in selecting robust Post-Quantum algorithms and investigate their applicability in the Public Key Infrastructure context. Our contribution entails defining requirements for a secure transition to a quantum-resistant Public Key Infrastructure, with a focus on adaptations for the X.509 certificate format. Additionally, we explore transitioning Certificate Revocation List and Online Certificate Status Protocol to support quantum-resistant algorithms. Through comparative analysis, we elucidate the complex transition to a quantum-resistant PKI.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4e13\u6ce8\u4e8e\u540e\u91cf\u5b50\u65f6\u4ee3\u4e0b\u516c\u94a5\u57fa\u7840\u8bbe\u65bd(Public Key Infrastructure, PKI)\u7684\u5b89\u5168\u6027\u8f6c\u578b\uff0c\u7279\u522b\u662f\u9002\u5e94X.509\u8bc1\u4e66\u683c\u5f0f\u548c\u8bc1\u4e66\u64a4\u9500\u5217\u8868\u7b49\u7ec4\u4ef6\uff0c\u4ecb\u7ecd\u5982\u4f55\u901a\u8fc7\u6bd4\u8f83\u5206\u6790\u8fc7\u6e21\u5230\u91cf\u5b50\u6297\u6027\u7684PKI\u3002", "motivation": "\u968f\u7740\u91cf\u5b50\u8ba1\u7b97\u65f6\u4ee3\u7684\u4e34\u8fd1\uff0c\u7ecf\u5178\u5bc6\u7801\u534f\u8bae\u7684\u4fdd\u62a4\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u7814\u7a76\u8868\u660e\uff0c\u57fa\u4e8e\u516c\u94a5\u7684\u7b7e\u540d\u548c\u5bc6\u94a5\u4ea4\u6362\u6700\u6613\u53d7\u5230\u91cf\u5b50\u8ba1\u7b97\u7684\u5a01\u80c1\uff0c\u5fc5\u987b\u786e\u4fdd\u5176\u6240\u4f9d\u8d56\u7684\u516c\u5171\u5bc6\u94a5\u8bc1\u4e66\u4e5f\u5177\u6709\u91cf\u5b50\u6297\u6027\u3002", "method": "\u7814\u7a76\u56e2\u961f\u8bc4\u4f30\u4e86\u6700\u65b0\u7684\u540e\u91cf\u5b50\u5b89\u5168\u7b97\u6cd5\uff0c\u5e76\u5b9a\u4e49\u4e86\u5c06PKI\u8f6c\u5411\u91cf\u5b50\u6297\u6027\u7684\u5177\u4f53\u8981\u6c42\uff0c\u7279\u522b\u5173\u6ce8\u4e86X.509\u8bc1\u4e66\u683c\u5f0f\u7684\u9002\u5e94\u6027\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u901a\u8fc7\u9002\u5f53\u8c03\u6574\u548c\u8fc7\u6e21\u7b56\u7565\uff0c\u53ef\u4ee5\u5b9e\u73b0PKI\u5411\u91cf\u5b50\u6297\u6027\u7cfb\u7edf\u7684\u5e73\u7a33\u8f6c\u53d8\uff0c\u5e76\u786e\u4fdd\u5173\u952e\u7ec4\u4ef6\u5982\u8bc1\u4e66\u64a4\u9500\u5217\u8868\u548c\u5728\u7ebf\u8bc1\u4e66\u72b6\u6001\u534f\u8bae\u7684\u652f\u6301\u3002", "conclusion": "\u7814\u7a76\u63d0\u4f9b\u4e86\u8be6\u7ec6\u7684\u9002\u5e94\u6027\u8bc4\u4f30\u548c\u5efa\u8bae\uff0c\u4e3a\u540e\u7eed\u8fc7\u6e21\u5230\u91cf\u5b50\u6297\u6027\u516c\u94a5\u57fa\u7840\u8bbe\u65bd\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2601.10904", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10904", "abs": "https://arxiv.org/abs/2601.10904", "authors": ["Fran\u00e7ois Chollet", "Mike Knoop", "Gregory Kamradt", "Bryan Landers"], "title": "ARC Prize 2025: Technical Report", "comment": null, "summary": "The ARC-AGI benchmark series serves as a critical measure of few-shot generalization on novel tasks, a core aspect of intelligence. The ARC Prize 2025 global competition targeted the newly released ARC-AGI-2 dataset, which features greater task complexity compared to its predecessor. The Kaggle competition attracted 1,455 teams and 15,154 entries, with the top score reaching 24% on the ARC-AGI-2 private evaluation set. Paper submissions nearly doubled year-over-year to 90 entries, reflecting the growing research interest in fluid intelligence and abstract reasoning. The defining theme of 2025 is the emergence of the refinement loop -- a per-task iterative program optimization loop guided by a feedback signal. Refinement loops come in a variety of forms, in particular evolutionary program synthesis approaches and application-layer refinements to commercial AI systems. Such refinement loops are also possible in weight space, as evidenced by zero-pretraining deep learning methods which are now achieving competitive performance with remarkably small networks (7M parameters). In parallel, four frontier AI labs (Anthropic, Google DeepMind, OpenAI, and xAI) reported ARC-AGI performance in public model cards in 2025, establishing ARC-AGI as an industry standard benchmark for AI reasoning. However, our analysis indicates that current frontier AI reasoning performance remains fundamentally constrained to knowledge coverage, giving rise to new forms of benchmark contamination. In this paper, we survey the top-performing methods, examine the role of refinement loops in AGI progress, discuss knowledge-dependent overfitting, and preview ARC-AGI-3, which introduces interactive reasoning challenges that require exploration, planning, memory, goal acquisition, and alignment capabilities.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u9876\u7ea7\u65b9\u6cd5\uff0c\u63a2\u8ba8\u4e86\u5728AGI\u8fdb\u5c55\u4e2d\u7cbe\u70bc\u56de\u8def\u7684\u4f5c\u7528\uff0c\u8ba8\u8bba\u4e86\u77e5\u8bc6\u4f9d\u8d56\u6027\u8fc7\u62df\u5408\uff0c\u5e76\u9884\u89c8\u4e86ARC-AGI-3\u57fa\u51c6\uff0c\u8be5\u7248\u672c\u5f15\u5165\u4e86\u4e92\u52a8\u63a8\u7406\u6311\u6218\u3002", "motivation": "\u968f\u7740ARC-AGI-2\u6570\u636e\u96c6\u7684\u53d1\u5e03\uff0c\u8be5\u7814\u7a76\u65e8\u5728\u8bc4\u4f30AI\u5728\u65b0\u9896\u4efb\u52a1\u4e0a\u7684\u5c11\u6837\u672c\u6cdb\u5316\u80fd\u529b\uff0c\u7279\u522b\u662f\u5173\u6ce8\u7cbe\u70bc\u56de\u8def\u5728AGI\u53d1\u5c55\u4e2d\u7684\u4f5c\u7528\u3002", "method": "\u8be5\u7814\u7a76\u901a\u8fc7\u5206\u6790\u548c\u6bd4\u8f83\u7ade\u8d5b\u4e2d\u7684\u9876\u7ea7\u65b9\u6cd5\uff0c\u4ee5\u53ca\u8ba8\u8bba\u672a\u6765\u57fa\u51c6\u7684\u8981\u6c42\uff0c\u6765\u63a2\u7d22\u7cbe\u70bc\u56de\u8def\u5728AGI\u8fdb\u5c55\u4e2d\u7684\u89d2\u8272\uff0c\u7279\u522b\u662f\u77e5\u8bc6\u4f9d\u8d56\u6027\u8fc7\u62df\u5408\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff0c\u5f53\u524d\u7684\u4eba\u5de5\u667a\u80fd\u5728\u63a8\u7406\u4e0a\u7684\u8fdb\u6b65\u4e3b\u8981\u53d7\u9650\u4e8e\u77e5\u8bc6\u8986\u76d6\u8303\u56f4\uff0c\u4f46\u96f6\u9884\u8bad\u7ec3\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5df2\u7ecf\u80fd\u591f\u5728\u8f83\u5c0f\u7684\u6a21\u578b\u5927\u5c0f\u4e2d\u8fbe\u5230\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u5f53\u7684\u6027\u80fd\u3002\u6b64\u5916\uff0c\u7814\u7a76\u5f15\u5165\u4e86ARC-AGI-3\uff0c\u8fd9\u4e00\u65b0\u7684\u57fa\u51c6\u6311\u6218\u9700\u8981\u63a2\u7d22\u3001\u89c4\u5212\u3001\u8bb0\u5fc6\u3001\u76ee\u6807\u83b7\u53d6\u548c\u5bf9\u9f50\u80fd\u529b\u3002", "conclusion": "\u8be5\u7814\u7a76\u5f3a\u8c03\u4e86\u9700\u8981\u65b0\u7684\u57fa\u51c6\u6765\u6d4b\u8bd5\u548c\u8bc4\u4f30AGI\uff0c\u7279\u522b\u662f\u5728\u5305\u542b\u4e92\u52a8\u63a8\u7406\u6311\u6218\u7684\u65b0ARC-AGI-3\u7248\u672c\u4e2d\uff0c\u8fd9\u4e9b\u6311\u6218\u9700\u8981\u9ad8\u7ea7\u7684\u63a8\u7406\u80fd\u529b\u6765\u89e3\u51b3\u3002"}}
{"id": "2601.10922", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10922", "abs": "https://arxiv.org/abs/2601.10922", "authors": ["Yosub Shin", "Michael Buriek", "Boris Sobolev", "Pavel Bushuyeu", "Vikas Kumar", "Haoyang Xu", "Samuel Watson", "Igor Molybog"], "title": "What Matters in Data Curation for Multimodal Reasoning? Insights from the DCVLR Challenge", "comment": null, "summary": "We study data curation for multimodal reasoning through the NeurIPS 2025 Data Curation for Vision-Language Reasoning (DCVLR) challenge, which isolates dataset selection by fixing the model and training protocol. Using a compact curated dataset derived primarily from Walton Multimodal Cold Start, our submission placed first in the challenge. Through post-competition ablations, we show that difficulty-based example selection on an aligned base dataset is the dominant driver of performance gains. Increasing dataset size does not reliably improve mean accuracy under the fixed training recipe, but mainly reduces run-to-run variance, while commonly used diversity and synthetic augmentation heuristics provide no additional benefit and often degrade performance. These results characterize DCVLR as a saturation-regime evaluation and highlight the central role of alignment and difficulty in data-efficient multimodal reasoning.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7NeurIPS 2025 \u89c6\u89c9-\u8bed\u8a00\u63a8\u7406\u6570\u636e\u6574\u7406\u6311\u6218\uff0c\u5c55\u793a\u4e86\u96be\u5ea6\u9a71\u52a8\u7684\u6837\u672c\u9009\u62e9\u5bf9\u6570\u636e\u6574\u7406\u8fc7\u7a0b\u7684\u91cd\u8981\u6027\uff0c\u5e76\u63a2\u8ba8\u4e86\u6570\u636e\u96c6\u5927\u5c0f\u3001\u591a\u6837\u6027\u589e\u5f3a\u548c\u5408\u6210\u589e\u5f3a\u7684\u6548\u679c\u3002", "motivation": "\u4e3a\u4e86\u901a\u8fc7\u56fa\u5b9a\u6a21\u578b\u548c\u8bad\u7ec3\u534f\u8bae\u8bc4\u4f30\u4e0d\u540c\u7684\u6570\u636e\u96c6\u9009\u62e9\u7b56\u7565\uff0c\u5e76\u6df1\u5165\u7406\u89e3\u5728\u6570\u636e\u53d7\u9650\u6761\u4ef6\u4e0b\u6570\u636e\u6574\u7406\u7684\u6548\u679c\u3002", "method": "\u4f7f\u7528\u4e86\u6765\u81eaWalton Multimodal Cold Start\u7684\u7d27\u51d1\u578b\u6574\u7406\u6570\u636e\u96c6\uff0c\u5e76\u901a\u8fc7\u540e\u7ade\u8d5b\u5206\u6790\uff0c\u6bd4\u8f83\u4e86\u4e0d\u540c\u7b56\u7565\u4e0b\u7684\u6027\u80fd\u5dee\u5f02\u3002", "result": "\u96be\u5ea6\u9a71\u52a8\u7684\u6837\u672c\u9009\u62e9\u7b56\u7565\u662f\u6027\u80fd\u63d0\u5347\u7684\u4e3b\u8981\u56e0\u7d20\u3002\u5927\u89c4\u6a21\u6570\u636e\u96c6\u5bf9\u5e73\u5747\u51c6\u786e\u7387\u65e0\u663e\u8457\u63d0\u5347\uff0c\u4f46\u80fd\u51cf\u5c11\u8fd0\u884c\u95f4\u5dee\u5f02\u3002\u5e38\u7528\u7684\u6570\u636e\u591a\u6837\u6027\u589e\u5f3a\u548c\u5408\u6210\u589e\u5f3a\u5e76\u6ca1\u6709\u63d0\u4f9b\u989d\u5916\u5e2e\u52a9\uff0c\u6709\u65f6\u751a\u81f3\u4f1a\u964d\u4f4e\u6027\u80fd\u3002", "conclusion": "DCVLR \u6311\u6218\u8868\u660e\uff0c\u6570\u636e\u6574\u7406\u5904\u4e8e\u9971\u548c\u9636\u6bb5\uff0c\u5f3a\u8c03\u4e86\u6570\u636e\u6574\u7406\u4e2d\u4e00\u81f4\u6027\u548c\u96be\u5ea6\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2601.11173", "categories": ["cs.CR", "cs.LO"], "pdf": "https://arxiv.org/pdf/2601.11173", "abs": "https://arxiv.org/abs/2601.11173", "authors": ["Sirui Shen", "Zunchen Huang", "Chenglu Jin"], "title": "Proving Circuit Functional Equivalence in Zero Knowledge", "comment": null, "summary": "The modern integrated circuit ecosystem is increasingly reliant on third-party intellectual property integration, which introduces security risks, including hardware Trojans and security vulnerabilities. Addressing the resulting trust deadlock between IP vendors and system integrators without exposing proprietary designs requires novel privacy-preserving verification techniques. However, existing privacy-preserving hardware verification methods are all simulation-based and fail to offer formal guarantees. In this paper, we propose ZK-CEC, the first privacy-preserving framework for hardware formal verification. By combining formal verification and zero-knowledge proof (ZKP), ZK-CEC establishes a foundation for formally verifying IP correctness and security without compromising the confidentiality of the designs.\n  We observe that existing zero-knowledge protocols for formal verification are designed to prove statements of public formulas. However, in a privacy-preserving verification context where the formula is secret, these protocols cannot prevent a malicious prover from forging the formula, thereby compromising the soundness of the verification. To address these gaps, we first propose a blueprint for proving the unsatisfiability of a secret design against a public constraint, which is widely applicable to proving properties in software, hardware, and cyber-physical systems. Based on the proposed blueprint, we construct ZK-CEC, which enables a prover to convince the verifier that a secret IP's functionality aligns perfectly with the public specification in zero knowledge, revealing only the length and width of the proof. We implement ZK-CEC and evaluate its performance across various circuits, including arithmetic units and cryptographic components. Experimental results show that ZK-CEC successfully verifies practical designs, such as the AES S-Box, within practical time limits.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u9690\u79c1\u4fdd\u62a4\u786c\u4ef6\u5f62\u5f0f\u9a8c\u8bc1\u65b9\u6cd5ZK-CEC\uff0c\u901a\u8fc7\u7ed3\u5408\u5f62\u5f0f\u9a8c\u8bc1\u548c\u96f6\u77e5\u8bc6\u8bc1\u660e\uff08ZKP\uff09\uff0c\u80fd\u591f\u5728\u4e0d\u6cc4\u9732\u8bbe\u8ba1\u673a\u5bc6\u6027\u7684\u524d\u63d0\u4e0b\uff0c\u9a8c\u8bc1IP\u7684\u6b63\u786e\u6027\u53ca\u5b89\u5168\u6027\u3002", "motivation": "\u968f\u7740\u73b0\u4ee3\u96c6\u6210\u7535\u8def\u751f\u6001\u7cfb\u7edf\u8d8a\u6765\u8d8a\u591a\u5730\u4f9d\u8d56\u7b2c\u4e09\u65b9\u786c\u4ef6IP\u96c6\u6210\uff0c\u8fd9\u5e26\u6765\u4e86\u786c\u4ef6\u7279\u6d1b\u4f0a\u6728\u9a6c\u548c\u5b89\u5168\u6f0f\u6d1e\u7b49\u5b89\u5168\u98ce\u9669\u3002\u73b0\u6709\u7684\u9690\u79c1\u4fdd\u62a4\u786c\u4ef6\u9a8c\u8bc1\u65b9\u6cd5\u5927\u591a\u57fa\u4e8e\u4eff\u771f\uff0c\u65e0\u6cd5\u63d0\u4f9b\u5f62\u5f0f\u4e0a\u7684\u4fdd\u8bc1\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u5728\u73b0\u6709\u7814\u7a76\u7684\u57fa\u7840\u4e0a\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5f15\u5165\u6b63\u5f0f\u9a8c\u8bc1\u548c\u96f6\u77e5\u8bc6\u8bc1\u660e\uff08ZKP\uff09\u7684\u65b0\u9896\u6846\u67b6ZK-CEC\u3002\u8be5\u65b9\u6cd5\u63d0\u51fa\u4e86\u4e00\u79cd\u8bc1\u660e\u79d8\u5bc6\u8bbe\u8ba1\u4e0e\u516c\u5171\u7ea6\u675f\u7684\u4e0d\u6ee1\u8db3\u6027\u7684\u84dd\u56fe\uff0c\u5e76\u57fa\u4e8e\u8be5\u84dd\u56fe\u6784\u5efa\u4e86ZK-CEC\uff0c\u4ee5\u5b9e\u73b0\u4ec5\u63ed\u793a\u8bc1\u660e\u7684\u957f\u5ea6\u548c\u5bbd\u5ea6\u7684\u65b9\u5f0f\u9a8c\u8bc1\u9690\u85cf\u8bbe\u8ba1\u662f\u5426\u7b26\u5408\u516c\u5f00\u89c4\u8303\u7684\u529f\u80fd\u3002", "result": "ZK-CEC\u5df2\u88ab\u5b9e\u73b0\u5e76\u5728\u4e0d\u540c\u7535\u8def\u4e2d\u8fdb\u884c\u4e86\u6027\u80fd\u8bc4\u4f30\uff0c\u5305\u62ec\u7b97\u672f\u5355\u5143\u548c\u52a0\u5bc6\u7ec4\u4ef6\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cZK-CEC\u80fd\u591f\u5728\u5408\u7406\u7684\u65f6\u95f4\u5185\u9a8c\u8bc1\u5b9e\u9645\u8bbe\u8ba1\uff0c\u4f8b\u5982AES S-Box\u3002", "conclusion": "ZK-CEC\u4e3a\u6b63\u5f0f\u9a8c\u8bc1\u79c1\u6709\u786c\u4ef6IP\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\u548c\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u5728\u5b9e\u9645\u5e94\u7528\u573a\u666f\u4e2d\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2601.11199", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11199", "abs": "https://arxiv.org/abs/2601.11199", "authors": ["Aiman Al Masoud", "Marco Arazzi", "Antonino Nocera"], "title": "SD-RAG: A Prompt-Injection-Resilient Framework for Selective Disclosure in Retrieval-Augmented Generation", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) has attracted significant attention due to its ability to combine the generative capabilities of Large Language Models (LLMs) with knowledge obtained through efficient retrieval mechanisms over large-scale data collections. Currently, the majority of existing approaches overlook the risks associated with exposing sensitive or access-controlled information directly to the generation model. Only a few approaches propose techniques to instruct the generative model to refrain from disclosing sensitive information; however, recent studies have also demonstrated that LLMs remain vulnerable to prompt injection attacks that can override intended behavioral constraints. For these reasons, we propose a novel approach to Selective Disclosure in Retrieval-Augmented Generation, called SD-RAG, which decouples the enforcement of security and privacy constraints from the generation process itself. Rather than relying on prompt-level safeguards, SD-RAG applies sanitization and disclosure controls during the retrieval phase, prior to augmenting the language model's input. Moreover, we introduce a semantic mechanism to allow the ingestion of human-readable dynamic security and privacy constraints together with an optimized graph-based data model that supports fine-grained, policy-aware retrieval. Our experimental evaluation demonstrates the superiority of SD-RAG over baseline existing approaches, achieving up to a $58\\%$ improvement in the privacy score, while also showing a strong resilience to prompt injection attacks targeting the generative model.", "AI": {"tldr": "SD-RAG \u662f\u4e00\u79cd\u65b0\u7684 RAG \u6280\u672f\uff0c\u901a\u8fc7\u5728\u68c0\u7d22\u9636\u6bb5\u5e94\u7528\u6e05\u6d17\u548c\u62ab\u9732\u63a7\u5236\u6765\u5206\u79bb\u5b89\u5168\u548c\u9690\u79c1\u7ea6\u675f\u7684\u6267\u884c\uff0c\u800c\u4e0d\u662f\u4f9d\u8d56\u4e8e\u63d0\u793a\u7ea7\u522b\u7684\u4fdd\u62a4\u63aa\u65bd\u3002SD-RAG \u8fd8\u5141\u8bb8\u4e0e\u4f18\u5316\u7684\u56fe\u57fa\u6570\u636e\u6a21\u578b\u4e00\u8d77\u6444\u53d6\u53ef\u8bfb\u7684\u52a8\u6001\u5b89\u5168\u548c\u9690\u79c1\u7ea6\u675f\uff0c\u5b9e\u73b0\u4e86\u5bf9\u751f\u6210\u6a21\u578b\u7684\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u7684\u5f3a\u5927\u62b5\u6297\u529b\uff0c\u5e76\u5728\u9690\u79c1\u8bc4\u5206\u4e0a\u53d6\u5f97\u4e86\u9ad8\u8fbe 58% \u7684\u6539\u8fdb\u3002", "motivation": "\u73b0\u6709\u7684 RAG \u65b9\u6cd5\u7f3a\u4e4f\u6709\u6548\u7684\u673a\u5236\u6765\u9632\u6b62\u654f\u611f\u4fe1\u606f\u7684\u6cc4\u9732\uff0c\u800c\u6700\u8fd1\u7684\u653b\u51fb\u8868\u660e\uff0cLLMs \u5bf9\u4e8e\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u4ecd\u6709\u4e00\u5b9a\u7684\u8106\u5f31\u6027\u3002\u56e0\u6b64\uff0c\u63d0\u51fa\u4e86 SD-RAG \u4ee5\u589e\u5f3a RAG \u65b9\u6cd5\u4e2d\u7684\u5b89\u5168\u6027\u548c\u9690\u79c1\u6027\u3002", "method": "SD-RAG \u901a\u8fc7\u5728\u68c0\u7d22\u9636\u6bb5\u6267\u884c\u6e05\u6d17\u548c\u62ab\u9732\u63a7\u5236\u6765\u5b9e\u65bd\u5b89\u5168\u548c\u9690\u79c1\u7ea6\u675f\uff0c\u907f\u514d\u76f4\u63a5\u5c06\u654f\u611f\u6216\u8bbf\u95ee\u53d7\u63a7\u7684\u4fe1\u606f\u4f20\u9012\u7ed9\u751f\u6210\u6a21\u578b\u3002\u6b64\u5916\uff0cSD-RAG \u4f7f\u7528\u4e86\u53ef\u8bfb\u7684\u52a8\u6001\u5b89\u5168\u4e0e\u9690\u79c1\u7ea6\u675f\u4ee5\u53ca\u4f18\u5316\u7684\u56fe\u57fa\u6570\u636e\u6a21\u578b\u8fdb\u6570\u636e\u68c0\u7d22\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cSD-RAG \u76f8\u5bf9\u4e8e\u73b0\u6709\u57fa\u51c6\u65b9\u6cd5\u5728\u9690\u79c1\u8bc4\u5206\u4e0a\u63d0\u9ad8\u4e86 58%\uff0c\u5e76\u4e14\u5c55\u793a\u4e86\u62b5\u6297\u9488\u5bf9\u751f\u6210\u6a21\u578b\u7684\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u7684\u5f3a\u5927\u80fd\u529b\u3002", "conclusion": "\u603b\u7ed3\u6765\u8bf4\uff0cSD-RAG \u901a\u8fc7\u6539\u8fdb\u7684\u68c0\u7d22\u9636\u6bb5\u63a7\u5236\u548c\u52a8\u6001\u5b89\u5168\u7b56\u7565\u6709\u6548\u63d0\u5347\u4e86 RAG \u65b9\u6cd5\u7684\u5b89\u5168\u6027\u548c\u9690\u79c1\u6027\uff0c\u4e3a\u672a\u6765\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\u3002"}}
{"id": "2601.11012", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11012", "abs": "https://arxiv.org/abs/2601.11012", "authors": ["Jiahao Wang", "Shuangjia Zheng"], "title": "Efficient Protein Optimization via Structure-aware Hamiltonian Dynamics", "comment": null, "summary": "The ability to engineer optimized protein variants has transformative potential for biotechnology and medicine. Prior sequence-based optimization methods struggle with the high-dimensional complexities due to the epistasis effect and the disregard for structural constraints. To address this, we propose HADES, a Bayesian optimization method utilizing Hamiltonian dynamics to efficiently sample from a structure-aware approximated posterior. Leveraging momentum and uncertainty in the simulated physical movements, HADES enables rapid transition of proposals toward promising areas. A position discretization procedure is introduced to propose discrete protein sequences from such a continuous state system. The posterior surrogate is powered by a two-stage encoder-decoder framework to determine the structure and function relationships between mutant neighbors, consequently learning a smoothed landscape to sample from. Extensive experiments demonstrate that our method outperforms state-of-the-art baselines in in-silico evaluations across most metrics. Remarkably, our approach offers a unique advantage by leveraging the mutual constraints between protein structure and sequence, facilitating the design of protein sequences with similar structures and optimized properties. The code and data are publicly available at https://github.com/GENTEL-lab/HADES.", "AI": {"tldr": "HADES\u662f\u4e00\u79cd\u5229\u7528\u8d1d\u53f6\u65af\u4f18\u5316\u65b9\u6cd5\u548c\u54c8\u5bc6\u987f\u52a8\u529b\u5b66\u6765\u9ad8\u6548\u63a2\u7d22\u7ed3\u6784\u611f\u77e5\u8fd1\u4f3c\u540e\u9a8c\u7684\u86cb\u767d\u8d28\u4f18\u5316\u6280\u672f\u3002\u8fd9\u79cd\u65b9\u6cd5\u80fd\u591f\u5feb\u901f\u5411\u6709\u5e0c\u671b\u7684\u533a\u57df\u63d0\u51fa\u63d0\u8bae\uff0c\u5e76\u5728\u6a21\u62df\u7269\u7406\u8fd0\u52a8\u4e2d\u5229\u7528\u52a8\u91cf\u548c\u4e0d\u786e\u5b9a\u6027\u3002\u53cc\u65b9\u7f16\u7801\u89e3\u7801\u6846\u67b6\u7528\u4e8e\u786e\u5b9a\u7a81\u53d8\u90bb\u5c45\u4e4b\u95f4\u7684\u7ed3\u6784\u548c\u529f\u80fd\u5173\u7cfb\uff0c\u4ece\u800c\u5b66\u4e60\u4e00\u79cd\u5e73\u6ed1\u7684\u91c7\u6837\u666f\u89c2\u3002HADES\u5728\u591a\u79cd\u6307\u6807\u4e0a\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5e8f\u5217\u7684\u4f18\u5316\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u9ad8\u7ef4\u5ea6\u590d\u6742\u6027\u53ca\u5ffd\u89c6\u7ed3\u6784\u7ea6\u675f\u7684\u95ee\u9898\uff0c\u800cHADES\u5219\u901a\u8fc7\u6574\u5408\u7ed3\u6784\u548c\u5e8f\u5217\u5173\u7cfb\u6765\u4f18\u5316\u86cb\u767d\u8d28\uff0c\u4e3a\u751f\u7269\u6280\u672f\u548c\u533b\u5b66\u9886\u57df\u7684\u5de5\u7a0b\u63d0\u4f9b\u65b0\u7684\u53ef\u80fd\u6027\u3002", "method": "HADES\u91c7\u7528\u8d1d\u53f6\u65af\u4f18\u5316\u65b9\u6cd5\uff0c\u5e76\u5229\u7528\u54c8\u5bc6\u987f\u52a8\u529b\u5b66\u9ad8\u6548\u63a2\u7d22\u7ed3\u6784\u654f\u611f\u7684\u8fd1\u4f3c\u540e\u9a8c\u3002\u901a\u8fc7\u52a8\u91cf\u548c\u4e0d\u786e\u5b9a\u6027\u589e\u5f3a\u6a21\u62df\u7269\u7406\u8fd0\u52a8\u8fc7\u7a0b\uff0c\u5f15\u5165\u4f4d\u7f6e\u79bb\u6563\u5316\u6280\u672f\u4ee5\u63d0\u51fa\u79bb\u6563\u7684\u86cb\u767d\u8d28\u5e8f\u5217\uff0c\u5e76\u4f7f\u7528\u4e24\u9636\u6bb5\u7f16\u7801\u89e3\u7801\u6846\u67b6\u6765\u6784\u5efa\u7ed3\u6784\u548c\u529f\u80fd\u5173\u7cfb\u6a21\u578b\u3002", "result": "HADES\u5728\u591a\u79cd\u6307\u6807\u4e0a\u4f18\u4e8e\u73b0\u6709\u7684\u5148\u8fdb\u65b9\u6cd5\u3002\u5b9e\u9a8c\u7ed3\u679c\u5c55\u793a\u4e86HADES\u5728\u86cb\u767d\u8d28\u4f18\u5316\u4e2d\u7684\u4f18\u52bf\uff0c\u5c24\u5176\u662f\u5728\u7ed3\u6784\u611f\u77e5\u4f18\u5316\u65b9\u9762\u3002", "conclusion": "HADES\u4e3a\u4f18\u5316\u86cb\u767d\u8d28\u5e8f\u5217\u63d0\u4f9b\u4e86\u6539\u8fdb\u7b56\u7565\uff0c\u5c24\u5176\u5728\u6574\u5408\u7ed3\u6784\u548c\u5e8f\u5217\u5173\u7cfb\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u5c55\u793a\u4e86\u5176\u5728\u751f\u7269\u6280\u672f\u548c\u533b\u5b66\u5de5\u7a0b\u4e2d\u7684\u6f5c\u5728\u5e94\u7528\u4ef7\u503c\u3002\u76f8\u5173\u4ee3\u7801\u548c\u6570\u636e\u53ef\u4ee5\u5728\u516c\u5f00\u4ed3\u5e93\u4e2d\u83b7\u53d6\u3002"}}
{"id": "2601.11368", "categories": ["cs.CR", "cs.AR"], "pdf": "https://arxiv.org/pdf/2601.11368", "abs": "https://arxiv.org/abs/2601.11368", "authors": ["Ishraq Tashdid", "Tasnuva Farheen", "Sazadur Rahman"], "title": "InterPUF: Distributed Authentication via Physically Unclonable Functions and Multi-party Computation for Reconfigurable Interposers", "comment": "Accepted to IEEE International Symposium on Hardware Oriented Security and Trust (HOST) 2026", "summary": "Modern system-in-package (SiP) platforms increasingly adopt reconfigurable interposers to enable plug-and-play chiplet integration across heterogeneous multi-vendor ecosystems. However, this flexibility introduces severe trust challenges, as traditional authentication schemes fail to scale or adapt in decentralized, post-fabrication programmable environments. This paper presents InterPUF, a compact and scalable authentication framework that transforms the interposer into a distributed root of trust. InterPUF embeds a route-based differential delay physically unclonable function (PUF) across the reconfigurable interconnect and secures authentication using multi-party computation (MPC), ensuring raw PUF signatures are never exposed. Our hardware evaluation shows only 0.23% area and 0.072% power overhead across diverse chiplets while preserving authentication latency within tens of nanoseconds. Simulation results using pyPUF confirm strong uniqueness, reliability, and modeling resistance under process, voltage, and temperature variations. By combining interposer-resident PUF primitives with cryptographic hashing and collaborative verification, InterPUF enforces a minimal-trust authentication model without relying on a centralized anchor.", "AI": {"tldr": "InterPUF \u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8def\u7531\u5dee\u5f02\u5ef6\u8fdf PUF \u7684\u5206\u5e03\u5f0f\u6839\u4fe1\u4efb\u6846\u67b6\uff0c\u4ee5\u63d0\u4f9b\u7075\u6d3b\u4e14\u5b89\u5168\u7684\u82af\u7247\u7ea7\u4e92\u8fde\u8eab\u4efd\u9a8c\u8bc1\u3002", "motivation": "\u968f\u7740\u73b0\u4ee3\u7cfb\u7edf\u7ea7\u5c01\u88c5\u5e73\u53f0\u91c7\u7528\u53ef\u91cd\u6784\u7684\u4e2d\u4ecb\u5c42\uff0c\u5b9e\u73b0\u4e86\u5f02\u6784\u591a\u4f9b\u5e94\u5546\u751f\u6001\u7cfb\u7edf\u4e2d\u7684\u5373\u63d2\u5373\u7528\u82af\u7247\u7ea7\u96c6\u6210\u3002\u7136\u800c\uff0c\u8fd9\u589e\u52a0\u4e86\u4fe1\u4efb\u6311\u6218\uff0c\u4f20\u7edf\u7684\u8eab\u4efd\u9a8c\u8bc1\u65b9\u6848\u65e0\u6cd5\u5728\u5206\u6563\u7684\u3001\u540e\u5236\u9020\u53ef\u7f16\u7a0b\u73af\u5883\u4e2d\u8fdb\u884c\u6269\u5c55\u6216\u9002\u5e94\u3002", "method": "InterPUF \u901a\u8fc7\u5d4c\u5165\u57fa\u4e8e\u8def\u7531\u7684\u5dee\u5f02\u5ef6\u8fdf\u7269\u7406\u4e0d\u53ef\u514b\u9686\u51fd\u6570\uff08PUF\uff09\u5230\u53ef\u91cd\u6784\u4e92\u8fde\u4e2d\uff0c\u5e76\u4f7f\u7528\u591a\u65b9\u8ba1\u7b97\uff08MPC\uff09\u8fdb\u884c\u8eab\u4efd\u9a8c\u8bc1\uff0c\u786e\u4fdd\u539f\u59cb PUF \u7b7e\u540d\u4e0d\u88ab\u66b4\u9732\u3002", "result": "\u786c\u4ef6\u8bc4\u4f30\u663e\u793a\uff0cInterPUF \u5728\u4e0d\u540c\u82af\u7247\u4e0a\u4ec5\u5360\u7528 0.23% \u7684\u9762\u79ef\u548c 0.072% \u7684\u529f\u7387\uff0c\u5e76\u4e14\u4fdd\u6301\u4e86\u6570\u5341\u7eb3\u79d2\u7684\u8ba4\u8bc1\u5ef6\u8fdf\uff0c\u800c\u4eff\u771f\u7684 pyPUF \u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6848\u5728\u5de5\u827a\u3001\u7535\u538b\u548c\u6e29\u5ea6\u6ce2\u52a8\u4e0b\u7684\u552f\u4e00\u6027\u3001\u53ef\u9760\u6027\u548c\u5efa\u6a21\u62b5\u6297\u529b\u5f88\u5f3a\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u5408\u4e2d\u4ecb\u5668\u5185\u5d4c\u7684 PUF \u539f\u8bed\u3001\u52a0\u5bc6\u6563\u5217\u548c\u534f\u4f5c\u9a8c\u8bc1\uff0cInterPUF \u5b9e\u73b0\u4e86\u4e00\u4e2a\u57fa\u4e8e\u6700\u5c0f\u4fe1\u4efb\u7684\u8eab\u4efd\u9a8c\u8bc1\u6a21\u578b\uff0c\u800c\u65e0\u9700\u4f9d\u8d56\u4e2d\u592e\u951a\u70b9\u3002"}}
{"id": "2601.11398", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.11398", "abs": "https://arxiv.org/abs/2601.11398", "authors": ["Kurt Thomas", "Sai Teja Peddinti", "Sarah Meiklejohn", "Tara Matthews", "Amelia Hassoun", "Animesh Srivastava", "Jessica McClearn", "Patrick Gage Kelley", "Sunny Consolvo", "Nina Taft"], "title": "Understanding Help Seeking for Digital Privacy, Safety, and Security", "comment": null, "summary": "The complexity of navigating digital privacy, safety, and security threats often falls directly on users. This leads to users seeking help from family and peers, platforms and advice guides, dedicated communities, and even large language models (LLMs). As a precursor to improving resources across this ecosystem, our community needs to understand what help seeking looks like in the wild. To that end, we blend qualitative coding with LLM fine-tuning to sift through over one billion Reddit posts from the last four years to identify where and for what users seek digital privacy, safety, or security help. We isolate three million relevant posts with 93% precision and recall and automatically annotate each with the topics discussed (e.g., security tools, privacy configurations, scams, account compromise, content moderation, and more). We use this dataset to understand the scope and scale of help seeking, the communities that provide help, and the types of help sought. Our work informs the development of better resources for users (e.g., user guides or LLM help-giving agents) while underscoring the inherent challenges of supporting users through complex combinations of threats, platforms, mitigations, context, and emotions.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u5bf9\u5927\u91cfReddit\u5e16\u5b50\u8fdb\u884c\u5206\u6790\uff0c\u8bc6\u522b\u7528\u6237\u5728\u6570\u5b57\u9690\u79c1\u3001\u5b89\u5168\u548c\u5b89\u5168\u65b9\u9762\u5bfb\u6c42\u5e2e\u52a9\u7684\u4f4d\u7f6e\u548c\u5185\u5bb9\uff0c\u4ee5\u66f4\u597d\u5730\u7406\u89e3\u548c\u89e3\u51b3\u95ee\u9898\uff0c\u4e3a\u7528\u6237\u63d0\u4f9b\u66f4\u597d\u7684\u8d44\u6e90\u3002", "motivation": "\u4e3a\u4e86\u66f4\u597d\u5730\u7406\u89e3\u7528\u6237\u5728\u5b9e\u9645\u4e2d\u5982\u4f55\u5bfb\u6c42\u5e2e\u52a9\uff0c\u7814\u7a76\u4eba\u5458\u5229\u7528\u6df7\u5408\u8d28\u6027\u7f16\u7801\u548c\u5927\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u7684\u65b9\u6cd5\uff0c\u5206\u6790\u4e86\u5927\u91cfReddit\u5e16\u5b50\uff0c\u4ee5\u4e86\u89e3\u6c42\u52a9\u7684\u8303\u56f4\u3001\u89c4\u6a21\uff0c\u63d0\u4f9b\u5e2e\u52a9\u7684\u793e\u533a\u7c7b\u578b\uff0c\u4ee5\u53ca\u6c42\u52a9\u7c7b\u578b\u3002", "method": "\u7814\u7a76\u4eba\u5458\u4f7f\u7528\u6df7\u5408\u8d28\u6027\u7f16\u7801\u548c\u5927\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u7684\u65b9\u6cd5\uff0c\u4ece\u8fc7\u53bb\u56db\u5e74\u8d85\u8fc710\u4ebf\u7684Reddit\u5e16\u5b50\u4e2d\u7b5b\u9009\u51fa93%\u7cbe\u5ea6\u548c\u53ec\u56de\u7387\u7684\u76f8\u5173\u5e16\u5b50\uff0c\u5e76\u81ea\u52a8\u6807\u6ce8\u4e86\u8ba8\u8bba\u7684\u4e3b\u9898\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff0c\u7528\u6237\u5728\u6570\u5b57\u9690\u79c1\u3001\u5b89\u5168\u548c\u5b89\u5168\u65b9\u9762\u7684\u95ee\u9898\u8bf7\u6c42\u6d89\u53ca\u591a\u79cd\u4e3b\u9898\uff0c\u5305\u62ec\u5b89\u5168\u5de5\u5177\u3001\u9690\u79c1\u8bbe\u7f6e\u3001\u6b3a\u8bc8\u3001\u8d26\u53f7\u4e22\u5931\u7b49\u3002\u793e\u533a\u548c\u7528\u6237\u901a\u8fc7\u5e73\u53f0\u548c\u5176\u4ed6\u8d44\u6e90\u63d0\u4f9b\u5e2e\u52a9\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u5728\u590d\u6742\u5a01\u80c1\u548c\u8ba1\u5212\u7ec4\u5408\u4e0b\u652f\u6301\u7528\u6237\u6240\u9762\u4e34\u7684\u6311\u6218\uff0c\u8be5\u5de5\u4f5c\u4e3a\u5f00\u53d1\u66f4\u597d\u7684\u7528\u6237\u6307\u5357\u6216\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u5e2e\u52a9\u63d0\u4f9b\u4e86\u4fe1\u606f\u3002"}}
{"id": "2601.11147", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11147", "abs": "https://arxiv.org/abs/2601.11147", "authors": ["Zixu Wang", "Bingbing Xu", "Yige Yuan", "Huawei Shen", "Xueqi Cheng"], "title": "Do We Always Need Query-Level Workflows? Rethinking Agentic Workflow Generation for Multi-Agent Systems", "comment": "17 pages, 4 figures, 3 tables", "summary": "Multi-Agent Systems (MAS) built on large language models typically solve complex tasks by coordinating multiple agents through workflows. Existing approaches generates workflows either at task level or query level, but their relative costs and benefits remain unclear. After rethinking and empirical analyses, we show that query-level workflow generation is not always necessary, since a small set of top-K best task-level workflows together already covers equivalent or even more queries. We further find that exhaustive execution-based task-level evaluation is both extremely token-costly and frequently unreliable. Inspired by the idea of self-evolution and generative reward modeling, we propose a low-cost task-level generation framework \\textbf{SCALE}, which means \\underline{\\textbf{S}}elf prediction of the optimizer with few shot \\underline{\\textbf{CAL}}ibration for \\underline{\\textbf{E}}valuation instead of full validation execution. Extensive experiments demonstrate that \\textbf{SCALE} maintains competitive performance, with an average degradation of just 0.61\\% compared to existing approach across multiple datasets, while cutting overall token usage by up to 83\\%.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4f4e\u6210\u672c\u7684\u4efb\u52a1\u7ea7\u751f\u6210\u6846\u67b6SCALE\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u5c11\u91cf\u6837\u672c\u6821\u51c6\u9884\u6d4b\u4f18\u5316\u5668\u6765\u8fdb\u884c\u8bc4\u4f30\uff0c\u800c\u65e0\u9700\u5b8c\u6574\u7684\u9a8c\u8bc1\u6267\u884c\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8be5\u6846\u67b6\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u6027\u80fd\u76f8\u5f53\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u9ad8\u8fbe83%\u7684\u4ee4\u724c\u4f7f\u7528\u91cf\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u751f\u6210\u5de5\u4f5c\u6d41\u65f6\u6210\u672c\u548c\u6536\u76ca\u4e0d\u660e\u786e\uff0c\u4e14\u5b58\u5728\u67e5\u8be2\u7ea7\u522b\u7684\u5de5\u4f5c\u6d41\u751f\u6210\u4e0d\u603b\u662f\u5fc5\u8981\u7684\u95ee\u9898\uff0c\u7814\u7a76\u53d1\u73b0\u901a\u8fc7\u5c11\u91cf\u6700\u4f73\u4efb\u52a1\u7ea7\u5de5\u4f5c\u6d41\u5373\u53ef\u8986\u76d6\u76f8\u5f53\u6570\u91cf\u7684\u67e5\u8be2\u3002\u672c\u6587\u65e8\u5728\u63d0\u51fa\u4e00\u79cd\u4f4e\u6210\u672c\u7684\u4efb\u52a1\u7ea7\u751f\u6210\u6846\u67b6\uff0c\u4ee5\u51cf\u5c11\u8ba1\u7b97\u6210\u672c\u5e76\u63d0\u9ad8\u8bc4\u4f30\u6548\u7387\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aSCALE\u7684\u4f4e\u6210\u672c\u4efb\u52a1\u7ea7\u751f\u6210\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u4f9d\u9760\u5c11\u91cf\u6837\u672c\u6821\u51c6\u6765\u9884\u6d4b\u4f18\u5316\u5668\u7684\u6548\u679c\uff0c\u907f\u514d\u4e86\u5168\u9762\u9a8c\u8bc1\u6267\u884c\u7684\u6210\u672c\u3002", "result": "\u7ecf\u8fc7\u5e7f\u6cdb\u7684\u5b9e\u9a8c\uff0c\u4e0e\u73b0\u6709\u7684\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8be5\u6846\u67b6\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u4fdd\u6301\u4e86\u7ade\u4e89\u529b\uff0c\u6027\u80fd\u4e0b\u964d\u5e73\u5747\u4ec50.61%\uff0c\u540c\u65f6\u5728\u4ee4\u724c\u4f7f\u7528\u4e0a\u964d\u4f4e\u4e86\u9ad8\u8fbe83%\u3002", "conclusion": "\u7814\u7a76\u8bc1\u660e\u4e86SCALE\u5728\u51cf\u5c11\u6210\u672c\u540c\u65f6\u4fdd\u6301\u6027\u80fd\u7684\u6709\u6548\u6027\uff0c\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u5de5\u4f5c\u6d41\u751f\u6210\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u4f4e\u6210\u672c\u65b9\u6cd5\u3002"}}
{"id": "2601.11178", "categories": ["cs.AI", "cs.CL", "cs.MM", "cs.SI"], "pdf": "https://arxiv.org/pdf/2601.11178", "abs": "https://arxiv.org/abs/2601.11178", "authors": ["Girish A. Koushik", "Helen Treharne", "Diptesh Kanojia"], "title": "TANDEM: Temporal-Aware Neural Detection for Multimodal Hate Speech", "comment": "Under review at ICWSM 2026", "summary": "Social media platforms are increasingly dominated by long-form multimodal content, where harmful narratives are constructed through a complex interplay of audio, visual, and textual cues. While automated systems can flag hate speech with high accuracy, they often function as \"black boxes\" that fail to provide the granular, interpretable evidence, such as precise timestamps and target identities, required for effective human-in-the-loop moderation. In this work, we introduce TANDEM, a unified framework that transforms audio-visual hate detection from a binary classification task into a structured reasoning problem. Our approach employs a novel tandem reinforcement learning strategy where vision-language and audio-language models optimize each other through self-constrained cross-modal context, stabilizing reasoning over extended temporal sequences without requiring dense frame-level supervision. Experiments across three benchmark datasets demonstrate that TANDEM significantly outperforms zero-shot and context-augmented baselines, achieving 0.73 F1 in target identification on HateMM (a 30% improvement over state-of-the-art) while maintaining precise temporal grounding. We further observe that while binary detection is robust, differentiating between offensive and hateful content remains challenging in multi-class settings due to inherent label ambiguity and dataset imbalance. More broadly, our findings suggest that structured, interpretable alignment is achievable even in complex multimodal settings, offering a blueprint for the next generation of transparent and actionable online safety moderation tools.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86TANDEM\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u97f3\u9891-\u89c6\u89c9\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u95ee\u9898\uff0c\u901a\u8fc7\u53cc\u5411\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u5728\u957f\u65f6\u5e8f\u4e0a\u8fdb\u884c\u7a33\u5b9a\u63a8\u7406\uff0c\u800c\u4e0d\u9700\u8981\u5bc6\u96c6\u7684\u65f6\u95f4\u70b9\u76d1\u7763\u3002\u8be5\u65b9\u6cd5\u5728\u4e09\u9879\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u83b7\u5f97\u4e86\u663e\u8457\u6548\u679c\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u65f6\u95f4\u5b9a\u4f4d\u7684\u7cbe\u5ea6\u3002", "motivation": "\u5f53\u524d\u81ea\u52a8\u7cfb\u7edf\u5728\u68c0\u6d4b\u4ec7\u6068\u8a00\u8bba\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5b83\u4eec\u5f80\u5f80\u65e0\u6cd5\u63d0\u4f9b\u7cbe\u7ec6\u3001\u53ef\u89e3\u91ca\u7684\u8bc1\u636e\uff0c\u5bfc\u81f4\u4eba\u7c7b\u4ecb\u5165\u7684\u56f0\u96be\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u5f15\u5165TANDEM\u4ee5\u63d0\u9ad8\u591a\u6a21\u6001\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u7684\u900f\u660e\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\u3002", "method": "TANDEM\u91c7\u7528\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u53cc\u5411\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\uff0c\u4f7f\u89c6\u542c\u8bed\u8a00\u6a21\u578b\u76f8\u4e92\u4f18\u5316\uff0c\u589e\u5f3a\u4e0a\u4e0b\u6587\u8de8\u6a21\u6001\u4e00\u81f4\u6027\uff0c\u4ece\u800c\u5728\u957f\u65f6\u95f4\u5e8f\u5217\u4e0a\u8fdb\u884c\u7a33\u5b9a\u63a8\u7406\uff0c\u65e0\u9700\u5bc6\u96c6\u7684\u65f6\u95f4\u70b9\u76d1\u7763\u3002", "result": "TANDEM\u5728\u4e09\u9879\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u611f\u77e5\u76ee\u6807\u8bc6\u522b\u7684\u6700\u4f73F1\u5206\u6570\u8fbe\u52300.73\uff0c\u5728HateMM\u6570\u636e\u96c6\uff08\u76f8\u5bf9\u4e8e\u73b0\u6709\u6700\u4f73\u6548\u679c\u63d0\u9ad830%\uff09\u4e0a\u8868\u73b0\u51fa\u8f83\u9ad8\u7684\u65f6\u95f4\u5b9a\u4f4d\u7cbe\u5ea6\u3002", "conclusion": "TANDEM\u4e0d\u4ec5\u5c55\u73b0\u4e86\u5728\u590d\u6742\u591a\u6a21\u6001\u73af\u5883\u4e2d\u7684\u7ed3\u6784\u5316\u53ef\u89e3\u91ca\u6027\u5bf9\u9f50\u7684\u53ef\u884c\u6027\uff0c\u8fd8\u4e3a\u4e0b\u4e00\u4ee3\u900f\u660e\u6709\u6548\u7684\u5728\u7ebf\u5b89\u5168\u5c4f\u853d\u5de5\u5177\u63d0\u4f9b\u4e86\u4e00\u4e2a\u8303\u4f8b\u3002"}}
{"id": "2601.11252", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11252", "abs": "https://arxiv.org/abs/2601.11252", "authors": ["Qianyue Wang", "Jinwu Hu", "Yufeng Wang", "Huanxiang Lin", "Bolin Chen", "Zhiquan Wen", "Yaofo Chen", "Mingkui Tan"], "title": "Beyond Model Scaling: Test-Time Intervention for Efficient Deep Reasoning", "comment": null, "summary": "Large Reasoning Models (LRMs) excel at multi-step reasoning but often suffer from inefficient reasoning processes like overthinking and overshoot, where excessive or misdirected reasoning increases computational cost and degrades performance. Existing efficient reasoning methods operate in a closed-loop manner, lacking mechanisms for external intervention to guide the reasoning process. To address this, we propose Think-with-Me, a novel test-time interactive reasoning paradigm that introduces external feedback intervention into the reasoning process. Our key insights are that transitional conjunctions serve as natural points for intervention, signaling phases of self-validation or exploration and using transitional words appropriately to prolong the reasoning enhances performance, while excessive use affects performance. Building on these insights, Think-with-Me pauses reasoning at these points for external feedback, adaptively extending or terminating reasoning to reduce redundancy while preserving accuracy. The feedback is generated via a multi-criteria evaluation (rationality and completeness) and comes from either human or LLM proxies. We train the target model using Group Relative Policy Optimization (GRPO) to adapt to this interactive mode. Experiments show that Think-with-Me achieves a superior balance between accuracy and reasoning length under limited context windows. On AIME24, Think-with-Me outperforms QwQ-32B by 7.19% in accuracy while reducing average reasoning length by 81% under an 8K window. The paradigm also benefits security and creative tasks.", "AI": {"tldr": "Think-with-Me \u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6d4b\u8bd5\u65f6\u4e92\u52a8\u63a8\u7406\u8303\u5f0f\uff0c\u901a\u8fc7\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u5f15\u5165\u5916\u90e8\u53cd\u9988\u5e72\u9884\u6765\u5e73\u8861\u63a8\u7406\u51c6\u786e\u6027\u548c\u957f\u5ea6\u3002", "motivation": "\u5f53\u524d\u7684\u9ad8\u6548\u63a8\u7406\u65b9\u6cd5\u901a\u5e38\u5728\u95ed\u73af\u4e2d\u8fd0\u884c\uff0c\u7f3a\u4e4f\u5916\u90e8\u5e72\u9884\u673a\u5236\u6765\u5f15\u5bfc\u63a8\u7406\u8fc7\u7a0b\u3002\u73b0\u6709\u7684\u6a21\u578b\u5728\u5904\u7406\u591a\u6b65\u63a8\u7406\u65f6\u5bb9\u6613\u51fa\u73b0\u8fc7\u5ea6\u63a8\u7406\u6216\u504f\u79bb\u8f68\u9053\u7684\u95ee\u9898\uff0c\u8fd9\u589e\u52a0\u4e86\u8ba1\u7b97\u6210\u672c\u5e76\u964d\u4f4e\u4e86\u6027\u80fd\u3002", "method": "Think-with-Me \u901a\u8fc7\u5f15\u5165\u4e00\u4e2a\u57fa\u4e8e\u591a\u6807\u51c6\u8bc4\u4f30\uff08\u5408\u7406\u6027\u4e0e\u5b8c\u6574\u6027\uff09\u7684\u5916\u90e8\u53cd\u9988\u673a\u5236\uff0c\u4f7f\u5f97\u63a8\u7406\u8fc7\u7a0b\u5728\u5173\u952e\u65f6\u523b\u6682\u505c\uff0c\u4ece\u800c\u51cf\u5c11\u5197\u4f59\uff0c\u540c\u65f6\u7ef4\u62a4\u51c6\u786e\u6027\u3002\u5177\u4f53\u65b9\u6cd5\u5305\u62ec\u8bc6\u522b\u8fc7\u6e21\u8fde\u8bcd\u4f5c\u4e3a\u5e72\u9884\u70b9\uff0c\u4ee5\u53ca\u6839\u636e\u8fd9\u4e9b\u70b9\u9002\u65f6\u63d0\u4f9b\u5916\u90e8\u53cd\u9988\uff0c\u4ece\u800c\u7075\u6d3b\u5730\u5ef6\u957f\u6216\u7ec8\u6b62\u63a8\u7406\u3002", "result": "\u5728\u5b9e\u9a8c\u4e2d\uff0cThink-with-Me \u5728 AIME24 \u6d4b\u8bd5\u96c6\u4e0a\u8fbe\u5230\u4e86\u4f18\u4e8e QwQ-32B \u7684\u6027\u80fd\uff0c\u51c6\u786e\u5ea6\u63d0\u9ad8\u4e86 7.19%\uff0c\u540c\u65f6\u5c06\u5e73\u5747\u63a8\u7406\u957f\u5ea6\u51cf\u5c11\u4e86 81%\u3002\u6b64\u5916\uff0c\u8be5\u8303\u5f0f\u4e5f\u9002\u7528\u4e8e\u5b89\u5168\u6027\u548c\u521b\u610f\u4efb\u52a1\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4e92\u52a8\u63a8\u7406\u65b9\u6cd5\uff0c\u6709\u6548\u5730\u7f13\u89e3\u4e86\u8fc7\u5ea6\u63a8\u7406\u6216\u504f\u79bb\u8f68\u9053\u7684\u95ee\u9898\uff0c\u540c\u65f6\u63d0\u9ad8\u4e86\u6a21\u578b\u5728\u6709\u9650\u4e0a\u4e0b\u6587\u7a97\u53e3\u4e2d\u7684\u6027\u80fd\u548c\u6548\u7387\u3002"}}
{"id": "2601.11286", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11286", "abs": "https://arxiv.org/abs/2601.11286", "authors": ["Weihong Qi", "Fan Huang", "Rasika Muralidharan", "Jisun An", "Haewoon Kwak"], "title": "XChoice: Explainable Evaluation of AI-Human Alignment in LLM-based Constrained Choice Decision Making", "comment": null, "summary": "We present XChoice, an explainable framework for evaluating AI-human alignment in constrained decision making. Moving beyond outcome agreement such as accuracy and F1 score, XChoice fits a mechanism-based decision model to human data and LLM-generated decisions, recovering interpretable parameters that capture the relative importance of decision factors, constraint sensitivity, and implied trade-offs. Alignment is assessed by comparing these parameter vectors across models, options, and subgroups. We demonstrate XChoice on Americans' daily time allocation using the American Time Use Survey (ATUS) as human ground truth, revealing heterogeneous alignment across models and activities and salient misalignment concentrated in Black and married groups. We further validate robustness of XChoice via an invariance analysis and evaluate targeted mitigation with a retrieval augmented generation (RAG) intervention. Overall, XChoice provides mechanism-based metrics that diagnose misalignment and support informed improvements beyond surface outcome matching.", "AI": {"tldr": "XChoice \u662f\u4e00\u4e2a\u53ef\u89e3\u91ca\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30 AI \u4e0e\u4eba\u7c7b\u5728\u53d7\u9650\u51b3\u7b56\u4e2d\u7684\u5bf9\u9f50\u60c5\u51b5\u3002\u901a\u8fc7\u5bf9\u6bd4\u673a\u5668\u5b66\u4e60\u6a21\u578b\u548c\u4eba\u7c7b\u51b3\u7b56\u4e2d\u53c2\u6570\u5411\u91cf\u7684\u53d8\u5316\uff0c\u63ed\u793a\u6a21\u578b\u4e0e\u4eba\u7c7b\u51b3\u7b56\u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u4ee5\u53ca\u4e0d\u540c\u7fa4\u4f53\u95f4\u7684\u5bf9\u9f50\u60c5\u51b5\u3002", "motivation": "\u5f53\u524d\u7684\u8bc4\u4f30\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u7ed3\u679c\u7684\u4e00\u81f4\u6027\uff0c\u5982\u51c6\u786e\u7387\u548c F1 \u5206\u6570\u7b49\uff0c\u4f46\u672a\u80fd\u63ed\u793a\u51b3\u7b56\u56e0\u7d20\u7684\u91cd\u8981\u6027\u3001\u7ea6\u675f\u654f\u611f\u6027\u53ca\u6743\u8861\u53d6\u820d\u80cc\u540e\u7684\u673a\u5236\u3002XChoice \u6846\u67b6\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u901a\u8fc7\u673a\u5236\u5efa\u6a21\u6765\u8bc4\u4f30 AI \u548c\u4eba\u7c7b\u51b3\u7b56\u4e4b\u95f4\u7684\u5bf9\u9f50\u3002", "method": "XChoice \u901a\u8fc7\u5c06\u673a\u5236\u57fa\u7840\u7684\u51b3\u7b56\u6a21\u578b\u62df\u5408\u5230\u4eba\u7c7b\u6570\u636e\u548c\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u51b3\u7b56\u4e0a\uff0c\u6355\u83b7\u51b3\u7b56\u56e0\u7d20\u7684\u91cd\u8981\u6027\u3001\u7ea6\u675f\u654f\u611f\u6027\u548c\u9690\u542b\u7684\u53d6\u820d\u3002\u7136\u540e\u901a\u8fc7\u6bd4\u8f83\u6a21\u578b\u3001\u9009\u9879\u548c\u5b50\u7ec4\u4e4b\u95f4\u7684\u53c2\u6570\u5411\u91cf\u6765\u8bc4\u4f30\u5bf9\u9f50\u3002", "result": "XChoice \u5728\u7f8e\u56fd\u4eba\u7684\u65e5\u5e38\u65f6\u95f4\u5206\u914d\u6570\u636e\u4e0a\u5c55\u793a\u4e86\u5dee\u5f02\u5316\u7684\u5bf9\u9f50\u60c5\u51b5\uff0c\u5e76\u5728\u4e0d\u540c\u6a21\u578b\u548c\u6d3b\u52a8\u4e2d\u53d1\u73b0\u663e\u8457\u7684\u4e0d\u5bf9\u9f50\u6a21\u5f0f\uff0c\u7279\u522b\u662f\u5728\u9ed1\u4eba\u548c\u5df2\u5a5a\u7fa4\u4f53\u4e2d\u3002", "conclusion": "XChoice \u63d0\u4f9b\u4e86\u673a\u5236\u57fa\u7840\u7684\u6307\u6807\uff0c\u4ee5\u8bca\u65ad\u4e0d\u4e00\u81f4\u5e76\u652f\u6301\u8d85\u51fa\u8868\u9762\u7ed3\u679c\u5339\u914d\u7684\u77e5\u60c5\u6539\u8fdb\u3002\u6b64\u5916\uff0cXChoice \u901a\u8fc7\u4e0d\u53d8\u6027\u5206\u6790\u9a8c\u8bc1\u4e86\u5176\u7a33\u5065\u6027\uff0c\u5e76\u8bc4\u4f30\u4e86\u5e26\u56de\u6eaf\u68c0\u7d22\u751f\u6210\uff08RAG\uff09\u5e72\u9884\u63aa\u65bd\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2601.11389", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11389", "abs": "https://arxiv.org/abs/2601.11389", "authors": ["Hedieh Haddad", "Thibault Falque", "Pierre Talbot", "Pascal Bouvry"], "title": "Hyperparameter Optimization of Constraint Programming Solvers", "comment": "28 pages, 3 figures. Submitted to Journal of Combinatorial Optimization. Special Issue: Recent applications, models and algorithms in Combinatorial Optimization", "summary": "The performance of constraint programming solvers is highly sensitive to the choice of their hyperparameters. Manually finding the best solver configuration is a difficult, time-consuming task that typically requires expert knowledge. In this paper, we introduce probe and solve algorithm, a novel two-phase framework for automated hyperparameter optimization integrated into the CPMpy library. This approach partitions the available time budget into two phases: a probing phase that explores different sets of hyperparameters using configurable hyperparameter optimization methods, followed by a solving phase where the best configuration found is used to tackle the problem within the remaining time.\n  We implement and compare two hyperparameter optimization methods within the probe and solve algorithm: Bayesian optimization and Hamming distance search. We evaluate the algorithm on two different constraint programming solvers, ACE and Choco, across 114 combinatorial problem instances, comparing their performance against the solver's default configurations.\n  Results show that using Bayesian optimization, the algorithm outperforms the solver's default configurations, improving solution quality for ACE in 25.4% of instances and matching the default performance in 57.9%, and for Choco, achieving superior results in 38.6% of instances. It also consistently surpasses Hamming distance search within the same framework, confirming the advantage of model-based exploration over simple local search. Overall, the probe and solve algorithm offers a practical, resource-aware approach for tuning constraint solvers that yields robust improvements across diverse problem types.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3a\u63a2\u9488\u4e0e\u6c42\u89e3\u7684\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u7ea6\u675f\u7f16\u7a0b\u6c42\u89e3\u5668\u7684\u8d85\u53c2\u6570\u4f18\u5316\u3002\u901a\u8fc7\u5728ACE\u548cChoco\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u6c42\u89e3\u5668\u7684\u8868\u73b0\u3002", "motivation": "\u624b\u52a8\u627e\u5230\u6700\u4f73\u6c42\u89e3\u5668\u914d\u7f6e\u662f\u4e00\u4e2a\u8017\u65f6\u4e14\u9700\u8981\u4e13\u5bb6\u77e5\u8bc6\u7684\u4efb\u52a1\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u65e8\u5728\u63d0\u51fa\u4e00\u79cd\u81ea\u52a8\u5316\u7684\u65b9\u6cd5\u6765\u4f18\u5316\u8fd9\u4e9b\u8d85\u53c2\u6570\u3002", "method": "\u8be5\u7814\u7a76\u5728CPMpy\u5e93\u4e2d\u5f15\u5165\u4e86\u4e00\u79cd\u63a2\u9488\u4e0e\u6c42\u89e3\u6846\u67b6\uff0c\u5c06\u53ef\u7528\u65f6\u95f4\u9884\u7b97\u5206\u4e3a\u4e24\u9636\u6bb5\uff1a\u63a2\u7d22\u9636\u6bb5\u4f7f\u7528\u4e0d\u540c\u8d85\u53c2\u6570\u4f18\u5316\u65b9\u6cd5\u63a2\u7d22\u4e0d\u540c\u7684\u8d85\u53c2\u6570\u96c6\uff0c\u968f\u540e\u7684\u6c42\u89e3\u9636\u6bb5\u4f7f\u7528\u6700\u4f73\u914d\u7f6e\u89e3\u51b3\u5b9e\u9645\u95ee\u9898\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u4f7f\u7528\u8d1d\u53f6\u65af\u4f18\u5316\u65b9\u6cd5\u65f6\uff0c\u7b97\u6cd5\u5728ACI\u4e0a\u63d0\u9ad8\u4e86\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\u768425.4%\uff0c\u8fbe\u5230\u9ed8\u8ba4\u914d\u7f6e\u768457.9%\uff0c\u5728Choco\u4e0a\u5219\u572838.6%\u7684\u5b9e\u4f8b\u4e2d\u8868\u73b0\u66f4\u4f18\u3002\u540c\u65f6\uff0c\u8be5\u65b9\u6cd5\u5728\u4e0e\u7b80\u8ddd\u79bb\u641c\u7d22\u7b97\u6cd5\u7684\u6bd4\u8f83\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u8fdb\u4e00\u6b65\u8bc1\u5b9e\u4e86\u57fa\u4e8e\u6a21\u578b\u7684\u63a2\u7d22\u7b56\u7565\u4f18\u4e8e\u7b80\u5355\u7684\u5c40\u90e8\u641c\u7d22\u3002", "conclusion": "\u63a2\u9488\u4e0e\u6c42\u89e3\u7b97\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u3001\u8d44\u6e90\u611f\u77e5\u7684\u65b9\u6cd5\uff0c\u80fd\u9002\u7528\u4e8e\u591a\u79cd\u95ee\u9898\u7c7b\u578b\uff0c\u4e3a\u8c03\u4f18\u7ea6\u675f\u6c42\u89e3\u5668\u5e26\u6765\u4e86\u7a33\u5065\u7684\u6539\u8fdb\u3002"}}
{"id": "2601.11468", "categories": ["cs.AI", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.11468", "abs": "https://arxiv.org/abs/2601.11468", "authors": ["Alessandro Padella", "Massimiliano de Leoni", "Marlon Dumas"], "title": "Exploring LLM Features in Predictive Process Monitoring for Small-Scale Event-Logs", "comment": "19 pages, 4 figure, TMIS journal submission", "summary": "Predictive Process Monitoring is a branch of process mining that aims to predict the outcome of an ongoing process. Recently, it leveraged machine-and-deep learning architectures. In this paper, we extend our prior LLM-based Predictive Process Monitoring framework, which was initially focused on total time prediction via prompting. The extension consists of comprehensively evaluating its generality, semantic leverage, and reasoning mechanisms, also across multiple Key Performance Indicators. Empirical evaluations conducted on three distinct event logs and across the Key Performance Indicators of Total Time and Activity Occurrence prediction indicate that, in data-scarce settings with only 100 traces, the LLM surpasses the benchmark methods. Furthermore, the experiments also show that the LLM exploits both its embodied prior knowledge and the internal correlations among training traces. Finally, we examine the reasoning strategies employed by the model, demonstrating that the LLM does not merely replicate existing predictive methods but performs higher-order reasoning to generate the predictions.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86\u6211\u4eec\u4e4b\u524d\u57fa\u4e8eLLM\u7684\u9884\u6d4b\u8fc7\u7a0b\u76d1\u63a7\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u6700\u521d\u4e13\u6ce8\u4e8e\u901a\u8fc7\u63d0\u793a\u603b\u65f6\u95f4\u9884\u6d4b\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u6570\u636e\u7a00\u7f3a\u7684\u60c5\u51b5\u4e0b\uff0cLLM\u5728\u603b\u65f6\u95f4\u548c\u6d3b\u52a8\u53d1\u751f\u9884\u6d4b\u65b9\u9762\u4f18\u4e8e\u57fa\u51c6\u65b9\u6cd5\u3002", "motivation": "\u9884\u6d4b\u8fc7\u7a0b\u76d1\u63a7\u662f\u8fc7\u7a0b\u6316\u6398\u4e2d\u7684\u4e00\u4e2a\u5206\u652f\uff0c\u65e8\u5728\u9884\u6d4b\u6b63\u5728\u8fdb\u884c\u7684\u8fc7\u7a0b\u7684\u7ed3\u679c\u3002\u672c\u6587\u6269\u5c55\u4e86\u4e4b\u524d\u7684\u57fa\u4e8eLLM\u7684\u9884\u6d4b\u8fc7\u7a0b\u76d1\u63a7\u6846\u67b6\uff0c\u4ee5\u8bc4\u4f30\u5176\u901a\u7528\u6027\u3001\u8bed\u4e49\u5229\u7528\u548c\u63a8\u7406\u673a\u5236\uff0c\u7279\u522b\u662f\u5728\u603b\u65f6\u95f4\u548c\u6d3b\u52a8\u53d1\u751f\u9884\u6d4b\u65b9\u9762\u3002", "method": "\u5b9e\u9a8c\u4f7f\u7528\u4e86\u4e09\u4e2a\u4e0d\u540c\u7684\u4e8b\u4ef6\u65e5\u5fd7\uff0c\u8bc4\u4f30\u4e86\u5728\u53ea\u6709100\u6761\u8f68\u8ff9\u7684\u6570\u636e\u7a00\u7f3a\u60c5\u51b5\u4e0bLLM\u76f8\u5bf9\u4e8e\u57fa\u51c6\u65b9\u6cd5\u7684\u8868\u73b0\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cLLM\u5728\u603b\u65f6\u95f4\u548c\u6d3b\u52a8\u53d1\u751f\u9884\u6d4b\u65b9\u9762\u7684\u8868\u73b0\u4f18\u4e8e\u57fa\u51c6\u65b9\u6cd5\uff0c\u8868\u660e\u5b83\u5229\u7528\u4e86\u5185\u90e8\u8bad\u7ec3\u8f68\u8ff9\u4e4b\u95f4\u7684\u8054\u7cfb\u548c\u5176\u5185\u7f6e\u7684\u5148\u9a8c\u77e5\u8bc6\u3002", "conclusion": "\u7814\u7a76\u8fd8\u8868\u660e\uff0c\u6a21\u578b\u91c7\u7528\u4e86\u9ad8\u7ea7\u63a8\u7406\u7b56\u7565\uff0c\u800c\u4e0d\u662f\u7b80\u5355\u5730\u590d\u5236\u73b0\u6709\u9884\u6d4b\u65b9\u6cd5\uff0c\u8fd9\u5bf9\u4e8e\u6539\u8fdb\u8fc7\u7a0b\u9884\u6d4b\u6027\u80fd\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2601.11479", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11479", "abs": "https://arxiv.org/abs/2601.11479", "authors": ["Yohai Trabelsi", "Guojun Xiong", "Fentabil Getnet", "St\u00e9phane Verguet", "Milind Tambe"], "title": "Health Facility Location in Ethiopia: Leveraging LLMs to Integrate Expert Knowledge into Algorithmic Planning", "comment": null, "summary": "Ethiopia's Ministry of Health is upgrading health posts to improve access to essential services, particularly in rural areas. Limited resources, however, require careful prioritization of which facilities to upgrade to maximize population coverage while accounting for diverse expert and stakeholder preferences. In collaboration with the Ethiopian Public Health Institute and Ministry of Health, we propose a hybrid framework that systematically integrates expert knowledge with optimization techniques. Classical optimization methods provide theoretical guarantees but require explicit, quantitative objectives, whereas stakeholder criteria are often articulated in natural language and difficult to formalize. To bridge these domains, we develop the Large language model and Extended Greedy (LEG) framework. Our framework combines a provable approximation algorithm for population coverage optimization with LLM-driven iterative refinement that incorporates human-AI alignment to ensure solutions reflect expert qualitative guidance while preserving coverage guarantees. Experiments on real-world data from three Ethiopian regions demonstrate the framework's effectiveness and its potential to inform equitable, data-driven health system planning.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u4e13\u5bb6\u77e5\u8bc6\u4e0e\u4f18\u5316\u6280\u672f\u7684\u6846\u67b6\uff0c\u4ee5\u63d0\u9ad8\u57c3\u585e\u4fc4\u6bd4\u4e9a\u519c\u6751\u5730\u533a\u57fa\u672c\u533b\u7597\u670d\u52a1\u7684\u53ef\u53ca\u6027\u3002", "motivation": "\u57c3\u585e\u4fc4\u6bd4\u4e9a\u536b\u751f\u90e8\u9700\u8981\u5347\u7ea7\u536b\u751f\u7ad9\u4ee5\u6539\u5584\u516c\u5171\u670d\u52a1\u7684\u53ef\u53ca\u6027\uff0c\u5c24\u5176\u662f\u5728\u519c\u6751\u5730\u533a\u3002\u7531\u4e8e\u8d44\u6e90\u6709\u9650\uff0c\u5fc5\u987b\u5408\u7406\u4f18\u5148\u8003\u8651\u5347\u7ea7\u54ea\u4e9b\u536b\u751f\u8bbe\u65bd\uff0c\u4ee5\u6700\u5927\u5316\u4eba\u53e3\u8986\u76d6\u7387\u5e76\u8003\u8651\u5230\u4e0d\u540c\u7684\u4e13\u5bb6\u548c\u5229\u76ca\u76f8\u5173\u8005\u7684\u504f\u597d\u3002", "method": "\u7814\u7a76\u56e2\u961f\u5f00\u53d1\u4e86\u4e00\u79cd\u79f0\u4e3a\u2018\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u6269\u5c55\u8d2a\u5a6a\u2019\uff08LEG\uff09\u7684\u6df7\u5408\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u53ef\u63d0\u4f9b\u7406\u8bba\u4fdd\u8bc1\u7684\u53e4\u5178\u4f18\u5316\u65b9\u6cd5\u548c\u4eba\u5de5\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u8fed\u4ee3\u7ec6\u5316\u6280\u672f\uff0c\u786e\u4fdd\u89e3\u51b3\u65b9\u6848\u53cd\u6620\u4e13\u5bb6\u7684\u5b9a\u6027\u6307\u5bfc\u540c\u65f6\u4fdd\u6301\u8986\u76d6\u7387\u4fdd\u8bc1\u3002", "result": "\u7814\u7a76\u5728\u4e09\u4e2a\u57c3\u585e\u4fc4\u6bd4\u4e9a\u5730\u533a\u7684\u5b9e\u9645\u6570\u636e\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\uff0c\u8868\u660e\u8be5\u6846\u67b6\u7684\u6709\u6548\u6027\u548c\u5176\u5728\u6307\u5bfc\u516c\u5e73\u3001\u6570\u636e\u9a71\u52a8\u7684\u5065\u5eb7\u7cfb\u7edf\u89c4\u5212\u65b9\u9762\u7684\u6f5c\u5728\u4ef7\u503c\u3002", "conclusion": "\u7814\u7a76\u6210\u679c\u5c55\u793a\u4e86\u4e00\u79cd\u7cfb\u7edf\u6574\u5408\u4e13\u5bb6\u77e5\u8bc6\u4e0e\u4f18\u5316\u6280\u672f\u7684\u65b9\u6cd5\uff0c\u6709\u52a9\u4e8e\u6307\u5bfc\u5408\u7406\u89c4\u5212\u57c3\u585e\u4fc4\u6bd4\u4e9a\u7684\u536b\u751f\u8bbe\u65bd\u5347\u7ea7\uff0c\u4ee5\u4fc3\u8fdb\u57fa\u672c\u533b\u7597\u670d\u52a1\u7684\u53ef\u53ca\u6027\u3002"}}
{"id": "2601.11492", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11492", "abs": "https://arxiv.org/abs/2601.11492", "authors": ["Kaiwen Wang", "Kaili Zheng", "Rongrong Deng", "Qingmin Fan", "Milin Zhang", "Zongrui Li", "Xuesi Zhou", "Bo Han", "Liren Chen", "Chenyi Guo", "Ji Wu"], "title": "BoxMind: Closed-loop AI strategy optimization for elite boxing validated in the 2024 Olympics", "comment": null, "summary": "Competitive sports require sophisticated tactical analysis, yet combat disciplines like boxing remain underdeveloped in AI-driven analytics due to the complexity of action dynamics and the lack of structured tactical representations. To address this, we present BoxMind, a closed-loop AI expert system validated in elite boxing competition. By defining atomic punch events with precise temporal boundaries and spatial and technical attributes, we parse match footage into 18 hierarchical technical-tactical indicators. We then propose a graph-based predictive model that fuses these explicit technical-tactical profiles with learnable, time-variant latent embeddings to capture the dynamics of boxer matchups. Modeling match outcome as a differentiable function of technical-tactical indicators, we turn winning probability gradients into executable tactical adjustments. Experiments show that the outcome prediction model achieves state-of-the-art performance, with 69.8% accuracy on BoxerGraph test set and 87.5% on Olympic matches. Using this predictive model as a foundation, the system generates strategic recommendations that demonstrate proficiency comparable to human experts. BoxMind is validated through a closed-loop deployment during the 2024 Paris Olympics, directly contributing to the Chinese National Team's historic achievement of three gold and two silver medals. BoxMind establishes a replicable paradigm for transforming unstructured video data into strategic intelligence, bridging the gap between computer vision and decision support in competitive sports.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aBoxMind\u7684\u95ed\u5408\u56de\u8defAI\u4e13\u5bb6\u7cfb\u7edf\uff0c\u521b\u65b0\u6027\u5730\u5c06\u62f3\u51fb\u6bd4\u8d5b\u89c6\u9891\u89e3\u6790\u4e3a18\u4e2a\u5c42\u6b21\u7684\u6280\u672f\u6218\u672f\u6307\u6807\uff0c\u5e76\u901a\u8fc7\u56fe\u57fa\u9884\u6d4b\u6a21\u578b\u878d\u5408\u4e86\u53ef\u5b66\u4e60\u7684\u65f6\u95f4\u53d8\u4f53\u6f5c\u5728\u5d4c\u5165\uff0c\u4ee5\u6355\u6349\u6bd4\u8d5b\u52a8\u6001\uff0c\u4f7f\u83b7\u80dc\u6982\u7387\u68af\u5ea6\u8f6c\u5316\u4e3a\u53ef\u6267\u884c\u7684\u6218\u672f\u8c03\u6574\u3002\u5b9e\u9a8c\u8bc1\u660e\u8be5\u7cfb\u7edf\u7684\u9884\u6d4b\u6a21\u578b\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u7cfb\u7edf\u8fd8\u751f\u6210\u4e86\u6218\u7565\u5efa\u8bae\uff0c\u5c55\u793a\u4e86\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u76f8\u5f53\u7684\u80fd\u529b\u3002", "motivation": "\u9762\u5411\u7ade\u4e89\u4f53\u80b2\u6240\u9700\u7684\u590d\u6742\u6218\u672f\u5206\u6790\uff0c\u672c\u6587\u65e8\u5728\u586b\u8865\u62f3\u51fb\u7b49\u683c\u6597\u8fd0\u52a8\u5728AI\u9a71\u52a8\u5206\u6790\u4e2d\u7684\u7a7a\u767d\uff0c\u56e0\u4e3a\u8fd9\u4e9b\u8fd0\u52a8\u7684\u52a8\u6001\u884c\u52a8\u590d\u6742\u4e14\u7f3a\u4e4f\u7ed3\u6784\u5316\u7684\u6218\u672f\u8868\u793a\u3002", "method": "\u672c\u6587\u901a\u8fc7\u5b9a\u4e49\u7cbe\u786e\u7684\u65f6\u9650\u548c\u7a7a\u95f4\u6280\u672f\u5c5e\u6027\u7684\u539f\u5b50\u51fb\u6253\u4e8b\u4ef6\uff0c\u5c06\u6bd4\u8d5b\u89c6\u9891\u89e3\u6790\u4e3a18\u4e2a\u5c42\u6b21\u7684\u6280\u672f\u6218\u672f\u6307\u6807\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u56fe\u57fa\u9884\u6d4b\u6a21\u578b\uff0c\u7ed3\u5408\u4e86\u660e\u786e\u7684\u6280\u672f\u6218\u672f\u914d\u7f6e\u6587\u4ef6\u4e0e\u53ef\u5b66\u4e60\u7684\u65f6\u95f4\u53d8\u4f53\u6f5c\u5728\u5d4c\u5165\uff0c\u901a\u8fc7\u4f7f\u80dc\u7387\u53d8\u5316\u68af\u5ea6\u6210\u4e3a\u53ef\u6267\u884c\u7684\u6218\u672f\u8c03\u6574\uff0c\u5efa\u7acb\u4e86\u62f3\u51fb\u6bd4\u8d5b\u7ed3\u679c\u9884\u6d4b\u4f53\u7cfb\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u6a21\u578b\u5728BoxerGraph\u6d4b\u8bd5\u96c6\u548c\u5965\u8fd0\u6bd4\u8d5b\u4e2d\u5206\u522b\u53d6\u5f97\u4e8669.8\uff05\u548c87.5\uff05\u7684\u9ad8\u51c6\u786e\u7387\u3002\u57fa\u4e8e\u6b64\u9884\u6d4b\u6a21\u578b\uff0c\u7cfb\u7edf\u751f\u6210\u4e86\u6218\u7565\u5efa\u8bae\uff0c\u5c55\u793a\u51fa\u4e86\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u76f8\u5f53\u7684\u6c34\u5e73\u3002\u8be5\u7cfb\u7edf\u5728\u4e2d\u56fd\u56fd\u5bb6\u62f3\u51fb\u961f2024\u5e74\u5df4\u9ece\u5965\u8fd0\u4f1a\u7684\u95ed\u5408\u56de\u8def\u90e8\u7f72\u4e2d\u8d77\u5230\u4e86\u5173\u952e\u4f5c\u7528\uff0c\u5e2e\u52a9\u4e2d\u56fd\u961f\u83b7\u5f97\u4e86\u4e09\u91d1\u4e24\u94f6\u7684\u5386\u53f2\u6027\u6218\u7ee9\u3002", "conclusion": "BoxMind\u4e3a\u5c06\u672a\u7ed3\u6784\u5316\u7684\u89c6\u9891\u6570\u636e\u8f6c\u5316\u4e3a\u6218\u7565\u60c5\u62a5\u5960\u5b9a\u4e86\u53ef\u590d\u5236\u7684\u5178\u8303\uff0c\u5f25\u5408\u4e86\u8ba1\u7b97\u673a\u89c6\u89c9\u4e0e\u51b3\u7b56\u652f\u6301\u5728\u7ade\u4e89\u4f53\u80b2\u4e2d\u7684\u5dee\u8ddd\uff0c\u5c55\u793a\u4e86\u672a\u6765\u6218\u672f\u5206\u6790\u4e2d\u7684\u5de8\u5927\u6f5c\u529b\u3002"}}
