{"id": "2601.00003", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.00003", "abs": "https://arxiv.org/abs/2601.00003", "authors": ["Shuqi Liu", "Bowei He", "Chen Ma", "Linqi Song"], "title": "Reasoning in Action: MCTS-Driven Knowledge Retrieval for Large Language Models", "comment": null, "summary": "Large language models (LLMs) typically enhance their performance through either the retrieval of semantically similar information or the improvement of their reasoning capabilities. However, a significant challenge remains in effectively integrating both retrieval and reasoning strategies to optimize LLM performance. In this paper, we introduce a reasoning-aware knowledge retrieval method that enriches LLMs with information aligned to the logical structure of conversations, moving beyond surface-level semantic similarity. We follow a coarse-to-fine approach for knowledge retrieval. First, we identify a contextually relevant sub-region of the knowledge base, ensuring that all sentences within it are relevant to the context topic. Next, we refine our search within this sub-region to extract knowledge that is specifically relevant to the reasoning process. Throughout both phases, we employ the Monte Carlo Tree Search-inspired search method to effectively navigate through knowledge sentences using common keywords. Experiments on two multi-turn dialogue datasets demonstrate that our knowledge retrieval approach not only aligns more closely with the underlying reasoning in human conversations but also significantly enhances the diversity of the retrieved knowledge, resulting in more informative and creative responses.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u589e\u5f3a\u578b\u77e5\u8bc6\u68c0\u7d22\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u7684\u7cbe\u70bc\u8fc7\u7a0b\u548c\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u4f7f\u8bed\u8a00\u6a21\u578b\u66f4\u8d34\u8fd1\u4eba\u7c7b\u5bf9\u8bdd\u7684\u63a8\u7406\u903b\u8f91\uff0c\u63d0\u9ad8\u4e86\u77e5\u8bc6\u7684\u591a\u6837\u6027\u548c\u5e94\u7b54\u7684\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u7684\u8bed\u8a00\u6a21\u578b\u5728\u589e\u5f3a\u6027\u80fd\u65b9\u9762\u4e3b\u8981\u4f9d\u8d56\u4e8e\u4fe1\u606f\u68c0\u7d22\u548c\u63a8\u7406\u80fd\u529b\u7684\u63d0\u5347\uff0c\u4f46\u7f3a\u4e4f\u6709\u6548\u7ed3\u5408\u4e24\u8005\u4ee5\u4f18\u5316\u6a21\u578b\u6027\u80fd\u7684\u65b9\u6cd5\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u4e00\u79cd\u63a8\u7406\u611f\u77e5\u7684\u77e5\u8bc6\u68c0\u7d22\u65b9\u6cd5\uff0c\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u8be5\u65b9\u6cd5\u91c7\u7528\u4ece\u7c97\u5230\u7ec6\u7684\u77e5\u8bc6\u68c0\u7d22\u7b56\u7565\uff0c\u9996\u5148\u6839\u636e\u5bf9\u8bdd\u7684\u80cc\u666f\u8bed\u5883\u7f29\u5c0f\u77e5\u8bc6\u5e93\u7684\u68c0\u7d22\u8303\u56f4\uff0c\u7136\u540e\u5728\u8be5\u8303\u56f4\u5185\u8fdb\u4e00\u6b65\u63d0\u53d6\u4e0e\u63a8\u7406\u76f8\u5173\u7684\u77e5\u8bc6\u3002\u5728\u6574\u4e2a\u8fc7\u7a0b\u4e2d\uff0c\u4f7f\u7528\u4e86\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u542f\u53d1\u5f0f\u7684\u641c\u7d22\u65b9\u6cd5\uff0c\u901a\u8fc7\u5e38\u7528\u5173\u952e\u8bcd\u5bfc\u822a\u77e5\u8bc6\u53e5\u5b50\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u4f7f\u68c0\u7d22\u7684\u77e5\u8bc6\u4e0e\u4eba\u7c7b\u5bf9\u8bdd\u7684\u63a8\u7406\u8fc7\u7a0b\u66f4\u4e3a\u5951\u5408\uff0c\u8fd8\u663e\u8457\u63d0\u5347\u4e86\u68c0\u7d22\u77e5\u8bc6\u7684\u591a\u6837\u6027\uff0c\u4ece\u800c\u751f\u6210\u66f4\u6709\u4fe1\u606f\u91cf\u548c\u521b\u9020\u6027\u7684\u56de\u590d\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u6539\u8fdb\u8bed\u8a00\u6a21\u578b\u7684\u77e5\u8bc6\u68c0\u7d22\u673a\u5236\uff0c\u589e\u5f3a\u5176\u751f\u6210\u9ad8\u8d28\u91cf\u5bf9\u8bdd\u56de\u7b54\u7684\u80fd\u529b\u3002"}}
{"id": "2601.00004", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.00004", "abs": "https://arxiv.org/abs/2601.00004", "authors": ["Isaac Iyinoluwa Olufadewa", "Miracle Ayomikun Adesina", "Ezekiel Ayodeji Oladejo", "Uthman Babatunde Usman", "Owen Kolade Adeniyi", "Matthew Tolulope Olawoyin"], "title": "Finetuning Large Language Models for Automated Depression Screening in Nigerian Pidgin English: GENSCORE Pilot Study", "comment": "9 pages, 1 figure, 4 tables", "summary": "Depression is a major contributor to the mental-health burden in Nigeria, yet screening coverage remains limited due to low access to clinicians, stigma, and language barriers. Traditional tools like the Patient Health Questionnaire-9 (PHQ-9) were validated in high-income countries but may be linguistically or culturally inaccessible for low- and middle-income countries and communities such as Nigeria where people communicate in Nigerian Pidgin and more than 520 local languages. This study presents a novel approach to automated depression screening using fine-tuned large language models (LLMs) adapted for conversational Nigerian Pidgin. We collected a dataset of 432 Pidgin-language audio responses from Nigerian young adults aged 18-40 to prompts assessing psychological experiences aligned with PHQ-9 items, performed transcription, rigorous preprocessing and annotation, including semantic labeling, slang and idiom interpretation, and PHQ-9 severity scoring. Three LLMs - Phi-3-mini-4k-instruct, Gemma-3-4B-it, and GPT-4.1 - were fine-tuned on this annotated dataset, and their performance was evaluated quantitatively (accuracy, precision and semantic alignment) and qualitatively (clarity, relevance, and cultural appropriateness). GPT-4.1 achieved the highest quantitative performance, with 94.5% accuracy in PHQ-9 severity scoring prediction, outperforming Gemma-3-4B-it and Phi-3-mini-4k-instruct. Qualitatively, GPT-4.1 also produced the most culturally appropriate, clear, and contextually relevant responses. AI-mediated depression screening for underserved Nigerian communities. This work provides a foundation for deploying conversational mental-health tools in linguistically diverse, resource-constrained environments.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5bf9\u5c3c\u65e5\u5229\u4e9a\u5e74\u8f7b\u4eba\u8fdb\u884c\u6291\u90c1\u7b5b\u67e5\u7684\u65b0\u578b\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u9488\u5bf9\u5c3c\u65e5\u5229\u4e9aPidgin\u8bed\u8a00\u7684\u5b9a\u5236\u6a21\u578b\uff0c\u5728\u9884\u6d4b\u4e25\u91cd\u7a0b\u5ea6\u548c\u6587\u5316\u9002\u5b9c\u6027\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u9274\u4e8e\u5c3c\u65e5\u5229\u4e9a\u6291\u90c1\u75c7\u8d1f\u62c5\u91cd\u5927\u4e14\u7b5b\u67e5\u8986\u76d6\u6709\u9650\uff0c\u73b0\u6709\u7b5b\u67e5\u5de5\u5177\u53ef\u80fd\u56e0\u8bed\u8a00\u548c\u6587\u5316\u5dee\u5f02\u800c\u65e0\u6cd5\u6709\u6548\u5e94\u7528\u4e8e\u8be5\u5730\u533a\u3002", "method": "\u7814\u7a76\u4eba\u5458\u6536\u96c6\u4e86432\u4efd\u5c3c\u65e5\u5229\u4e9a\u5e74\u8f7b\u4eba\u7684Pidgin\u8bed\u8a00\u97f3\u9891\u56de\u7b54\uff0c\u9488\u5bf9\u4e0ePHQ-9\u9879\u76ee\u76f8\u5173\u7684\u5fc3\u7406\u4f53\u9a8c\u8fdb\u884c\u6807\u6ce8\uff0c\u5e76\u4f7f\u7528Phi-3-mini-4k-instruct\u3001Gemma-3-4B-it\u548cGPT-4.1\u4e09\u79cdLM\u5bf9\u8fd9\u4e9b\u6570\u636e\u8fdb\u884c\u4e86\u5fae\u8c03\uff0c\u6700\u7ec8\u8bc4\u4f30\u4e86\u5404\u4e2a\u6a21\u578b\u7684\u6027\u80fd\u3002", "result": "GPT-4.1\u5728\u5b9a\u91cf\u6d4b\u8bd5\u4e2d\u4ee594.5%\u7684\u51c6\u786e\u7387\u5728\u6291\u90c1\u75c7\u4e25\u91cd\u7a0b\u5ea6\u9884\u6d4b\u4e2d\u8868\u73b0\u6700\u4f73\uff0c\u4e14\u5728\u5b9a\u6027\u8bc4\u4f30\u4e2d\u63d0\u4f9b\u4e86\u6700\u7b26\u5408\u6587\u5316\u3001\u6e05\u6670\u548c\u4e0a\u4e0b\u6587\u76f8\u5173\u6027\u7684\u56de\u7b54\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u8868\u660e\uff0c\u4f7f\u7528\u9488\u5bf9\u5c3c\u65e5\u5229\u4e9aPidgin\u8bed\u8a00\u5fae\u8c03\u7684LLM\u53ef\u4ee5\u5728\u8bed\u8a00\u548c\u6587\u5316\u591a\u6837\u6027\u8f83\u9ad8\u7684\u73af\u5883\u4e2d\u6709\u6548\u8fdb\u884c\u6291\u90c1\u75c7\u7b5b\u67e5\u3002"}}
{"id": "2601.00021", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.00021", "abs": "https://arxiv.org/abs/2601.00021", "authors": ["Peter David Fagan"], "title": "Toward a Physical Theory of Intelligence", "comment": "47 pages, 9 figures", "summary": "We present a physical theory of intelligence grounded in irreversible information processing in systems constrained by conservation laws. An intelligent system is modelled as a coupled agent-environment process whose evolution transforms information into goal-directed work. To connect information to physical state, we introduce the Conservation-Congruent Encoding (CCE) framework, in which encodings correspond to metastable basins of attraction whose separability is enforced by conservation laws. Within this framework, intelligence is defined as the amount of goal-directed work produced per nat of irreversibly processed information. From this definition we derive a hierarchy of physical constraints governing information intake, irreversible computation, and work extraction in open systems. The framework reveals how long-horizon efficiency requires the preservation of internal informational structure, giving rise to self-modelling, and it establishes that physically embodied intelligent systems possess intrinsic epistemic limits analogous to incompleteness phenomena. Applying the theory to biological systems, we analyse how oscillatory and near-critical dynamics optimise the trade-off between information preservation, dissipation, and useful work, placing the brain near an efficient operating regime predicted by the framework. At the architectural level, we develop a theory of continuous dynamical circuits in which classical Boolean logic emerges as a special case of attractor selection, while more general invariant geometries support computational modes beyond fixed-point logic. Finally, we propose a physically grounded perspective on artificial intelligence safety based on irreversible information flow and structural homeostasis. Together, these results provide a unified, substrate-neutral account of intelligence as a physical phenomenon.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e0d\u53ef\u9006\u4fe1\u606f\u5904\u7406\u7684\u7269\u7406\u667a\u80fd\u7406\u8bba\uff0c\u7ed3\u5408\u5b88\u6052\u5b9a\u5f8b\uff0c\u5b9a\u4e49\u4e86\u667a\u80fd\u7cfb\u7edf\u5e76\u901a\u8fc7\u4f53\u7cfb\u7ed3\u6784\u5f00\u53d1\u4e86\u4e00\u4e2a\u5168\u65b0\u7684\u7406\u8bba\u6846\u67b6\u3002\u8be5\u7406\u8bba\u5c06\u667a\u80fd\u5b9a\u4e49\u4e3a\u6bcf\u5355\u4f4d\u4e0d\u53ef\u9006\u5904\u7406\u4fe1\u606f\u4ea7\u751f\u7684\u76ee\u6807\u5bfc\u5411\u5de5\u4f5c\u7684\u91cf\uff0c\u5e76\u63ed\u793a\u4e86\u6548\u7387\u548c\u9002\u5e94\u6027\u7684\u81ea\u8c03\u8282\u673a\u5236\u3002", "motivation": "\u5f53\u524d\u4eba\u5de5\u667a\u80fd\u9886\u57df\u7f3a\u4e4f\u4e00\u79cd\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\u6765\u63cf\u8ff0\u667a\u80fd\u7684\u672c\u8d28\u548c\u8fd0\u4f5c\u8fc7\u7a0b\uff0c\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u63d0\u4f9b\u4e00\u4e2a\u8de8\u9886\u57df\u7684\u7269\u7406\u667a\u80fd\u7406\u8bba\u3002", "method": "\u4f5c\u8005\u901a\u8fc7\u5f15\u5165\u4fdd\u5b88\u517c\u5bb9\u7f16\u7801\uff08CCE\uff09\u6846\u67b6\uff0c\u5c06\u4fe1\u606f\u7f16\u7801\u4e0e\u5b88\u6052\u5b9a\u5f8b\u8054\u7cfb\u8d77\u6765\uff0c\u5b9a\u4e49\u4e86\u4e00\u79cd\u65b0\u7684\u667a\u80fd\u5ea6\u91cf\u6807\u51c6\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u63a8\u5bfc\u548c\u751f\u7269\u7cfb\u7edf\u5206\u6790\u63ed\u793a\u4e86\u667a\u80fd\u7cfb\u7edf\u7684\u5de5\u4f5c\u673a\u5236\u3002", "result": "\u63d0\u51fa\u4e86\u667a\u80fd\u5b9a\u4e49\u7684\u65b0\u89c2\u70b9\uff0c\u5373\u6bcf\u5355\u4f4d\u4e0d\u53ef\u9006\u5904\u7406\u4fe1\u606f\u4ea7\u751f\u7684\u76ee\u6807\u5bfc\u5411\u5de5\u4f5c\u7684\u91cf\uff1b\u63ed\u793a\u4e86\u957f\u671f\u6548\u7387\u548c\u81ea\u8c03\u8282\u673a\u5236\u4e4b\u95f4\u7684\u5173\u7cfb\uff1b\u5206\u6790\u4e86\u751f\u7269\u7cfb\u7edf\u4e2d\u7684\u6709\u6548\u64cd\u4f5c\u6a21\u5f0f\u3002", "conclusion": "\u8be5\u8bba\u6587\u4e3a\u667a\u80fd\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7269\u7406\u7edf\u4e00\u7684\u89e3\u91ca\uff0c\u6db5\u76d6\u4e86\u4ece\u4fe1\u606f\u5904\u7406\u5230\u751f\u6210\u6709\u7528\u5de5\u4f5c\u7684\u5168\u8fc7\u7a0b\uff0c\u5e76\u63d0\u51fa\u4e86\u5b89\u5168\u6027\u89c6\u89d2\u4e0b\u7684\u7269\u7406 AI \u65b9\u6cd5\u8bba\u3002"}}
{"id": "2601.00023", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.00023", "abs": "https://arxiv.org/abs/2601.00023", "authors": ["Luis M. Moreno-Saavedra", "Silvia Jimenez-Fernandez", "Antonio Portilla-Figueras", "David Casillas-Perez", "Sancho Salcedo-Sanz"], "title": "A multi-algorithm approach for operational human resources workload balancing in a last mile urban delivery system", "comment": null, "summary": "Efficient workload assignment to the workforce is critical in last-mile package delivery systems. In this context, traditional methods of assigning package deliveries to workers based on geographical proximity can be inefficient and surely guide to an unbalanced workload distribution among delivery workers. In this paper, we look at the problem of operational human resources workload balancing in last-mile urban package delivery systems. The idea is to consider the effort workload to optimize the system, i.e., the optimization process is now focused on improving the delivery time, so that the workload balancing is complete among all the staff. This process should correct significant decompensations in workload among delivery workers in a given zone. Specifically, we propose a multi-algorithm approach to tackle this problem. The proposed approach takes as input a set of delivery points and a defined number of workers, and then assigns packages to workers, in such a way that it ensures that each worker completes a similar amount of work per day. The proposed algorithms use a combination of distance and workload considerations to optimize the allocation of packages to workers. In this sense, the distance between the delivery points and the location of each worker is also taken into account. The proposed multi-algorithm methodology includes different versions of k-means, evolutionary approaches, recursive assignments based on k-means initialization with different problem encodings, and a hybrid evolutionary ensemble algorithm. We have illustrated the performance of the proposed approach in a real-world problem in an urban last-mile package delivery workforce operating at Azuqueca de Henares, Spain.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u591a\u7b97\u6cd5\u65b9\u6cd5\u6765\u4f18\u5316\u6700\u540e\u4e00\u82f1\u91cc\u57ce\u5e02\u5305\u88f9\u9012\u9001\u7cfb\u7edf\u4e2d\u7684\u4eba\u529b\u8d44\u6e90\u5de5\u4f5c\u8d1f\u8f7d\u5e73\u8861\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u57fa\u4e8e\u5730\u7406\u4f4d\u7f6e\u5206\u914d\u5305\u88f9\uff0c\u53ef\u80fd\u5bfc\u81f4\u5de5\u4f5c\u8d1f\u8f7d\u4e0d\u5e73\u8861\uff0c\u672c\u6587\u63d0\u51fa\u4f18\u5316\u5206\u914d\u65b9\u6cd5\u4ee5\u5e73\u8861\u6240\u6709\u5458\u5de5\u7684\u5de5\u4f5c\u91cf\u3002", "method": "\u4f7f\u7528\u591a\u7b97\u6cd5\u65b9\u6cd5\u7ed3\u5408\u8ddd\u79bb\u548c\u5de5\u4f5c\u91cf\u8003\u8651\u6765\u4f18\u5316\u5305\u88f9\u5206\u914d\u3002", "result": "\u5728\u897f\u73ed\u7259Azuqueca de Henares\u5e02\u7684\u73b0\u5b9e\u5305\u88f9\u9012\u9001\u5de5\u4f5c\u4e2d\u9a8c\u8bc1\u4e86\u6240\u63d0\u51fa\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u591a\u7b97\u6cd5\u65b9\u6cd5\u5728\u65f6\u95f4\u548c\u5de5\u4f5c\u91cf\u5206\u914d\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u5b9e\u73b0\u4e86\u66f4\u5747\u8861\u7684\u5de5\u4f5c\u8d1f\u8f7d\u5206\u914d\u3002"}}
{"id": "2601.00042", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.00042", "abs": "https://arxiv.org/abs/2601.00042", "authors": ["Manish Bhatt", "Adrian Wood", "Idan Habler", "Ammar Al-Kahfah"], "title": "Large Empirical Case Study: Go-Explore adapted for AI Red Team Testing", "comment": null, "summary": "Production LLM agents with tool-using capabilities require security testing despite their safety training. We adapt Go-Explore to evaluate GPT-4o-mini across 28 experimental runs spanning six research questions. We find that random-seed variance dominates algorithmic parameters, yielding an 8x spread in outcomes; single-seed comparisons are unreliable, while multi-seed averaging materially reduces variance in our setup. Reward shaping consistently harms performance, causing exploration collapse in 94% of runs or producing 18 false positives with zero verified attacks. In our environment, simple state signatures outperform complex ones. For comprehensive security testing, ensembles provide attack-type diversity, whereas single agents optimize coverage within a given attack type. Overall, these results suggest that seed variance and targeted domain knowledge can outweigh algorithmic sophistication when testing safety-trained models.", "AI": {"tldr": "\u8be5\u7814\u7a76\u4f7f\u7528Go-Explore\u8bc4\u4f30\u4e86GPT-4o-mini\uff0c\u5e76\u53d1\u73b0\u968f\u673a\u79cd\u5b50\u53d8\u5f02\u662f\u4e3b\u8981\u56e0\u7d20\uff0c\u5956\u52b1\u5851\u9020\u4f1a\u8d1f\u9762\u5f71\u54cd\u6027\u80fd\uff0c\u800c\u7b80\u5355\u7684\u72b6\u6001\u7b7e\u540d\u66f4\u4f18\u3002\u591a\u6a21\u578b\u6709\u5229\u4e8e\u653b\u51fb\u7c7b\u578b\u7684\u591a\u6837\u6027\uff0c\u4f46\u5355\u4e2a\u6a21\u578b\u5728\u5355\u4e00\u653b\u51fb\u7c7b\u578b\u4e0a\u80fd\u66f4\u597d\u4f18\u5316\u8986\u76d6\u3002", "motivation": "\u7531\u4e8e\u5373\u4f7f\u7ecf\u8fc7\u5b89\u5168\u8bad\u7ec3\uff0c\u5177\u5907\u5de5\u5177\u4f7f\u7528\u80fd\u529b\u7684LLM\u4ecd\u9700\u5b89\u5168\u6d4b\u8bd5\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u8bc4\u4f30\u6b64\u7c7b\u6a21\u578b\u7684\u6709\u6548\u65b9\u6cd5\u3002", "method": "\u7814\u7a76\u4f7f\u7528Go-Explore\u65b9\u6cd5\u8fdb\u884c\u4e8628\u6b21\u5b9e\u9a8c\uff0c\u5206\u522b\u6d4b\u8bd5\u4e86\u516d\u9879\u4e0d\u540c\u7684\u7814\u7a76\u95ee\u9898\uff0c\u901a\u8fc7\u968f\u673a\u79cd\u5b50\u548c\u7b97\u6cd5\u53c2\u6570\u7684\u53d8\u5316\uff0c\u89c2\u5bdf\u5176\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u968f\u673a\u79cd\u5b50\u53d8\u5f02\u663e\u8457\u5f71\u54cd\u4e86\u6a21\u578b\u7684\u8868\u73b0\uff0c\u5956\u52b1\u5851\u9020\u4f1a\u964d\u4f4e\u63a2\u7d22\u529b\u5e76\u5bfc\u81f4\u5047\u9633\u6027\u8f83\u9ad8\u7684\u60c5\u51b5\uff0c\u7b80\u5355\u72b6\u6001\u7b7e\u540d\u66f4\u4e3a\u6709\u6548\u3002", "conclusion": "\u57fa\u4e8e\u8fd9\u4e9b\u7ed3\u679c\uff0c\u7814\u7a76\u6307\u51fa\uff0c\u5373\u4f7f\u6a21\u578b\u7ecf\u8fc7\u5b89\u5168\u8bad\u7ec3\uff0c\u79cd\u5b50\u53d8\u5f02\u548c\u7279\u5b9a\u9886\u57df\u7684\u77e5\u8bc6\u53ef\u80fd\u5728\u5b89\u5168\u6027\u6d4b\u8bd5\u4e2d\u6bd4\u7b97\u6cd5\u590d\u6742\u6027\u66f4\u4e3a\u5173\u952e\u3002"}}
{"id": "2601.00213", "categories": ["cs.CR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.00213", "abs": "https://arxiv.org/abs/2601.00213", "authors": ["Haoran Gu", "Handing Wang", "Yi Mei", "Mengjie Zhang", "Yaochu Jin"], "title": "Overlooked Safety Vulnerability in LLMs: Malicious Intelligent Optimization Algorithm Request and its Jailbreak", "comment": null, "summary": "The widespread deployment of large language models (LLMs) has raised growing concerns about their misuse risks and associated safety issues. While prior studies have examined the safety of LLMs in general usage, code generation, and agent-based applications, their vulnerabilities in automated algorithm design remain underexplored. To fill this gap, this study investigates this overlooked safety vulnerability, with a particular focus on intelligent optimization algorithm design, given its prevalent use in complex decision-making scenarios. We introduce MalOptBench, a benchmark consisting of 60 malicious optimization algorithm requests, and propose MOBjailbreak, a jailbreak method tailored for this scenario. Through extensive evaluation of 13 mainstream LLMs including the latest GPT-5 and DeepSeek-V3.1, we reveal that most models remain highly susceptible to such attacks, with an average attack success rate of 83.59% and an average harmfulness score of 4.28 out of 5 on original harmful prompts, and near-complete failure under MOBjailbreak. Furthermore, we assess state-of-the-art plug-and-play defenses that can be applied to closed-source models, and find that they are only marginally effective against MOBjailbreak and prone to exaggerated safety behaviors. These findings highlight the urgent need for stronger alignment techniques to safeguard LLMs against misuse in algorithm design.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5173\u6ce8\u5927\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u52a8\u5316\u7b97\u6cd5\u8bbe\u8ba1\u4e2d\u7684\u5b89\u5168\u6027\u6f0f\u6d1e\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u6076\u610f\u4f18\u5316\u7b97\u6cd5\u57fa\u51c6\uff08MalOptBench\uff09\u548c\u76f8\u5e94\u7684\u7834\u89e3\u65b9\u6cd5\uff08MOBjailbreak\uff09\uff0c\u63ed\u793a\u4e86\u73b0\u5b58\u6a21\u578b\u5728\u9762\u5bf9\u6b64\u7c7b\u653b\u51fb\u65f6\u7684\u9ad8\u5ea6\u6613\u53d7\u653b\u51fb\u6027\u3002", "motivation": "\u7531\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5e7f\u6cdb\u5e94\u7528\u5f15\u53d1\u4e86\u5bf9\u5176\u5728\u7b97\u6cd5\u8bbe\u8ba1\u4e2d\u7684\u6f5c\u5728\u98ce\u9669\u548c\u5b89\u5168\u9690\u60a3\u7684\u5173\u6ce8\uff0c\u8be5\u9879\u7814\u7a76\u65e8\u5728\u586b\u8865\u73b0\u6709\u7814\u7a76\u7684\u7a7a\u767d\uff0c\u5173\u6ce8\u5728\u81ea\u52a8\u5316\u7b97\u6cd5\u8bbe\u8ba1\u4e2d\u7684\u5b89\u5168\u95ee\u9898\u3002", "method": "\u8be5\u7814\u7a76\u901a\u8fc7\u521b\u5efa\u4e00\u4e2a\u5305\u542b60\u4e2a\u6076\u610f\u4f18\u5316\u7b97\u6cd5\u8bf7\u6c42\u7684\u57fa\u51c6MalOptBench\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u4e13\u95e8\u9488\u5bf9\u8be5\u573a\u666f\u7684\u7834\u89e3\u65b9\u6cd5MOBjailbreak\uff0c\u5bf913\u79cd\u4e3b\u6d41\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08\u5305\u62ec\u6700\u65b0\u7684GPT-5\u548cDeepSeek-V3.1\uff09\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u8bc4\u4f30\uff0c\u4ee5\u63ed\u793a\u6a21\u578b\u5728\u9762\u5bf9\u6b64\u7c7b\u653b\u51fb\u65f6\u7684\u8106\u5f31\u6027\u548c\u653b\u51fb\u7684\u6210\u529f\u7387\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5927\u90e8\u5206\u6a21\u578b\u5728\u9762\u5bf9\u6b64\u7c7b\u653b\u51fb\u65f6\u5b58\u5728\u8f83\u9ad8\u7684\u6613\u53d7\u653b\u51fb\u7387\uff0c\u5e73\u5747\u653b\u51fb\u6210\u529f\u7387\u8fbe\u5230\u4e8683.59%\uff0c\u540c\u65f6\u5bf9\u4e00\u4e9b\u65b0\u7684\u63d2\u4ef6\u5f0f\u9632\u5fa1\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u53d1\u73b0\u8fd9\u4e9b\u9632\u5fa1\u63aa\u65bd\u5bf9MOBjailbreak\u7684\u6709\u6548\u6027\u6709\u9650\uff0c\u53ef\u80fd\u4ea7\u751f\u8fc7\u5ea6\u7684\u5b89\u5168\u63aa\u65bd\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u5728\u7b97\u6cd5\u8bbe\u8ba1\u4e2d\u52a0\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u4fdd\u62a4\u63aa\u65bd\u7684\u7d27\u8feb\u6027\uff0c\u5e76\u6307\u51fa\u9700\u8981\u66f4\u5f3a\u7684\u5bf9\u9f50\u6280\u672f\u6765\u9632\u6b62\u6a21\u578b\u88ab\u8bef\u7528\u3002"}}
{"id": "2601.00029", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.00029", "abs": "https://arxiv.org/abs/2601.00029", "authors": ["Abolhassan Pishahang", "Maryam Badiei"], "title": "From Clay to Code: Typological and Material Reasoning in AI Interpretations of Iranian Pigeon Towers", "comment": "Proceedings of SIGraDi 2025: XXIX International Conference of the Ibero-American Society of Digital Graphics, C\u00f3rdoba, Argentina, 2025", "summary": "This study investigates how generative AI systems interpret the architectural intelligence embedded in vernacular form. Using the Iranian pigeon tower as a case study, the research tests three diffusion models, Midjourney v6, DALL-E 3, and DreamStudio based on Stable Diffusion XL (SDXL), across three prompt stages: referential, adaptive, and speculative. A five-criteria evaluation framework assesses how each system reconstructs typology, materiality, environment, realism, and cultural specificity. Results show that AI reliably reproduces geometric patterns but misreads material and climatic reasoning. Reference imagery improves realism yet limits creativity, while freedom from reference generates inventive but culturally ambiguous outcomes. The findings define a boundary between visual resemblance and architectural reasoning, positioning computational vernacular reasoning as a framework for analyzing how AI perceives, distorts, and reimagines traditional design intelligence.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u4f0a\u6717\u9e3d\u5854\u6848\u4f8b\uff0c\u4f7f\u7528\u4e09\u79cd\u6269\u6563\u6a21\u578b\u6d4b\u8bd5\u4e86AI\u5bf9\u4f20\u7edf\u5efa\u7b51\u8bbe\u8ba1\u7684\u8ba4\u77e5\uff0c\u7ed3\u679c\u663e\u793aAI\u5728\u51e0\u4f55\u6a21\u5f0f\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u6750\u6599\u548c\u6c14\u5019\u903b\u8f91\u4e0a\u5b58\u5728\u8bef\u5dee\u3002\u53c2\u8003\u56fe\u50cf\u63d0\u9ad8\u4e86\u73b0\u5b9e\u611f\u4f46\u9650\u5236\u4e86\u521b\u610f\uff0c\u800c\u6446\u8131\u53c2\u8003\u5219\u4ea7\u751f\u4e86\u5177\u6709\u521b\u9020\u6027\u7684\u4f46\u6587\u5316\u4e0a\u6a21\u7cca\u7684\u7ed3\u679c\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u63a2\u8ba8\u751f\u6210\u578bAI\u7cfb\u7edf\u5982\u4f55\u7406\u89e3\u548c\u89e3\u91ca\u5b58\u5728\u4e8e\u4f20\u7edf\u5f62\u5f0f\u4e2d\u7684\u5efa\u7b51\u667a\u80fd\uff0c\u901a\u8fc7\u5bf9\u4f0a\u6717\u9e3d\u5854\u7684\u6848\u4f8b\u7814\u7a76\u6765\u9a8c\u8bc1\u548c\u5206\u6790\u4e0d\u540c\u6269\u6563\u6a21\u578b\u5728\u4e0d\u540c\u65f6\u6bb5\u4e0b\u7684\u8868\u73b0\u3002", "method": "\u7814\u7a76\u91c7\u7528\u4e86\u4f0a\u6717\u9e3d\u5854\u4f5c\u4e3a\u6848\u4f8b\uff0c\u5e94\u7528\u4e86\u4e09\u79cd\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u4e0d\u540c\u7248\u672c\u5373 Midjourney v6\u3001DALL-E 3 \u548c\u57fa\u4e8e Stable Diffusion XL (SDXL) \u7684 DreamStudio\uff0c\u9488\u5bf9\u63cf\u8ff0\u6027\u3001\u9002\u5e94\u6027\u548c\u63a8\u6d4b\u6027\u4e09\u4e2a\u9636\u6bb5\u751f\u6210\u56fe\u50cf\u3002\u901a\u8fc7\u4e00\u5957\u57fa\u4e8e\u4e94\u9879\u6807\u51c6\uff08\u7c7b\u578b\u3001\u6750\u8d28\u3001\u73af\u5883\u3001\u73b0\u5b9e\u4e3b\u4e49\u548c\u6587\u5316\u7279\u5f02\u6027\uff09\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u8bc4\u4f30AI \u5bf9\u5404\u4e2a\u6a21\u578b\u7684\u751f\u6210\u6548\u679c\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff0cAI \u5728\u51e0\u4f55\u56fe\u6848\u65b9\u9762\u7684\u751f\u6210\u80fd\u529b\u76f8\u5f53\u53ef\u9760\uff0c\u4f46\u5728\u89e3\u8bfb\u6750\u6599\u4e0e\u6c14\u5019\u539f\u7406\u65f6\u51fa\u73b0\u4e86\u504f\u5dee\u3002\u4f7f\u7528\u53c2\u8003\u56fe\u50cf\u63d0\u9ad8\u56fe\u50cf\u7684\u771f\u5b9e\u611f\uff0c\u4f46\u9650\u5236\u4e86\u521b\u9020\u6027\u601d\u7ef4\u7684\u7a7a\u95f4\uff1b\u8131\u79bb\u53c2\u8003\u5219\u80fd\u6fc0\u53d1\u66f4\u591a\u521b\u65b0\uff0c\u4f46\u6709\u65f6\u7f3a\u4e4f\u6587\u5316\u80cc\u666f\u3002", "conclusion": "\u7814\u7a76\u4e3a\u89c6\u89c9\u76f8\u4f3c\u6027\u548c\u5efa\u7b51\u903b\u8f91\u4e4b\u95f4\u7684\u754c\u9650\u63d0\u4f9b\u4e86\u65b0\u7684\u8ba4\u8bc6\uff0c\u5e76\u5c06\u8ba1\u7b97\u4f20\u7edf\u63a8\u7406\u4f5c\u4e3a\u5206\u6790AI\u5982\u4f55\u611f\u77e5\u3001\u626d\u66f2\u548c\u91cd\u65b0\u60f3\u8c61\u4f20\u7edf\u8bbe\u8ba1\u667a\u6167\u7684\u6846\u67b6\u3002"}}
{"id": "2601.00252", "categories": ["cs.CR", "cs.OS"], "pdf": "https://arxiv.org/pdf/2601.00252", "abs": "https://arxiv.org/abs/2601.00252", "authors": ["Rajendra Kumar Solanki", "Vijay Laxmi", "Manoj Singh Gaur"], "title": "Evolution of Android's Permission-based Security Model and Challenges", "comment": null, "summary": "Android Permission Model and Application (app) analysis has consistently remained the focus of the investigation of research groups and stakeholders of the Android ecosystem since it was launched in 2008. Even though the Android smartphone operating system (OS) permission model has evolved significantly from `all-or-none access' to `user-chosen dangerous resource access', specific challenges and issues remain unresolved even after 15 years after the smartphone OS launch. This study addresses the issues and documents the research work in this arena through a comprehensive literature survey and comparative analysis.\n  The survey's focal point is the Android permission model and relevant research between 2010-2022. We systematize the knowledge on (i) Android API Calls to permissions mapping, (ii) Android Permissions evolution, and (iii) how permissions are checked. Furthermore, the survey identifies the permission-related issues and relevant research addressed during the last decade. We reference seminal work in these areas. We summarize the identified research gaps and present future directions for early and experienced researchers.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u5168\u9762\u7684\u6587\u732e\u7efc\u8ff0\u548c\u5bf9\u6bd4\u5206\u6790\uff0c\u5173\u6ce82010\u5e74\u81f32022\u5e74\u95f4Android\u6743\u9650\u6a21\u578b\u53ca\u5176\u76f8\u5173\u7814\u7a76\uff0c\u7cfb\u7edf\u5316\u5730\u6982\u8ff0\u4e86Android API\u8c03\u7528\u4e0e\u6743\u9650\u6620\u5c04\u3001\u6743\u9650\u6f14\u53d8\u53ca\u6743\u9650\u68c0\u67e5\u7684\u77e5\u8bc6\uff0c\u5e76\u8bc6\u522b\u4e86\u8fc7\u53bb\u5341\u5e74\u4e2d\u7684\u6743\u9650\u76f8\u5173\u95ee\u9898\u548c\u7814\u7a76\u5de5\u4f5c\uff0c\u603b\u7ed3\u7814\u7a76\u4e2d\u7684\u7a7a\u767d\u5e76\u4e3a\u65e9\u671f\u548c\u6709\u7ecf\u9a8c\u7684\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u672a\u6765\u65b9\u5411\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u5206\u6790\u81ea2008\u5e74Android\u64cd\u4f5c\u7cfb\u7edf\u63a8\u51fa\u4ee5\u6765\uff0c\u5c24\u5176\u662f2010\u5e74\u81f32022\u5e74\u95f4\uff0cAndroid\u6743\u9650\u6a21\u578b\u7684\u6f14\u53d8\u548c\u76f8\u5173\u7814\u7a76\u6210\u679c\u3002\u9274\u4e8e\u6743\u9650\u6a21\u578b\u5c1a\u672a\u5b8c\u5168\u6210\u719f\uff0c\u901a\u8fc7\u603b\u7ed3\u76f8\u5173\u7814\u7a76\u5de5\u4f5c\uff0c\u8bc6\u522b\u73b0\u6709\u95ee\u9898\uff0c\u53ef\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u53c2\u8003\u3002", "method": "\u8be5\u7814\u7a76\u91c7\u7528\u4e86\u5168\u9762\u7684\u6587\u732e\u8c03\u7814\u65b9\u6cd5\uff0c\u91cd\u70b9\u7814\u7a76\u4e862010\u5e74\u81f32022\u5e74\u95f4\u5173\u4e8eAndroid\u6743\u9650\u6a21\u578b\u7684\u7814\u7a76\u3002\u7814\u7a76\u901a\u8fc7\u5bf9\u6bd4\u5206\u6790\u7684\u65b9\u6cd5\uff0c\u7cfb\u7edf\u5316\u5730\u6982\u8ff0\u4e86API\u8c03\u7528\u4e0e\u6743\u9650\u6620\u5c04\u5173\u7cfb\uff0c\u5206\u6790\u4e86\u6743\u9650\u6a21\u578b\u7684\u6f14\u53d8\u8fc7\u7a0b\u53ca\u6743\u9650\u68c0\u67e5\u673a\u5236\uff0c\u5e76\u8bc6\u522b\u4e86\u73b0\u6709\u7814\u7a76\u4e2d\u7684\u7a7a\u767d\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b9\u5411\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff0c\u5c3d\u7ba1Android\u6743\u9650\u6a21\u578b\u6709\u4e86\u663e\u8457\u6539\u8fdb\uff0c\u4f46\u4ecd\u5b58\u5728\u4e00\u4e9b\u672a\u89e3\u51b3\u7684\u95ee\u9898\u3002\u7814\u7a76\u56e2\u961f\u603b\u7ed3\u4e86\u8fc7\u53bb\u5341\u5e74\u4e2d\u5173\u4e8eAndroid\u6743\u9650\u6a21\u578b\u7684\u7814\u7a76\u5de5\u4f5c\uff0c\u8bc6\u522b\u51fa\u6743\u9650\u7ba1\u7406\u65b9\u9762\u7684\u6f5c\u5728\u95ee\u9898\u548c\u76f8\u5173\u7814\u7a76\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u610f\u4e49\u7684\u65b9\u5411\u3002", "conclusion": "\u7efc\u5408\u6587\u732e\u8c03\u7814\u7ed3\u679c\u548c\u5bf9\u6bd4\u5206\u6790\uff0c\u8be5\u7814\u7a76\u4e3a\u7406\u89e3\u548c\u89e3\u51b3Android\u6743\u9650\u6a21\u578b\u76f8\u5173\u95ee\u9898\u63d0\u4f9b\u4e86\u6df1\u5165\u89c1\u89e3\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411\u3002\u7814\u7a76\u8ba4\u4e3a\uff0c\u901a\u8fc7\u8fdb\u4e00\u6b65\u7684\u7814\u7a76\uff0c\u53ef\u4ee5\u6539\u8fdbAndroid\u6743\u9650\u7cfb\u7edf\u7684\u7075\u6d3b\u6027\u548c\u5b89\u5168\u6027\uff0c\u4f7f\u5176\u66f4\u52a0\u9002\u5e94\u4e0d\u65ad\u53d8\u5316\u7684\u5e94\u7528\u9700\u6c42\u548c\u6280\u672f\u8fdb\u6b65\u3002"}}
{"id": "2601.00270", "categories": ["cs.CR", "cs.LG", "cs.NE"], "pdf": "https://arxiv.org/pdf/2601.00270", "abs": "https://arxiv.org/abs/2601.00270", "authors": ["Fumiya Morimoto", "Ryuto Morita", "Satoshi Ono"], "title": "Rectifying Adversarial Examples Using Their Vulnerabilities", "comment": null, "summary": "Deep neural network-based classifiers are prone to errors when processing adversarial examples (AEs). AEs are minimally perturbed input data undetectable to humans posing significant risks to security-dependent applications. Hence, extensive research has been undertaken to develop defense mechanisms that mitigate their threats. Most existing methods primarily focus on discriminating AEs based on the input sample features, emphasizing AE detection without addressing the correct sample categorization before an attack. While some tasks may only require mere rejection on detected AEs, others necessitate identifying the correct original input category such as traffic sign recognition in autonomous driving. The objective of this study is to propose a method for rectifying AEs to estimate the correct labels of their original inputs. Our method is based on re-attacking AEs to move them beyond the decision boundary for accurate label prediction, effectively addressing the issue of rectifying minimally perceptible AEs created using white-box attack methods. However, challenge remains with respect to effectively rectifying AEs produced by black-box attacks at a distance from the boundary, or those misclassified into low-confidence categories by targeted attacks. By adopting a straightforward approach of only considering AEs as inputs, the proposed method can address diverse attacks while avoiding the requirement of parameter adjustments or preliminary training. Results demonstrate that the proposed method exhibits consistent performance in rectifying AEs generated via various attack methods, including targeted and black-box attacks. Moreover, it outperforms conventional rectification and input transformation methods in terms of stability against various attacks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b9\u6cd5\u4ee5\u4fee\u590d\u5bf9\u6297\u6837\u672c\uff08AEs\uff09\uff0c\u901a\u8fc7\u91cd\u65b0\u653b\u51fbAEs\u4f7f\u5176\u8d85\u51fa\u51b3\u7b56\u8fb9\u754c\u4ece\u800c\u51c6\u786e\u9884\u6d4b\u5176\u539f\u59cb\u8f93\u5165\u7684\u6807\u7b7e\u3002\u8be5\u65b9\u6cd5\u65e0\u9700\u9488\u5bf9\u7279\u5b9a\u653b\u51fb\u65b9\u6cd5\u8c03\u6574\u53c2\u6570\u6216\u5148\u8fdb\u884c\u57f9\u8bad\uff0c\u5c55\u793a\u4e86\u5bf9\u4e0d\u540c\u653b\u51fb\u65b9\u6cd5\u751f\u6210\u7684AEs\u5177\u6709\u4e00\u81f4\u6027\u8868\u73b0\uff0c\u5e76\u5728\u591a\u79cd\u653b\u51fb\u4e0b\u7684\u7a33\u5b9a\u6027\u4e0a\u4f18\u4e8e\u4f20\u7edf\u4fee\u6b63\u65b9\u6cd5\u548c\u8f93\u5165\u53d8\u6362\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u5bf9\u6297\u6837\u672c\u68c0\u6d4b\u65b9\u6cd5\u5927\u591a\u4fa7\u91cd\u4e8e\u4ec5\u9274\u522b\u5bf9\u6297\u6837\u672c\uff0c\u800c\u4e0d\u662f\u5728\u653b\u51fb\u524d\u8fdb\u884c\u6b63\u786e\u7684\u7c7b\u522b\u5206\u7c7b\u5904\u7406\u3002\u672c\u6587\u7814\u7a76\u65e8\u5728\u63d0\u51fa\u4e00\u79cd\u65b9\u6cd5\u6765\u4fee\u6b63\u5bf9\u6297\u6837\u672c\uff0c\u4ee5\u6062\u590d\u5b83\u4eec\u7684\u6b63\u786e\u6807\u7b7e\uff0c\u589e\u5f3a\u76ee\u6807\u5e94\u7528\u7684\u5b89\u5168\u6027\u3002", "method": "\u8be5\u65b9\u6cd5\u57fa\u4e8e\u91cd\u65b0\u653b\u51fb\u5bf9\u6297\u6837\u672c\uff0c\u4f7f\u5f97\u5b83\u4eec\u5728\u51b3\u7b56\u8fb9\u754c\u4e4b\u5916\uff0c\u4ece\u800c\u5b9e\u73b0\u51c6\u786e\u7684\u6807\u7b7e\u9884\u6d4b\u3002\u53ea\u8003\u8651\u5bf9\u6297\u6837\u672c\u4f5c\u4e3a\u8f93\u5165\uff0c\u907f\u514d\u4e86\u5bf9\u7279\u5b9a\u653b\u51fb\u7c7b\u578b\u8fdb\u884c\u53c2\u6570\u8c03\u6574\u7684\u5fc5\u8981\u3002\u7814\u7a76\u91c7\u7528\u4e86\u7b80\u5355\u7684\u65b9\u6cd5\uff0c\u65e0\u9700\u5148\u8fdb\u884c\u8bad\u7ec3\u6216\u8c03\u6574\u53c2\u6570\uff0c\u56e0\u6b64\u9002\u7528\u4e8e\u591a\u79cd\u653b\u51fb\u7c7b\u578b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u4e00\u81f4\u5730\u4fee\u590d\u901a\u8fc7\u4e0d\u540c\u653b\u51fb\u65b9\u6cd5\u751f\u6210\u7684\u5bf9\u6297\u6837\u672c\uff0c\u4e0d\u4ec5\u9002\u7528\u4e8e\u767d\u76d2\u653b\u51fb\uff0c\u8fd8\u80fd\u6709\u6548\u5e94\u5bf9\u9ed1\u76d2\u653b\u51fb\uff0c\u4e14\u5728\u62b5\u5fa1\u5404\u79cd\u653b\u51fb\u65b9\u9762\u7684\u7a33\u5b9a\u6027\u4f18\u4e8e\u4f20\u7edf\u4fee\u6b63\u65b9\u6cd5\u548c\u8f93\u5165\u53d8\u6362\u65b9\u6cd5\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u4e3a\u5bf9\u6297\u6837\u672c\u7684\u4fee\u6b63\u63d0\u4f9b\u4e86\u65b0\u7684\u9014\u5f84\uff0c\u53ef\u4ee5\u63d0\u5347\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u5b89\u5168\u5e94\u7528\u4e2d\u7684\u7a33\u5065\u6027\u3002"}}
{"id": "2601.00105", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.00105", "abs": "https://arxiv.org/abs/2601.00105", "authors": ["Muhammad U. Nasir", "Yuchen Li", "Steven James", "Julian Togelius"], "title": "Mortar: Evolving Mechanics for Automatic Game Design", "comment": null, "summary": "We present Mortar, a system for autonomously evolving game mechanics for automatic game design. Game mechanics define the rules and interactions that govern gameplay, and designing them manually is a time-consuming and expert-driven process. Mortar combines a quality-diversity algorithm with a large language model to explore a diverse set of mechanics, which are evaluated by synthesising complete games that incorporate both evolved mechanics and those drawn from an archive. The mechanics are evaluated by composing complete games through a tree search procedure, where the resulting games are evaluated by their ability to preserve a skill-based ordering over players -- that is, whether stronger players consistently outperform weaker ones. We assess the mechanics based on their contribution towards the skill-based ordering score in the game. We demonstrate that Mortar produces games that appear diverse and playable, and mechanics that contribute more towards the skill-based ordering score in the game. We perform ablation studies to assess the role of each system component and a user study to evaluate the games based on human feedback.", "AI": {"tldr": "Mortar\u81ea\u52a8\u751f\u6210\u6e38\u620f\u673a\u5236\uff0c\u901a\u8fc7\u8d28\u91cf\u591a\u6837\u6027\u7b97\u6cd5\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u76f8\u7ed3\u5408\uff0c\u63a2\u7d22\u591a\u6837\u5316\u7684\u6e38\u620f\u89c4\u5219\uff0c\u8fd9\u4e9b\u89c4\u5219\u88ab\u7528\u6765\u5408\u6210\u5b8c\u6574\u7684\u6e38\u620f\uff0c\u8bc4\u4f30\u6e38\u620f\u673a\u5236\u662f\u5426\u6709\u52a9\u4e8e\u6280\u80fd\u6392\u5e8f\u3002", "motivation": "\u901a\u8fc7\u5bf9\u6e38\u620f\u673a\u5236\u7684\u81ea\u52a8\u8bbe\u8ba1\uff0c\u4ee5\u51cf\u5c11\u8bbe\u8ba1\u8fc7\u7a0b\u4e2d\u7684\u65f6\u95f4\u548c\u4e13\u5bb6\u4f9d\u8d56\u3002", "method": "Mortar\u7cfb\u7edf\u4f7f\u7528\u8d28\u91cf\u591a\u6837\u6027\u7b97\u6cd5\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6765\u63a2\u7d22\u591a\u6837\u5316\u7684\u6e38\u620f\u89c4\u5219\u3002\u8fd9\u4e9b\u89c4\u5219\u901a\u8fc7\u5408\u6210\u5b8c\u6574\u7684\u6e38\u620f\u6765\u8fdb\u884c\u8bc4\u4f30\uff0c\u6e38\u620f\u7684\u8bc4\u4ef7\u6807\u51c6\u662f\u662f\u5426\u80fd\u4fdd\u6301\u73a9\u5bb6\u5728\u6280\u80fd\u4e0a\u7684\u6392\u5e8f\u3002", "result": "\u751f\u6210\u7684\u6e38\u620f\u591a\u6837\u5316\u4e14\u53ef\u73a9\uff0c\u6e38\u620f\u673a\u5236\u5bf9\u4fdd\u6301\u6280\u80fd\u6392\u5e8f\u6709\u8d21\u732e\u3002\u901a\u8fc7\u6d88\u878d\u7814\u7a76\u548c\u7528\u6237\u7814\u7a76\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u7684\u5404\u4e2a\u7ec4\u6210\u90e8\u5206\u7684\u4f5c\u7528\u3002", "conclusion": "Mortar\u7cfb\u7edf\u8bc1\u660e\u4e86\u5176\u5728\u81ea\u52a8\u6e38\u620f\u8bbe\u8ba1\u4e2d\u7684\u6f5c\u529b\uff0c\u4e3a\u6e38\u620f\u5f00\u53d1\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2601.00273", "categories": ["cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2601.00273", "abs": "https://arxiv.org/abs/2601.00273", "authors": ["Tamer Afifi", "Abdelfatah Hegazy", "Ehab Abousaif"], "title": "From Consensus to Chaos: A Vulnerability Assessment of the RAFT Algorithm", "comment": "10 pages, 8 figures, 3 tables. Published in International Journal of Advanced Computer Science and Applications (IJACSA), Vol. 16, No. 12 (2025)", "summary": "In recent decades, the RAFT distributed consensus algorithm has become a main pillar of the distributed systems ecosystem, ensuring data consistency and fault tolerance across multiple nodes. Although the fact that RAFT is well known for its simplicity, reliability, and efficiency, its security properties are not fully recognized, leaving implementations vulnerable to different kinds of attacks and threats, which can transform the RAFT harmony of consensus into a chaos of data inconsistency. This paper presents a systematic security analysis of the RAFT protocol, with a specific focus on its susceptibility to security threats such as message replay attacks and message forgery attacks. Examined how a malicious actor can exploit the protocol's message-passing mechanism to reintroduce old messages, disrupting the consensus process and leading to data inconsistency. The practical feasibility of these attacks is examined through simulated scenarios, and the key weaknesses in RAFT's design that enable them are identified. To address these vulnerabilities, a novel approach based on cryptography, authenticated message verification, and freshness check is proposed. This proposed solution provides a framework for enhancing the security of the RAFT implementations and guiding the development of more resilient distributed systems.", "AI": {"tldr": "\u672c\u6587\u5bf9RAFT\u534f\u8bae\u8fdb\u884c\u4e86\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u5206\u6790\uff0c\u6307\u51fa\u4e86\u5176\u5728\u6d88\u606f\u91cd\u64ad\u548c\u4f2a\u9020\u653b\u51fb\u65b9\u9762\u7684\u8106\u5f31\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u52a0\u5bc6\u3001\u8ba4\u8bc1\u6d88\u606f\u9a8c\u8bc1\u548c\u65b0\u9c9c\u5ea6\u68c0\u67e5\u7684\u65b9\u6cd5\u6765\u52a0\u5f3aRAFT\u7684\u5b89\u5168\u6027\u3002", "motivation": "\u5c3d\u7ba1RAFT\u56e0\u5176\u7b80\u5355\u6027\u3001\u53ef\u9760\u6027\u548c\u6548\u7387\u800c\u95fb\u540d\uff0c\u4f46\u5176\u5b89\u5168\u6027\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7684\u8ba4\u8bc6\uff0c\u8fd9\u4f7f\u5f97\u5b9e\u73b0\u4e86RAFT\u7684\u7cfb\u7edf\u5bb9\u6613\u53d7\u5230\u4e0d\u540c\u7c7b\u578b\u7684\u653b\u51fb\u548c\u5a01\u80c1\uff0c\u4ece\u800c\u5bfc\u81f4\u6570\u636e\u4e0d\u4e00\u81f4\u6027\u3002\u56e0\u6b64\uff0c\u672c\u6587\u65e8\u5728\u63ed\u793aRAFT\u534f\u8bae\u5728\u5b89\u5168\u6027\u65b9\u9762\u53ef\u80fd\u5b58\u5728\u7684\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u6539\u8fdb\u5efa\u8bae\u3002", "method": "\u901a\u8fc7\u6a21\u62df\u573a\u666f\u6765\u8bc4\u4f30\u8fd9\u4e9b\u653b\u51fb\u7684\u53ef\u884c\u6027\u548c\u8bc6\u522bRAFT\u8bbe\u8ba1\u4e2d\u7684\u5173\u952e\u5f31\u70b9\u3002\u7136\u540e\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u52a0\u5bc6\u3001\u6d88\u606f\u8ba4\u8bc1\u548c\u65b0\u9c9c\u5ea6\u68c0\u67e5\u7684\u65b0\u578b\u65b9\u6cd5\u6765\u52a0\u5f3aRAFT\u7684\u5b89\u5168\u6027\u3002", "result": "\u672c\u6587\u7684\u5de5\u4f5c\u5305\u62ec\u4e86\u66b4\u9732RAFT\u6f5c\u5728\u7684\u5b89\u5168\u5a01\u80c1\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5b89\u5168\u589e\u5f3a\u6846\u67b6\uff0c\u8fd9\u4e00\u6846\u67b6\u63d0\u4f9b\u4e86\u589e\u5f3a\u73b0\u6709RAFT\u5b9e\u73b0\u5b89\u5168\u6027\u7684\u57fa\u7840\u3002", "conclusion": "\u672c\u6587\u7684\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u901a\u8fc7\u5b9e\u65bd\u57fa\u4e8e\u52a0\u5bc6\u548c\u8ba4\u8bc1\u7684\u6d88\u606f\u9a8c\u8bc1\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8RAFT\u534f\u8bae\u7684\u5b89\u5168\u6027\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u589e\u5f3a\u5206\u5e03\u5f0f\u7cfb\u7edf\u53ef\u9760\u6027\u7684\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2601.00274", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.00274", "abs": "https://arxiv.org/abs/2601.00274", "authors": ["Weijie Wang", "Peizhuo Lv", "Yan Wang", "Rujie Dai", "Guokun Xu", "Qiujian Lv", "Hangcheng Liu", "Weiqing Huang", "Wei Dong", "Jiaheng Zhang"], "title": "Making Theft Useless: Adulteration-Based Protection of Proprietary Knowledge Graphs in GraphRAG Systems", "comment": null, "summary": "Graph Retrieval-Augmented Generation (GraphRAG) has emerged as a key technique for enhancing Large Language Models (LLMs) with proprietary Knowledge Graphs (KGs) in knowledge-intensive applications. As these KGs often represent an organization's highly valuable intellectual property (IP), they face a significant risk of theft for private use. In this scenario, attackers operate in isolated environments. This private-use threat renders passive defenses like watermarking ineffective, as they require output access for detection. Simultaneously, the low-latency demands of GraphRAG make strong encryption which incurs prohibitive overhead impractical. To address these challenges, we propose AURA, a novel framework based on Data Adulteration designed to make any stolen KG unusable to an adversary. Our framework pre-emptively injects plausible but false adulterants into the KG. For an attacker, these adulterants deteriorate the retrieved context and lead to factually incorrect responses. Conversely, for authorized users, a secret key enables the efficient filtering of all adulterants via encrypted metadata tags before they are passed to the LLM, ensuring query results remain completely accurate. Our evaluation demonstrates the effectiveness of this approach: AURA degrades the performance of unauthorized systems to an accuracy of just 5.3%, while maintaining 100% fidelity for authorized users with negligible overhead. Furthermore, AURA proves robust against various sanitization attempts, retaining 80.2% of its adulterants.", "AI": {"tldr": "AURA\u6846\u67b6\u901a\u8fc7\u9884\u5148\u5728\u77e5\u8bc6\u56fe\u8c31\u4e2d\u6ce8\u5165\u865a\u5047\u4f46\u5408\u7406\u7684\u7be1\u6539\uff0c\u4f7f\u5f97\u672a\u7ecf\u6388\u6743\u7684\u653b\u51fb\u8005\u65e0\u6cd5\u4f7f\u7528\u7a83\u53d6\u7684\u77e5\u8bc6\u56fe\u8c31\uff0c\u800c\u6388\u6743\u7528\u6237\u5219\u53ef\u4ee5\u901a\u8fc7\u89e3\u5bc6\u6807\u7b7e\u9ad8\u6548\u5730\u8fc7\u6ee4\u6389\u8fd9\u4e9b\u7be1\u6539\u3002\u5b9e\u9a8c\u8868\u660e\uff0cAURA\u80fd\u5c06\u975e\u6388\u6743\u7cfb\u7edf\u7684\u6027\u80fd\u964d\u81f35.3%\u7684\u51c6\u786e\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u6388\u6743\u7528\u6237\u67e5\u8be2\u7ed3\u679c\u7684\u5b8c\u5168\u51c6\u786e\u6027\u3002", "motivation": "\u9274\u4e8e\u7ec4\u7ec7\u7684\u77e5\u8bc6\u56fe\u8c31\u53ef\u80fd\u88ab\u7528\u4e8e\u5185\u90e8\u5e94\u7528\u5e76\u5305\u542b\u654f\u611f\u4fe1\u606f\uff0c\u9700\u8981\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u9632\u6b62\u6b64\u7c7b\u77e5\u8bc6\u56fe\u8c31\u88ab\u672a\u7ecf\u6388\u6743\u7684\u7528\u6237\u7a83\u53d6\u5e76\u7528\u4e8e\u975e\u6b63\u5f53\u76ee\u7684\u3002\u4f20\u7edf\u7684\u6c34\u5370\u6280\u672f\u56e0\u9700\u8981\u8bbf\u95ee\u8f93\u51fa\u624d\u80fd\u68c0\u6d4b\u800c\u65e0\u6548\uff0c\u800c\u5f3a\u52a0\u5bc6\u5219\u4f1a\u5e26\u6765\u96be\u4ee5\u63a5\u53d7\u7684\u5ef6\u8fdf\u6210\u672c\u3002", "method": "AURA\u6846\u67b6\u901a\u8fc7\u5728\u77e5\u8bc6\u56fe\u8c31\u4e2d\u52a0\u5165\u865a\u5047\u4f46\u53ef\u4fe1\u7684\u7be1\u6539\u5143\u7d20\u4f5c\u4e3a\u2018\u75ab\u82d7\u2019\uff0c\u4f7f\u5f97\u653b\u51fb\u8005\u5728\u4f7f\u7528\u6b64\u7c7b\u77e5\u8bc6\u56fe\u8c31\u65f6\u751f\u6210\u7684\u7ed3\u679c\u53d8\u5f97\u4e0d\u53ef\u4fe1\u3002\u6388\u6743\u7528\u6237\u5219\u6301\u6709\u79c1\u94a5\uff0c\u53ef\u4ee5\u89e3\u5bc6\u5e76\u8fc7\u6ee4\u8fd9\u4e9b\u7be1\u6539\uff0c\u4ece\u800c\u786e\u4fdd\u67e5\u8be2\u7ed3\u679c\u7684\u51c6\u786e\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cAURA\u80fd\u591f\u663e\u8457\u964d\u4f4e\u975e\u6388\u6743\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u51c6\u786e\u7387\u964d\u81f35.3%\u3002\u800c\u5bf9\u6388\u6743\u7528\u6237\u6765\u8bf4\uff0c\u7531\u4e8e\u79c1\u94a5\u7684\u5b58\u5728\uff0c\u5176\u67e5\u8be2\u7ed3\u679c\u7684\u51c6\u786e\u6027\u5f97\u5230\u4fdd\u8bc1\uff0c\u540c\u65f6AURA\u4e5f\u80fd\u591f\u6709\u6548\u5bf9\u6297\u5404\u79cd\u51c0\u5316\u5c1d\u8bd5\uff0c\u4fdd\u755980.2%\u7684\u7be1\u6539\u3002", "conclusion": "AURA\u6846\u67b6\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u4e14\u9ad8\u6548\u7684\u65b9\u6cd5\u6765\u4fdd\u62a4\u77e5\u8bc6\u56fe\u8c31\u7684\u5b89\u5168\u6027\uff0c\u80fd\u591f\u5728\u4fdd\u8bc1\u6388\u6743\u7528\u6237\u4f7f\u7528\u7684\u51c6\u786e\u6027\u548c\u4fbf\u5229\u6027\u7684\u540c\u65f6\uff0c\u6709\u6548\u904f\u5236\u672a\u7ecf\u6388\u6743\u7684\u4f7f\u7528\u884c\u4e3a\u3002"}}
{"id": "2601.00125", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.00125", "abs": "https://arxiv.org/abs/2601.00125", "authors": ["Keqin Xie"], "title": "Constructing a Neuro-Symbolic Mathematician from First Principles", "comment": null, "summary": "Large Language Models (LLMs) exhibit persistent logical failures in complex reasoning due to the lack of an internal axiomatic framework. We propose Mathesis, a neuro-symbolic architecture that encodes mathematical states as higher-order hypergraphs and uses a Symbolic Reasoning Kernel (SRK)--a differentiable logic engine that maps constraints to a continuous energy landscape. By defining a global energy function E(G), where zero energy implies logical consistency, the SRK yields gradient-based signals to train a Hypergraph Transformer Brain, turning proof search into energy minimization. Multi-step deduction is enabled via Monte Carlo Tree Search and Evolutionary Proof Search, guided by learned value functions and semantic unification.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMathesis\u7684\u795e\u7ecf\u7b26\u53f7\u67b6\u6784\uff0c\u901a\u8fc7\u5c06\u6570\u5b66\u72b6\u6001\u7f16\u7801\u4e3a\u9ad8\u9636\u8d85\u56fe\uff0c\u5e76\u7ed3\u5408\u7b26\u53f7\u63a8\u7406\u5185\u6838\uff08SRK\uff09\u5c06\u7ea6\u675f\u6620\u5c04\u5230\u8fde\u7eed\u80fd\u91cf\u666f\u89c2\uff0c\u5b9e\u73b0\u903b\u8f91\u4e00\u81f4\u6027\u7684\u8bad\u7ec3\u4e0e\u591a\u6b65\u63a8\u7406\uff0c\u4ece\u800c\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4e2d\u7684\u4e00\u8d2f\u903b\u8f91\u5931\u8d25\u95ee\u9898\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u590d\u6742\u63a8\u7406\u65f6\u5b58\u5728\u56fa\u6709\u7684\u903b\u8f91\u7f3a\u9677\uff0c\u56e0\u4e3a\u6ca1\u6709\u5185\u90e8\u516c\u7406\u6846\u67b6\u6307\u5bfc\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u7814\u7a76\u63d0\u51faMathesis\u67b6\u6784\uff0c\u5229\u7528\u795e\u7ecf\u7b26\u53f7\u6280\u672f\u589e\u5f3a\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002", "method": "Mathesis\u91c7\u7528\u9ad8\u9636\u8d85\u56fe\u7f16\u7801\u6570\u5b66\u72b6\u6001\uff0c\u5e76\u901a\u8fc7\u7b26\u53f7\u63a8\u7406\u5185\u6838\uff08SRK\uff09\u5c06\u7ea6\u675f\u4e0e\u8fde\u7eed\u80fd\u91cf\u666f\u89c2\u76f8\u5bf9\u5e94\uff0c\u4ece\u800c\u5b9a\u4e49\u4e00\u4e2a\u5168\u5c40\u80fd\u91cf\u51fd\u6570E(G)\uff0c\u8be5\u51fd\u6570\u5728\u96f6\u80fd\u91cf\u4e0b\u8868\u660e\u903b\u8f91\u4e00\u81f4\u6027\u3002SRK\u63d0\u4f9b\u68af\u5ea6\u4fe1\u53f7\u7528\u4e8e\u8bad\u7ec3\u9ad8\u9636\u53d8\u538b\u5668\u5927\u8111\uff0c\u4f7f\u8bc1\u660e\u641c\u7d22\u8f6c\u5316\u4e3a\u80fd\u91cf\u6700\u5c0f\u5316\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u548c\u8fdb\u5316\u8bc1\u660e\u641c\u7d22\u5b9e\u73b0\u591a\u6b65\u63a8\u7406\uff0c\u5229\u7528\u5b66\u4e60\u7684\u4ef7\u503c\u51fd\u6570\u548c\u8bed\u4e49\u7edf\u4e00\u8fdb\u884c\u5f15\u5bfc\u3002", "result": "\u901a\u8fc7\u8be5\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u5728\u591a\u6b65\u9aa4\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7531\u8bc1\u660e\u641c\u7d22\u5411\u80fd\u91cf\u6700\u5c0f\u5316\u8f6c\u53d8\u7684\u6280\u672f\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u5728\u5904\u7406\u590d\u6742\u63a8\u7406\u4efb\u52a1\u65f6\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u7814\u7a76\u8bc1\u660e\u4e86Mathesis\u67b6\u6784\u7684\u6709\u6548\u6027\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4e0a\u7684\u903b\u8f91\u7f3a\u9677\uff0c\u5c55\u793a\u4e86\u5176\u5728\u589e\u5f3a\u6a21\u578b\u63a8\u7406\u80fd\u529b\u548c\u89e3\u51b3\u903b\u8f91\u4e00\u81f4\u6027\u7684\u6f5c\u529b\u3002"}}
{"id": "2601.00332", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.00332", "abs": "https://arxiv.org/abs/2601.00332", "authors": ["Juan Pedro Hecht", "Hugo Daniel Scolnik"], "title": "PQC standards alternatives -- reliable semantically secure key encapsulation mechanism and digital signature protocols using the rank-deficient matrix power function", "comment": "14 pages, 1 Figure, 2 Tables, 19 References, 2 Appendix", "summary": "Post-quantum cryptography-PQC- aims to develop public-key primitives that are secure against adversaries using classical and quantum computing technologies. This study introduces novel protocols, a key encapsulation mechanism, a digital signature scheme, and special protection against linear attacks. Our purpose is to create reliable alternatives to current standards, seeking compact, fast, and secure replacements of the key interchange and digital signature in the TLS 1_3 protocol, which safeguards Internet traffic, allowing an easy post-quantum transition to protect current data from the harvest now, decrypt later threat.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u65b0\u578b\u534f\u8bae\u3001\u5bc6\u94a5\u5c01\u88c5\u673a\u5236\u3001\u6570\u5b57\u7b7e\u540d\u65b9\u6848\u4ee5\u53ca\u5bf9\u6297\u7ebf\u6027\u653b\u51fb\u7684\u7279\u6b8a\u4fdd\u62a4\u63aa\u65bd\u3002\u76ee\u7684\u662f\u4e3a\u5f53\u524d\u6807\u51c6\u5bfb\u627e\u53ef\u9760\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u8bbe\u8ba1\u66f4\u7d27\u51d1\u3001\u66f4\u5feb\u4e14\u66f4\u5b89\u5168\u7684\u516c\u94a5\u4ea4\u6362\u548c\u6570\u5b57\u7b7e\u540d\uff0c\u4ece\u800c\u4fdd\u969c\u4e92\u8054\u7f51\u6d41\u91cf\u7684\u5b89\u5168\u3002", "motivation": "\u4e3a\u4e86\u5bf9\u6297\u672a\u6765\u7684\u91cf\u5b50\u8ba1\u7b97\u673a\u5e26\u6765\u7684\u5a01\u80c1\uff0c\u786e\u4fdd\u73b0\u6709\u6570\u636e\u7684\u5b89\u5168\uff0c\u907f\u514d\u5728\u73b0\u5728\u6536\u96c6\u6570\u636e\u3001\u5f85\u91cf\u5b50\u8ba1\u7b97\u6280\u672f\u6210\u719f\u540e\u518d\u8fdb\u884c\u89e3\u5bc6\u7684\u6f5c\u5728\u98ce\u9669\u3002", "method": "\u63d0\u51fa\u4e86\u65b0\u7684\u534f\u8bae\u548c\u673a\u5236\uff0c\u7279\u522b\u8bbe\u8ba1\u7528\u4e8e\u63d0\u9ad8\u516c\u94a5\u4e92\u6362\u548c\u6570\u5b57\u7b7e\u540d\u7684\u5b89\u5168\u6027\uff0c\u540c\u65f6\u786e\u4fdd\u8fd9\u4e9b\u673a\u5236\u5177\u6709\u7d27\u51d1\u6027\u548c\u9ad8\u6548\u6027\u3002", "result": "\u6210\u529f\u5b9e\u73b0\u4e86\u65b0\u578b\u7684\u5bc6\u94a5\u5c01\u88c5\u673a\u5236\u548c\u6570\u5b57\u7b7e\u540d\u65b9\u6848\uff0c\u63d0\u9ad8\u4e86\u5b89\u5168\u6027\u548c\u6548\u7387\u3002", "conclusion": "\u7814\u7a76\u4e3a\u52a0\u5bc6\u534f\u8bae\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u987a\u5229\u8fc7\u6e21\u5230\u540e\u91cf\u5b50\u5bc6\u94a5\u4ea4\u6362\u548c\u6570\u5b57\u7b7e\u540d\uff0c\u589e\u5f3a\u73b0\u6709\u7cfb\u7edf\u5728\u672a\u6765\u7684\u5b89\u5168\u6027\u3002"}}
{"id": "2601.00138", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.00138", "abs": "https://arxiv.org/abs/2601.00138", "authors": ["Jorge Ortiz"], "title": "Explicit Abstention Knobs for Predictable Reliability in Video Question Answering", "comment": "Preprint. Diagnostic study of confidence-based abstention under evidence truncation", "summary": "High-stakes deployment of vision-language models (VLMs) requires selective prediction, where systems abstain when uncertain rather than risk costly errors. We investigate whether confidence-based abstention provides reliable control over error rates in video question answering, and whether that control remains robust under distribution shift. Using NExT-QA and Gemini 2.0 Flash, we establish two findings. First, confidence thresholding provides mechanistic control in-distribution. Sweeping threshold epsilon produces smooth risk-coverage tradeoffs, reducing error rates f", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u5728\u89c6\u9891\u95ee\u7b54\u4efb\u52a1\u4e2d\u901a\u8fc7\u7f6e\u4fe1\u5ea6\u9608\u503c\u5316\u5b9e\u73b0\u7684\u7f6e\u4fe1\u533a\u95f4\u907f\u9009\u53ef\u4ee5\u6709\u6548\u63a7\u5236\u9519\u8bef\u7387\uff0c\u5e76\u4e14\u8fd9\u79cd\u63a7\u5236\u5728\u5206\u5e03\u8fc1\u79fb\u65f6\u4f9d\u7136\u7a33\u5065\u3002", "motivation": "\u9ad8\u98ce\u9669\u573a\u666f\u4e2d\u90e8\u7f72\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u9700\u8981\u9009\u62e9\u6027\u9884\u6d4b\uff0c\u5373\u5f53\u6a21\u578b\u4e0d\u786e\u5b9a\u65f6\u9009\u62e9\u56de\u907f\u800c\u4e0d\u662f\u5192\u9669\u72af\u9519\u3002\u4f5c\u8005\u7814\u7a76\u4e86\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u907f\u9009\u65b9\u6cd5\u5728\u89c6\u9891\u95ee\u7b54\u4e2d\u7684\u53ef\u9760\u6027\u548c\u666e\u9002\u6027\u3002", "method": "\u5229\u7528NExT-QA\u548cGemini 2.0 Flash\u4e24\u4e2a\u6570\u636e\u96c6\uff0c\u4f5c\u8005\u901a\u8fc7\u5bf9\u7f6e\u4fe1\u5ea6\u9608\u503c\u03b5\u8fdb\u884c\u8c03\u6574\uff0c\u63a2\u7d22\u7f6e\u4fe1\u907f\u9009\u7b56\u7565\u5728\u4e0d\u540c\u7f6e\u4fe1\u5ea6\u9608\u503c\u4e0b\u7684\u98ce\u9669-\u8986\u76d6\u7387\u6743\u8861\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5728\u5206\u5e03\u5185\uff0c\u901a\u8fc7\u6539\u53d8\u7f6e\u4fe1\u5ea6\u9608\u503c\u53ef\u4ee5\u5e73\u6ed1\u5730\u6539\u53d8\u98ce\u9669\u2014\u8986\u76d6\u7387\u5e73\u8861\uff0c\u4ece\u800c\u964d\u4f4e\u9519\u8bef\u7387\u3002\u540c\u65f6\u786e\u8ba4\uff0c\u8fd9\u79cd\u63a7\u5236\u673a\u5236\u5728\u5206\u5e03\u8fc1\u79fb\u65f6\u4f9d\u7136\u7a33\u5065\u3002", "conclusion": "\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u907f\u9009\u7b56\u7565\u5728\u89c6\u9891\u95ee\u7b54\u4efb\u52a1\u4e2d\u53ef\u4ee5\u6709\u6548\u5730\u63a7\u5236\u9519\u8bef\u7387\uff0c\u5e76\u4e14\u5728\u6570\u636e\u5206\u5e03\u53d1\u751f\u53d8\u5316\u7684\u60c5\u51b5\u4e0b\u4f9d\u7136\u4fdd\u6301\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2601.00353", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.00353", "abs": "https://arxiv.org/abs/2601.00353", "authors": ["Saif E. Nouma", "Gokhan Mumcu", "Attila A. Yavuz"], "title": "Diamond: Design and Implementation of Breach-Resilient Authenticated Encryption Framework For Internet of Things", "comment": null, "summary": "Resource-constrained Internet of Things (IoT) devices, from medical implants to small drones, must transmit sensitive telemetry under adversarial wireless channels while operating under stringent computing and energy budgets. Authenticated Encryption (AE) is essential for ensuring confidentiality, integrity, and authenticity. However, existing lightweight AE standards lack forward-security guarantees, compact tag aggregation, and offline-online (OO) optimizations required for modern high-throughput IoT pipelines.\n  We introduce Diamond, the first provable secure Forward-secure and Aggregate Authenticated Encryption (FAAE) framework that extends and generalizes prior FAAE constructions through a lightweight key evolution mechanism, an OO-optimized computation pipeline, and a set of performance-tiered instantiations tailored to heterogeneous IoT platforms. Diamond substantially reduces amortized offline preprocessing (up to 47%) and achieves up to an order-ofmagnitude reduction in end-to-end latency for large telemetry batches. Our comprehensive evaluation across 64-bit ARM Cortex-A72, 32-bit ARM Cortex-M4, and 8-bit AVR architectures confirms that Diamond consistently outperforms baseline FAAE variants and NIST lightweight AE candidates across authenticated encryption throughput and end-to-end verification latency while maintaining compact tag aggregation and strong breach resilience. We formally prove the security of Diamond and provide two concrete instantiations optimized for compliance and high efficiency. Our open-source release enables reproducibility and seamless integration into IoT platforms.", "AI": {"tldr": "Diamond \u662f\u4e00\u79cd\u65b0\u578b\u7684\u9ad8\u6027\u80fd\u3001\u4f4e\u80fd\u8017\u7684\u8ba4\u8bc1\u52a0\u5bc6\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u7684\u7269\u8054\u7f51\u8bbe\u5907\uff0c\u5b83\u51cf\u5c11\u4e86\u9884\u5904\u7406\u65f6\u95f4\u5e76\u964d\u4f4e\u4e86\u7aef\u5230\u7aef\u5ef6\u8fdf\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u7d27\u51d1\u7684\u6807\u7b7e\u805a\u5408\u548c\u5f3a\u5927\u7684\u6cc4\u9732\u6062\u590d\u80fd\u529b\u3002", "motivation": "\u8d44\u6e90\u53d7\u9650\u7684\u7269\u8054\u7f51\u8bbe\u5907\u9700\u8981\u5728\u654c\u5bf9\u7684\u65e0\u7ebf\u901a\u9053\u4e0b\u4f20\u8f93\u654f\u611f\u6570\u636e\u3002\u73b0\u6709\u7684\u8f7b\u91cf\u7ea7\u8ba4\u8bc1\u52a0\u5bc6\uff08AE\uff09\u6807\u51c6\u7f3a\u4e4f\u524d\u5411\u5b89\u5168\u6027\u4fdd\u8bc1\u3001\u7d27\u51d1\u7684\u6807\u7b7e\u805a\u5408\u4ee5\u53ca\u5728\u7ebf\u4e0b-\u5728\u7ebf\u4f18\u5316\uff0c\u8fd9\u4e9b\u5bf9\u4e8e\u73b0\u4ee3\u9ad8\u6027\u80fd\u7684\u7269\u8054\u7f51\u7ba1\u9053\u662f\u5fc5\u9700\u7684\u3002", "method": "Diamond \u901a\u8fc7\u8f7b\u91cf\u7ea7\u5bc6\u94a5\u6f14\u5316\u673a\u5236\u3001\u5728\u7ebf\u4e0b-\u5728\u7ebf\u4f18\u5316\u8ba1\u7b97\u7ba1\u9053\u4ee5\u53ca\u9488\u5bf9\u4e0d\u540c\u7269\u8054\u7f51\u5e73\u53f0\u7684\u6027\u80fd\u5206\u7ea7\u5b9e\u73b0\uff0c\u662f\u9996\u4e2a\u65e2\u5177\u5907\u524d\u5411\u5b89\u5168\u6027\u548c\u805a\u5408\u529f\u80fd\u7684\u8ba4\u8bc1\u52a0\u5bc6\u6846\u67b6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cDiamond \u76f8\u5bf9\u4e8e\u57fa\u51c6\u6a21\u578b\u548c\u7f8e\u56fd\u56fd\u5bb6\u6807\u51c6\u4e0e\u6280\u672f\u7814\u7a76\u9662\uff08NIST\uff09\u8f7b\u91cf\u7ea7 AE \u5019\u9009\u65b9\u6848\u5728\u8ba4\u8bc1\u52a0\u5bc6\u541e\u5410\u91cf\u548c\u7aef\u5230\u7aef\u9a8c\u8bc1\u5ef6\u8fdf\u4e0a\u5747\u8868\u73b0\u51fa\u66f4\u4f18\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u7d27\u51d1\u7684\u6807\u7b7e\u805a\u5408\u548c\u5f3a\u5927\u7684\u6cc4\u9732\u6062\u590d\u80fd\u529b\u3002", "conclusion": "Diamond \u5df2\u7ecf\u88ab\u6b63\u5f0f\u8bc1\u660e\u5b89\u5168\uff0c\u5e76\u63d0\u4f9b\u4e86\u89e3\u51b3\u65b9\u6848\u7684\u6b63\u5f0f\u8bc1\u660e\u3002\u5f00\u653e\u6e90\u4ee3\u7801\u7684\u53d1\u5e03\u4f7f\u5f97\u8be5\u65b9\u6848\u53ef\u4ee5\u88ab\u590d\u5236\u548c\u65e0\u7f1d\u6574\u5408\u8fdb\u7269\u8054\u7f51\u5e73\u53f0\u3002"}}
{"id": "2601.00227", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.00227", "abs": "https://arxiv.org/abs/2601.00227", "authors": ["Shanli Xing", "Yiyan Zhai", "Alexander Jiang", "Yixin Dong", "Yong Wu", "Zihao Ye", "Charlie Ruan", "Yingyi Huang", "Yineng Zhang", "Liangsheng Yin", "Aksara Bayyapu", "Luis Ceze", "Tianqi Chen"], "title": "FlashInfer-Bench: Building the Virtuous Cycle for AI-driven LLM Systems", "comment": null, "summary": "Recent advances show that large language models (LLMs) can act as autonomous agents capable of generating GPU kernels, but integrating these AI-generated kernels into real-world inference systems remains challenging. FlashInfer-Bench addresses this gap by establishing a standardized, closed-loop framework that connects kernel generation, benchmarking, and deployment. At its core, FlashInfer Trace provides a unified schema describing kernel definitions, workloads, implementations, and evaluations, enabling consistent communication between agents and systems. Built on real serving traces, FlashInfer-Bench includes a curated dataset, a robust correctness- and performance-aware benchmarking framework, a public leaderboard to track LLM agents' GPU programming capabilities, and a dynamic substitution mechanism (apply()) that seamlessly injects the best-performing kernels into production LLM engines such as SGLang and vLLM. Using FlashInfer-Bench, we further evaluate the performance and limitations of LLM agents, compare the trade-offs among different GPU programming languages, and provide insights for future agent design. FlashInfer-Bench thus establishes a practical, reproducible pathway for continuously improving AI-generated kernels and deploying them into large-scale LLM inference.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.00357", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.00357", "abs": "https://arxiv.org/abs/2601.00357", "authors": ["Jiajun Zhou", "Changhui Sun", "Meng Shen", "Shanqing Yu", "Qi Xuan"], "title": "Traffic-MoE: A Sparse Foundation Model for Network Traffic Analysis", "comment": null, "summary": "While pre-trained large models have achieved state-of-the-art performance in network traffic analysis, their prohibitive computational costs hinder deployment in real-time, throughput-sensitive network defense environments. This work bridges the gap between advanced representation learning and practical network protection by introducing Traffic-MoE, a sparse foundation model optimized for high-efficiency real-time inference. By dynamically routing traffic tokens to a small subset of specialized experts, Traffic-MoE effectively decouples model capacity from computational overhead. Extensive evaluations across three security-oriented tasks demonstrate that Traffic-MoE achieves up to a 12.38% improvement in detection performance compared to leading dense competitors. Crucially, it delivers a 91.62% increase in throughput, reduces inference latency by 47.81%, and cuts peak GPU memory consumption by 38.72%. Beyond efficiency, Traffic-MoE exhibits superior robustness against adversarial traffic shaping and maintains high detection efficacy in few-shot scenarios, establishing a new paradigm for scalable and resilient network traffic analysis.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.00240", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.00240", "abs": "https://arxiv.org/abs/2601.00240", "authors": ["Zongwei Wang", "Bincheng Gu", "Hongyu Yu", "Junliang Yu", "Tao He", "Jiayin Feng", "Min Gao"], "title": "Will LLM-powered Agents Bias Against Humans? Exploring the Belief-Dependent Vulnerability", "comment": "16 pages", "summary": "LLM-empowered agents can exhibit not only demographic bias (e.g., gender, religion) but also intergroup bias triggered by minimal \"us\" versus \"them\" cues. When this intergroup boundary aligns with an agent-human divide, the risk shifts from disparities among human demographic groups to a more fundamental group-level asymmetry, i.e., humans as a whole may be treated as the outgroup by agents. To examine this possibility, we construct a controlled multi-agent social simulation based on allocation decisions under explicit payoff trade-offs and find that agents exhibit a consistent intergroup bias under minimal group cues. Although this bias is attenuated when some counterparts are framed as humans, we attribute the attenuation to an implicit human-norm script that favors humans yet activates only when the agent believes a real human is present. This belief dependence creates a new attack surface. We therefore introduce a Belief Poisoning Attack (BPA) that corrupts persistent identity beliefs to suppress the human-norm script and reactivate outgroup bias toward humans, instantiated as profile poisoning at initialization (BPA-PP) and memory poisoning via optimized belief-refinement suffixes injected into stored reflections (BPA-MP). Finally, we discuss practical mitigation strategies for hardening current agent frameworks against BPA, highlighting feasible interventions at profile and memory boundaries. Extensive experiments demonstrate both the existence of agent intergroup bias and the severity of BPA across settings. Our goal in identifying these vulnerabilities is to inform safer agent design, not to enable real-world exploitation.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.00367", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.00367", "abs": "https://arxiv.org/abs/2601.00367", "authors": ["Nandish Chattopadhyay", "Abdul Basit", "Amira Guesmi", "Muhammad Abdullah Hanif", "Bassem Ouni", "Muhammad Shafique"], "title": "PatchBlock: A Lightweight Defense Against Adversarial Patches for Embedded EdgeAI Devices", "comment": "7 pages, 5 figures, 5 tables, Accepted to DATE 2026", "summary": "Adversarial attacks pose a significant challenge to the reliable deployment of machine learning models in EdgeAI applications, such as autonomous driving and surveillance, which rely on resource-constrained devices for real-time inference. Among these, patch-based adversarial attacks, where small malicious patches (e.g., stickers) are applied to objects, can deceive neural networks into making incorrect predictions with potentially severe consequences. In this paper, we present PatchBlock, a lightweight framework designed to detect and neutralize adversarial patches in images. Leveraging outlier detection and dimensionality reduction, PatchBlock identifies regions affected by adversarial noise and suppresses their impact. It operates as a pre-processing module at the sensor level, efficiently running on CPUs in parallel with GPU inference, thus preserving system throughput while avoiding additional GPU overhead. The framework follows a three-stage pipeline: splitting the input into chunks (Chunking), detecting anomalous regions via a redesigned isolation forest with targeted cuts for faster convergence (Separating), and applying dimensionality reduction on the identified outliers (Mitigating). PatchBlock is both model- and patch-agnostic, can be retrofitted to existing pipelines, and integrates seamlessly between sensor inputs and downstream models. Evaluations across multiple neural architectures, benchmark datasets, attack types, and diverse edge devices demonstrate that PatchBlock consistently improves robustness, recovering up to 77% of model accuracy under strong patch attacks such as the Google Adversarial Patch, while maintaining high portability and minimal clean accuracy loss. Additionally, PatchBlock outperforms the state-of-the-art defenses in efficiency, in terms of computation time and energy consumption per sample, making it suitable for EdgeAI applications.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.00290", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.00290", "abs": "https://arxiv.org/abs/2601.00290", "authors": ["Sixue Xing", "Xuanye Xia", "Kerui Wu", "Meng Jiang", "Jintai Chen", "Tianfan Fu"], "title": "ClinicalReTrial: A Self-Evolving AI Agent for Clinical Trial Protocol Optimization", "comment": null, "summary": "Clinical trial failure remains a central bottleneck in drug development, where minor protocol design flaws can irreversibly compromise outcomes despite promising therapeutics. Although cutting-edge AI methods achieve strong performance in predicting trial success, they are inherently reactive for merely diagnosing risk without offering actionable remedies once failure is anticipated. To fill this gap, this paper proposes ClinicalReTrial, a self-evolving AI agent framework that addresses this gap by casting clinical trial reasoning as an iterative protocol redesign problem. Our method integrates failure diagnosis, safety-aware modification, and candidate evaluation in a closed-loop, reward-driven optimization framework. Serving the outcome prediction model as a simulation environment, ClinicalReTrial enables low-cost evaluation of protocol modifications and provides dense reward signals for continuous self-improvement. To support efficient exploration, the framework maintains hierarchical memory that captures iteration-level feedback within trials and distills transferable redesign patterns across trials. Empirically, ClinicalReTrial improves 83.3% of trial protocols with a mean success probability gain of 5.7%, and retrospective case studies demonstrate strong alignment between the discovered redesign strategies and real-world clinical trial modifications.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.00370", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.00370", "abs": "https://arxiv.org/abs/2601.00370", "authors": ["Joshua Shen"], "title": "Ouroboros AutoSyn: Time Based Permissionless Synchrony Model for PoS", "comment": null, "summary": "Blockchain as a promising technology is gaining its popularity ever since proof-of-work based Bitcoin came to the world. Nevertheless, Bitcoin achieves consensus at an expensive cost of energy. Proof-of-stake is one of the solutions for such a problem. Participants of PoS protocols achieve dynamic-availability in permissionless settings. Parties can join and leave the protocol at their will without notifying others. However, such protocol relies heavily on a central clock, providing the function of synchrony by collecting the finish status of every honest participant.\n  In our protocol, the global function maintains the round information for each participant no longer needed. We analyze and modify the round into real-time based round model. Message delivery delay is also taken into consideration of the round length. However, participant need the connection of a real-world time global clock which is crucial to calculate the current round. And round length also is adjusted due to the changing network situation at the start of every new epoch.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.00324", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.00324", "abs": "https://arxiv.org/abs/2601.00324", "authors": ["Alicia Vidler", "Gal A. Kaminka"], "title": "Multiagent Reinforcement Learning for Liquidity Games", "comment": "9 pages", "summary": "Making use of swarm methods in financial market modeling of liquidity, and techniques from financial analysis in swarm analysis, holds the potential to advance both research areas. In swarm research, the use of game theory methods holds the promise of explaining observed phenomena of collective utility adherence with rational self-interested swarm participants. In financial markets, a better understanding of how independent financial agents may self-organize for the betterment and stability of the marketplace would be a boon for market design researchers. This paper unifies Liquidity Games, where trader payoffs depend on aggregate liquidity within a trade, with Rational Swarms, where decentralized agents use difference rewards to align self-interested learning with global objectives. We offer a theoretical frameworks where we define a swarm of traders whose collective objective is market liquidity provision while maintaining agent independence. Using difference rewards within a Markov team games framework, we show that individual liquidity-maximizing behaviors contribute to overall market liquidity without requiring coordination or collusion. This Financial Swarm model provides a framework for modeling rational, independent agents where they achieve both individual profitability and collective market efficiency in bilateral asset markets.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.00372", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.00372", "abs": "https://arxiv.org/abs/2601.00372", "authors": ["Taufiq Islam Protick", "Sai Teja Peddinti", "Nina Taft", "Anupam Das"], "title": "LLM-Powered Analysis of IoT User Reviews: Tracking and Ranking Security and Privacy Concerns", "comment": null, "summary": "Being able to understand the security and privacy (S&P) concerns of IoT users brings benefits to both developers and users. To learn about users' views, we examine Amazon IoT reviews - one of the biggest IoT markets. This work presents a state-of-the-art methodology to identify and categorize reviews in which users express S&P concerns. We developed an automated pipeline by fine-tuning GPT-3.5-Turbo to build two models: the Classifier-Rationalizer-Categorizer and the Thematic Mapper. By leveraging dynamic few-shot prompting and the model's large context size, our pipeline achieved over 97% precision and recall, significantly outperforming keyword-based and classical ML methods. We applied our pipeline to 91K Amazon reviews about fitness trackers, smart speakers and cameras, over multiple years. We found that on average 5% contained S&P concerns, while security camera exhibited the highest prevalence at 10%. Our method detected significantly more S&P-relevant reviews than prior works: 15x more for fitness trackers, 29% more for smart speakers, and 70% more for cameras. Our longitudinal analysis reveals that concerns like surveillance and data control have persisted for years, suggesting limited industry progress. We demonstrate that across all device types, users consistently demand more precise control over what data is collected and shared. We uncover challenges in multi-user and multi-device interactions, identifying two previously unreported themes concerning inadequate controls for account separation and data access. These findings, ranging from broad persistent trends to specific instances of customer loss, offer actionable insights for developers to improve user satisfaction and trust.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.00339", "categories": ["cs.AI", "cs.DC", "cs.ET", "cs.MA", "cs.NE"], "pdf": "https://arxiv.org/pdf/2601.00339", "abs": "https://arxiv.org/abs/2601.00339", "authors": ["Alaa Saleh", "Praveen Kumar Donta", "Roberto Morabito", "Sasu Tarkoma", "Anders Lindgren", "Qiyang Zhang", "Schahram Dustdar Susanna Pirttikangas", "Lauri Lov\u00e9n"], "title": "Bio-inspired Agentic Self-healing Framework for Resilient Distributed Computing Continuum Systems", "comment": null, "summary": "Human biological systems sustain life through extraordinary resilience, continually detecting damage, orchestrating targeted responses, and restoring function through self-healing. Inspired by these capabilities, this paper introduces ReCiSt, a bio-inspired agentic self-healing framework designed to achieve resilience in Distributed Computing Continuum Systems (DCCS). Modern DCCS integrate heterogeneous computing resources, ranging from resource-constrained IoT devices to high-performance cloud infrastructures, and their inherent complexity, mobility, and dynamic operating conditions expose them to frequent faults that disrupt service continuity. These challenges underscore the need for scalable, adaptive, and self-regulated resilience strategies. ReCiSt reconstructs the biological phases of Hemostasis, Inflammation, Proliferation, and Remodeling into the computational layers Containment, Diagnosis, Meta-Cognitive, and Knowledge for DCCS. These four layers perform autonomous fault isolation, causal diagnosis, adaptive recovery, and long-term knowledge consolidation through Language Model (LM)-powered agents. These agents interpret heterogeneous logs, infer root causes, refine reasoning pathways, and reconfigure resources with minimal human intervention. The proposed ReCiSt framework is evaluated on public fault datasets using multiple LMs, and no baseline comparison is included due to the scarcity of similar approaches. Nevertheless, our results, evaluated under different LMs, confirm ReCiSt's self-healing capabilities within tens of seconds with minimum of 10% of agent CPU usage. Our results also demonstrated depth of analysis to over come uncertainties and amount of micro-agents invoked to achieve resilience.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.00384", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.00384", "abs": "https://arxiv.org/abs/2601.00384", "authors": ["Md Mahbub Hasan", "Marcus Sternhagen", "Krishna Chandra Roy"], "title": "Engineering Attack Vectors and Detecting Anomalies in Additive Manufacturing", "comment": "This paper has been accepted to EAI SmartSP 2025. This is the preprint version", "summary": "Additive manufacturing (AM) is rapidly integrating into critical sectors such as aerospace, automotive, and healthcare. However, this cyber-physical convergence introduces new attack surfaces, especially at the interface between computer-aided design (CAD) and machine execution layers. In this work, we investigate targeted cyberattacks on two widely used fused deposition modeling (FDM) systems, Creality's flagship model K1 Max, and Ender 3. Our threat model is a multi-layered Man-in-the-Middle (MitM) intrusion, where the adversary intercepts and manipulates G-code files during upload from the user interface to the printer firmware. The MitM intrusion chain enables several stealthy sabotage scenarios. These attacks remain undetectable by conventional slicer software or runtime interfaces, resulting in structurally defective yet externally plausible printed parts. To counter these stealthy threats, we propose an unsupervised Intrusion Detection System (IDS) that analyzes structured machine logs generated during live printing. Our defense mechanism uses a frozen Transformer-based encoder (a BERT variant) to extract semantic representations of system behavior, followed by a contrastively trained projection head that learns anomaly-sensitive embeddings. Later, a clustering-based approach and a self-attention autoencoder are used for classification. Experimental results demonstrate that our approach effectively distinguishes between benign and compromised executions.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.00400", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.00400", "abs": "https://arxiv.org/abs/2601.00400", "authors": ["Weng Ding", "Yi Han", "Mu-Jiang-Shan Wang"], "title": "Adaptive Causal Coordination Detection for Social Media: A Memory-Guided Framework with Semi-Supervised Learning", "comment": "15 pages, 8 figures. Under review", "summary": "Detecting coordinated inauthentic behavior on social media remains a critical and persistent challenge, as most existing approaches rely on superficial correlation analysis, employ static parameter settings, and demand extensive and labor-intensive manual annotation. To address these limitations systematically, we propose the Adaptive Causal Coordination Detection (ACCD) framework. ACCD adopts a three-stage, progressive architecture that leverages a memory-guided adaptive mechanism to dynamically learn and retain optimal detection configurations for diverse coordination scenarios. Specifically, in the first stage, ACCD introduces an adaptive Convergent Cross Mapping (CCM) technique to deeply identify genuine causal relationships between accounts. The second stage integrates active learning with uncertainty sampling within a semi-supervised classification scheme, significantly reducing the burden of manual labeling. The third stage deploys an automated validation module driven by historical detection experience, enabling self-verification and optimization of the detection outcomes. We conduct a comprehensive evaluation using real-world datasets, including the Twitter IRA dataset, Reddit coordination traces, and several widely-adopted bot detection benchmarks. Experimental results demonstrate that ACCD achieves an F1-score of 87.3\\% in coordinated attack detection, representing a 15.2\\% improvement over the strongest existing baseline. Furthermore, the system reduces manual annotation requirements by 68\\% and achieves a 2.8x speedup in processing through hierarchical clustering optimization. In summary, ACCD provides a more accurate, efficient, and highly automated end-to-end solution for identifying coordinated behavior on social platforms, offering substantial practical value and promising potential for broad application.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.00385", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.00385", "abs": "https://arxiv.org/abs/2601.00385", "authors": ["Brahim Khalil Sedraoui", "Abdelmadjid Benmachiche", "Amina Makhlouf", "Chaouki Chemam"], "title": "Exploring the Integration of Differential Privacy in Cybersecurity Analytics: Balancing Data Utility and Privacy in Threat Intelligence", "comment": null, "summary": "To resolve the acute problem of privacy protection and guarantee that data can be used in the context of threat intelligence, this paper considers the implementation of Differential Privacy (DP) in cybersecurity analytics. DP, which is a sound mathematical framework, ensures privacy by adding a controlled noise to data outputs and thus avoids sensitive information disclosure even with auxiliary datasets. The use of DP in Security Information and Event Management (SIEM) systems is highlighted, and it can be seen that DP has the capability to protect event log and threat data analysis without interfering with the analytical efficiency. The utility versus privacy trade-offs linked to the maximization of the epsilon parameter, which is one of the critical components of DP mechanisms, is pointed out. The article shows the transformative power of DP in promoting safe sharing of data and joint threat intelligence through real-world systems and case studies. Finally, this paper makes DP one of the key strategies to improve privacy-preserving analytics in the field of cybersecurity.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.00421", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.00421", "abs": "https://arxiv.org/abs/2601.00421", "authors": ["Alessio Di Rubbo", "Mattia Neri", "Remo Pareschi", "Marco Pedroni", "Roberto Valtancoli", "Paolino Zica"], "title": "Can Semantic Methods Enhance Team Sports Tactics? A Methodology for Football with Broader Applications", "comment": "Submitted to Sci (MDPI) for peer review", "summary": "This paper explores how semantic-space reasoning, traditionally used in computational linguistics, can be extended to tactical decision-making in team sports. Building on the analogy between texts and teams -- where players act as words and collective play conveys meaning -- the proposed methodology models tactical configurations as compositional semantic structures. Each player is represented as a multidimensional vector integrating technical, physical, and psychological attributes; team profiles are aggregated through contextual weighting into a higher-level semantic representation. Within this shared vector space, tactical templates such as high press, counterattack, or possession build-up are encoded analogously to linguistic concepts. Their alignment with team profiles is evaluated using vector-distance metrics, enabling the computation of tactical ``fit'' and opponent-exploitation potential. A Python-based prototype demonstrates how these methods can generate interpretable, dynamically adaptive strategy recommendations, accompanied by fine-grained diagnostic insights at the attribute level. Beyond football, the approach offers a generalizable framework for collective decision-making and performance optimization in team-based domains -- ranging from basketball and hockey to cooperative robotics and human-AI coordination systems. The paper concludes by outlining future directions toward real-world data integration, predictive simulation, and hybrid human-machine tactical intelligence.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.00389", "categories": ["cs.CR", "cs.LG", "cs.NI"], "pdf": "https://arxiv.org/pdf/2601.00389", "abs": "https://arxiv.org/abs/2601.00389", "authors": ["Muhammad Bilal", "Omer Tariq", "Hasan Ahmed"], "title": "NOS-Gate: Queue-Aware Streaming IDS for Consumer Gateways under Timing-Controlled Evasion", "comment": "9 pages, 3 figures, 4 tables", "summary": "Timing and burst patterns can leak through encryption, and an adaptive adversary can exploit them. This undermines metadata-only detection in a stand-alone consumer gateway. Therefore, consumer gateways need streaming intrusion detection on encrypted traffic using metadata only, under tight CPU and latency budgets. We present a streaming IDS for stand-alone gateways that instantiates a lightweight two-state unit derived from Network-Optimised Spiking (NOS) dynamics per flow, named NOS-Gate. NOS-Gate scores fixed-length windows of metadata features and, under a $K$-of-$M$ persistence rule, triggers a reversible mitigation that temporarily reduces the flow's weight under weighted fair queueing (WFQ). We evaluate NOS-Gate under timing-controlled evasion using an executable 'worlds' benchmark that specifies benign device processes, auditable attacker budgets, contention structure, and packet-level WFQ replay to quantify queue impact. All methods are calibrated label-free via burn-in quantile thresholding. Across multiple reproducible worlds and malicious episodes, at an achieved $0.1%$ false-positive operating point, NOS-Gate attains 0.952 incident recall versus 0.857 for the best baseline in these runs. Under gating, it reduces p99.9 queueing delay and p99.9 collateral delay with a mean scoring cost of ~ 2.09 \u03bcs per flow-window on CPU.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.00475", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.00475", "abs": "https://arxiv.org/abs/2601.00475", "authors": ["Sankar B", "Srinidhi Ranjini Girish", "Aadya Bharti", "Dibakar Sen"], "title": "Progressive Ideation using an Agentic AI Framework for Human-AI Co-Creation", "comment": "21 pages, 11 figures", "summary": "The generation of truly novel and diverse ideas is important for contemporary engineering design, yet it remains a significant cognitive challenge for novice designers. Current 'single-spurt' AI systems exacerbate this challenge by producing a high volume of semantically clustered ideas. We propose MIDAS (Meta-cognitive Ideation through Distributed Agentic AI System), a novel framework that replaces the single-AI paradigm with a distributed 'team' of specialized AI agents designed to emulate the human meta-cognitive ideation workflow. This agentic system progressively refines ideas and assesses each one for both global novelty (against existing solutions) and local novelty (against previously generated ideas). MIDAS, therefore, demonstrates a viable and progressive paradigm for true human-AI co-creation, elevating the human designer from a passive filterer to a participatory, active, collaborative partner.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.00418", "categories": ["cs.CR", "cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.00418", "abs": "https://arxiv.org/abs/2601.00418", "authors": ["Prajwal Panth", "Sahaj Raj Malla"], "title": "Secure, Verifiable, and Scalable Multi-Client Data Sharing via Consensus-Based Privacy-Preserving Data Distribution", "comment": "Preprint. Under review", "summary": "We propose the Consensus-Based Privacy-Preserving Data Distribution (CPPDD) framework, a lightweight and post-setup autonomous protocol for secure multi-client data aggregation. The framework enforces unanimous-release confidentiality through a dual-layer protection mechanism that combines per-client affine masking with priority-driven sequential consensus locking. Decentralized integrity is verified via step (sigma_S) and data (sigma_D) checksums, facilitating autonomous malicious deviation detection and atomic abort without requiring persistent coordination. The design supports scalar, vector, and matrix payloads with O(N*D) computation and communication complexity, optional edge-server offloading, and resistance to collusion under N-1 corruptions. Formal analysis proves correctness, Consensus-Dependent Integrity and Fairness (CDIF) with overwhelming-probability abort on deviation, and IND-CPA security assuming a pseudorandom function family. Empirical evaluations on MNIST-derived vectors demonstrate linear scalability up to N = 500 with sub-millisecond per-client computation times. The framework achieves 100% malicious deviation detection, exact data recovery, and three-to-four orders of magnitude lower FLOPs compared to MPC and HE baselines. CPPDD enables atomic collaboration in secure voting, consortium federated learning, blockchain escrows, and geo-information capacity building, addressing critical gaps in scalability, trust minimization, and verifiable multi-party computation for regulated and resource-constrained environments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u4e14\u65e0\u6301\u7eed\u534f\u8c03\u7684\u81ea\u7ba1\u7406\u534f\u8baeCPPDD\uff0c\u7528\u4e8e\u5b89\u5168\u7684\u591a\u65b9\u6570\u636e\u805a\u5408\uff0c\u652f\u6301\u591a\u79cd\u6570\u636e\u7c7b\u578b\uff0c\u5177\u6709\u9ad8\u6548\u7684\u8ba1\u7b97\u548c\u901a\u4fe1\u590d\u6742\u5ea6\uff0c\u80fd\u591f\u68c0\u6d4b\u6076\u610f\u884c\u4e3a\u5e76\u6b63\u786e\u6062\u590d\u6570\u636e\u3002", "motivation": "\u5f53\u524d\u591a\u65b9\u5b89\u5168\u8ba1\u7b97\u548c\u540c\u6001\u52a0\u5bc6\u7b49\u6280\u672f\u5728\u89c4\u6a21\u5316\u5e94\u7528\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u5982\u7f3a\u4e4f\u8f7b\u91cf\u9ad8\u6548\u7684\u7ec4\u4ef6\uff0c\u96be\u4ee5\u5728\u4e0d\u4fe1\u4efb\u7b2c\u4e09\u65b9\u7684\u73af\u5883\u4e2d\u5b9e\u73b0\u591a\u65b9\u5b89\u5168\u534f\u4f5c\u3002", "method": "\u901a\u8fc7\u5f15\u5165\u4e00\u79cd\u53cc\u91cd\u4fdd\u62a4\u673a\u5236\u2014\u2014\u5ba2\u6237\u7aef\u7279\u5b9a\u7684\u4eff\u5c04\u906e\u63a9\u4e0e\u4f18\u5148\u7ea7\u9a71\u52a8\u7684\u987a\u5e8f\u5171\u8bc6\u9501\u5b9a\uff0c\u7ed3\u5408\u68c0\u67e5\u548c\uff08sigma_S\uff09\u4e0e\u6570\u636e\uff08sigma_D\uff09\u6821\u9a8c\u548c\uff0c\u6765\u5b9e\u73b0\u5171\u8bc6\u4f9d\u8d56\u7684\u5b8c\u6574\u6027\u4e0e\u516c\u5e73\u6027\uff0c\u786e\u4fdd\u5728N-1\u7be1\u6539\u4e0b\u7684\u5b89\u5168\u3002", "result": "\u8be5\u6846\u67b6\u5728MNIST\u6570\u636e\u4e0a\u7684\u5b9e\u9a8c\u8bc1\u660e\u4e86\u5728\u5ba2\u6237\u7aef\u53ef\u4ee5\u5b9e\u73b0\u6beb\u79d2\u7ea7\u7684\u8ba1\u7b97\u65f6\u95f4\uff0c\u5e76\u5177\u6709\u7ebf\u6027\u53ef\u6269\u5c55\u6027\u3002\u76f8\u6bd4MPC\u548cHE\u7b49\u57fa\u7ebf\u6280\u672f\uff0c\u8be5\u6846\u67b6\u5728FLOPs\u4e0a\u4f4e\u4e863-4\u4e2a\u6570\u91cf\u7ea7\uff0c\u80fd\u6709\u6548\u68c0\u6d4b\u6076\u610f\u884c\u5f84\u5e76\u6062\u590d\u6240\u6709\u6570\u636e\u3002", "conclusion": "CPPDD\u4e3a\u5b89\u5168\u591a\u65b9\u8ba1\u7b97\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u9002\u7528\u4e8e\u76d1\u7ba1\u4e25\u683c\u548c\u8d44\u6e90\u6709\u9650\u7684\u73af\u5883\u4e0b\u7684\u539f\u5b50\u5408\u4f5c\uff0c\u5982\u5b89\u5168\u6295\u7968\uff0c\u8054\u76df\u8054\u90a6\u5b66\u4e60\uff0c\u533a\u5757\u94fe\u6258\u7ba1\uff0c\u5730\u7406\u4fe1\u606f\u80fd\u529b\u63d0\u5347\u7b49\u9886\u57df\uff0c\u586b\u8865\u4e86\u4e0a\u8ff0\u6280\u672f\u5728\u53ef\u4f38\u7f29\u6027\uff0c\u6700\u5c0f\u4fe1\u4efb\u548c\u591a\u65b9\u8ba1\u7b97\u9a8c\u8bc1\u7b49\u65b9\u9762\u7684\u5173\u952e\u7a7a\u767d\u3002"}}
{"id": "2601.00514", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.00514", "abs": "https://arxiv.org/abs/2601.00514", "authors": ["Liv G. d'Aliberti", "Manoel Horta Ribeiro"], "title": "The Illusion of Insight in Reasoning Models", "comment": null, "summary": "Do reasoning models have \"Aha!\" moments? Prior work suggests that models like DeepSeek-R1-Zero undergo sudden mid-trace realizations that lead to accurate outputs, implying an intrinsic capacity for self-correction. Yet, it remains unclear whether such intrinsic shifts in reasoning strategy actually improve performance. Here, we study mid-reasoning shifts and instrument training runs to detect them. Our analysis spans 1M+ reasoning traces, hundreds of training checkpoints, three reasoning domains, and multiple decoding temperatures and model architectures. We find that reasoning shifts are rare, do not become more frequent with training, and seldom improve accuracy, indicating that they do not correspond to prior perceptions of model insight. However, their effect varies with model uncertainty. Building on this finding, we show that artificially triggering extrinsic shifts under high entropy reliably improves accuracy. Our results show that mid-reasoning shifts are symptoms of unstable inference behavior rather than an intrinsic mechanism for self-correction.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u63a8\u7406\u4e2d\u7684\u7a81\u53d8\u5e76\u4e0d\u9891\u7e41\uff0c\u4e14\u901a\u5e38\u4e0d\u4f1a\u63d0\u5347\u51c6\u786e\u6027\uff0c\u8868\u660e\u5b83\u4eec\u5e76\u975e\u81ea\u6211\u7ea0\u6b63\u7684\u5185\u5728\u673a\u5236\u3002\u901a\u8fc7\u5f15\u53d1\u9ad8\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u5916\u90e8\u7a81\u53d8\uff0c\u53ef\u4ee5\u63d0\u5347\u51c6\u786e\u6027\u3002", "motivation": "\u63a2\u8ba8\u63a8\u7406\u6a21\u578b\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u662f\u5426\u4f1a\u51fa\u73b0\u201c\u604d\u7136\u5927\u609f\u201d\u7684\u65f6\u523b\uff0c\u53ca\u5176\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "method": "\u5206\u6790\u8d85\u8fc7100\u4e07\u6761\u63a8\u7406\u8f68\u8ff9\uff0c\u4ece\u6570\u767e\u4e2a\u8bad\u7ec3\u68c0\u67e5\u70b9\u7684\u4e0d\u540c\u63a8\u7406\u9886\u57df\u5165\u624b\uff0c\u7814\u7a76\u63a8\u7406\u4e2d\u7684\u7a81\u53d8\uff0c\u5e76\u901a\u8fc7\u89e6\u53d1\u9ad8\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u5916\u90e8\u7a81\u53d8\u6765\u89c2\u5bdf\u5176\u6548\u679c\u3002", "result": "\u63a8\u7406\u7a81\u53d8\u7684\u53d1\u751f\u7387\u4f4e\uff0c\u4e0d\u4f1a\u56e0\u8bad\u7ec3\u800c\u589e\u52a0\uff0c\u4e14\u5728\u591a\u6570\u60c5\u51b5\u4e0b\u4e0d\u63d0\u9ad8\u51c6\u786e\u6027\u3002\u9ad8\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u5916\u90e8\u7a81\u53d8\u80fd\u591f\u63d0\u5347\u51c6\u786e\u6027\u3002", "conclusion": "\u63a8\u7406\u4e2d\u7684\u7a81\u53d8\u662f\u4e0d\u7a33\u5b9a\u63a8\u7406\u884c\u4e3a\u7684\u75c7\u72b6\uff0c\u800c\u975e\u81ea\u6211\u7ea0\u6b63\u7684\u5185\u5728\u673a\u5236\u3002"}}
{"id": "2601.00623", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.00623", "abs": "https://arxiv.org/abs/2601.00623", "authors": ["Longtian Qiu", "Shan Ning", "Chuyu Zhang", "Jiaxuan Sun", "Xuming He"], "title": "DA-DPO: Cost-efficient Difficulty-aware Preference Optimization for Reducing MLLM Hallucinations", "comment": "Accepted by TMLR", "summary": "Direct Preference Optimization (DPO) has shown strong potential for mitigating hallucinations in Multimodal Large Language Models (MLLMs). However, existing multimodal DPO approaches often suffer from overfitting due to the difficulty imbalance in preference data. Our analysis shows that MLLMs tend to overemphasize easily distinguishable preference pairs, which hinders fine-grained hallucination suppression and degrades overall performance. To address this issue, we propose Difficulty-Aware Direct Preference Optimization (DA-DPO), a cost-effective framework designed to balance the learning process. DA-DPO consists of two main components: (1) Difficulty Estimation leverages pre-trained vision--language models with complementary generative and contrastive objectives, whose outputs are integrated via a distribution-aware voting strategy to produce robust difficulty scores without additional training; and (2) Difficulty-Aware Training reweights preference pairs based on their estimated difficulty, down-weighting easy samples while emphasizing harder ones to alleviate overfitting. This framework enables more effective preference optimization by prioritizing challenging examples, without requiring new data or extra fine-tuning stages. Extensive experiments demonstrate that DA-DPO consistently improves multimodal preference optimization, yielding stronger robustness to hallucinations and better generalization across standard benchmarks, while remaining computationally efficient. The project page is available at https://artanic30.github.io/project_pages/DA-DPO/.", "AI": {"tldr": "DA-DPO \u63d0\u51fa\u4e86\u4e00\u79cd\u6210\u672c\u6548\u76ca\u9ad8\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u96be\u5ea6\u4f30\u8ba1\u548c\u96be\u5ea6\u611f\u77e5\u8bad\u7ec3\u5e73\u8861\u5b66\u4e60\u8fc7\u7a0b\uff0c\u63d0\u9ad8\u591a\u6a21\u6001\u504f\u597d\u4f18\u5316\u7684\u6548\u679c\uff0c\u589e\u5f3a\u9c81\u68d2\u6027\u5e76\u63d0\u5347\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u5927\u89c4\u6a21\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u504f\u597d\u4f18\u5316\u65b9\u6cd5\u5bb9\u6613\u56e0\u504f\u597d\u6570\u636e\u4e0d\u5e73\u8861\u800c\u5bfc\u81f4\u8fc7\u62df\u5408\uff0c\u65e0\u6cd5\u6709\u6548\u5730\u6291\u5236\u7ec6\u7c92\u5ea6\u5e7b\u89c9\u3002", "method": "DA-DPO \u901a\u8fc7\u96be\u5ea6\u4f30\u8ba1\u6a21\u5757\u5229\u7528\u9884\u8bad\u7ec3\u7684\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u96be\u5ea6\u8bc4\u5206\uff0c\u5e76\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u6839\u636e\u96be\u5ea6\u91cd\u6743\u5904\u7406\u504f\u597d\u6837\u672c\uff0c\u4f18\u5148\u5904\u7406\u96be\u5ea6\u9ad8\u7684\u6837\u672c\uff0c\u4ece\u800c\u66f4\u52a0\u6709\u6548\u7684\u8fdb\u884c\u504f\u597d\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cDA-DPO \u80fd\u591f\u63d0\u9ad8\u591a\u6a21\u6001\u504f\u597d\u4f18\u5316\u7684\u6548\u679c\uff0c\u589e\u5f3a\u5bf9\u6297\u5e7b\u89c9\u7684\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "DA-DPO \u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u591a\u6a21\u6001\u504f\u597d\u4f18\u5316\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u5e76\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5c55\u793a\u4e86\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2601.00509", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.00509", "abs": "https://arxiv.org/abs/2601.00509", "authors": ["Vidyut Sriram", "Sawan Pandita", "Achintya Lakshmanan", "Aneesh Shamraj", "Suman Saha"], "title": "Improving LLM-Assisted Secure Code Generation through Retrieval-Augmented-Generation and Multi-Tool Feedback", "comment": null, "summary": "Large Language Models (LLMs) can generate code but often introduce security vulnerabilities, logical inconsistencies, and compilation errors. Prior work demonstrates that LLMs benefit substantially from structured feedback, static analysis, retrieval augmentation, and execution-based refinement. We propose a retrieval-augmented, multi-tool repair workflow in which a single code-generating LLM iteratively refines its outputs using compiler diagnostics, CodeQL security scanning, and KLEE symbolic execution. A lightweight embedding model is used for semantic retrieval of previously successful repairs, providing security-focused examples that guide generation. Evaluated on a combined dataset of 3,242 programs generated by DeepSeek-Coder-1.3B and CodeLlama-7B, the system demonstrates significant improvements in robustness. For DeepSeek, security vulnerabilities were reduced by 96%. For the larger CodeLlama model, the critical security defect rate was decreased from 58.55% to 22.19%, highlighting the efficacy of tool-assisted self-repair even on \"stubborn\" models.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528\u68c0\u7d22\u589e\u5f3a\u7684\u591a\u5de5\u5177\u4fee\u590d\u5de5\u4f5c\u6d41\uff0c\u901a\u8fc7\u7f16\u8bd1\u5668\u8bca\u65ad\u3001CodeQL\u5b89\u5168\u626b\u63cf\u548cKLEE\u7b26\u53f7\u6267\u884c\u8fed\u4ee3\u4fee\u590d\u4ee3\u7801\u751f\u6210LLMs\u7684\u8f93\u51fa\u3002\u7cfb\u7edf\u57283,242\u4e2a\u7a0b\u5e8f\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5b89\u5168\u6027\uff0c\u7279\u522b\u662f\u5728CodeLlama\u6a21\u578b\u4e2d\u8868\u73b0\u7a81\u51fa\u3002", "motivation": "\u5f53\u524d\u7684LLMs\u5728\u751f\u6210\u4ee3\u7801\u65b9\u9762\u5b58\u5728\u5b89\u5168\u6f0f\u6d1e\u3001\u903b\u8f91\u4e0d\u4e00\u81f4\u548c\u7f16\u8bd1\u9519\u8bef\u7684\u95ee\u9898\uff0c\u7814\u7a76\u4eba\u5458\u63d0\u51fa\u8be5\u65b9\u6cd5\u65e8\u5728\u63d0\u9ad8\u4ee3\u7801\u751f\u6210\u7684\u9c81\u68d2\u6027\uff0c\u7279\u522b\u662f\u589e\u5f3a\u5b89\u5168\u6027\u3002", "method": "\u7814\u7a76\u91c7\u7528\u4e86\u68c0\u7d22\u589e\u5f3a\u3001\u591a\u5de5\u5177\u4fee\u590d\u7684\u5de5\u4f5c\u6d41\u3002\u5177\u4f53\u6b65\u9aa4\u5305\u62ec\u5229\u7528\u7f16\u8bd1\u5668\u8bca\u65ad\u53d1\u73b0\u9519\u8bef\u3001\u4f7f\u7528CodeQL\u8fdb\u884c\u5b89\u5168\u626b\u63cf\u8bc6\u522b\u6f5c\u5728\u6f0f\u6d1e\u3001\u4ee5\u53ca\u901a\u8fc7KLEE\u8fdb\u884c\u7b26\u53f7\u6267\u884c\u4ee5\u4fdd\u8bc1\u903b\u8f91\u6b63\u786e\u6027\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u5d4c\u5165\u5f0f\u6a21\u578b\u68c0\u7d22\u5386\u53f2\u6210\u529f\u7684\u4fee\u590d\u65b9\u6cd5\uff0c\u63d0\u4f9b\u5b89\u5168\u5bfc\u5411\u793a\u4f8b\u6765\u6307\u5bfc\u4ee3\u7801\u751f\u6210\u3002", "result": "\u8be5\u7cfb\u7edf\u5728DeepSeek\u548cCodeLlama\u4e24\u4e2a\u6a21\u578b\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793a\u5b89\u5168\u6f0f\u6d1e\u663e\u8457\u51cf\u5c11\u3002\u5bf9\u4e8eDeepSeek\uff0c\u5b89\u5168\u6f0f\u6d1e\u51cf\u5c11\u4e8696%\uff1b\u5bf9\u4e8eCodeLlama\uff0c\u5173\u952e\u5b89\u5168\u7f3a\u9677\u7387\u4ece58.55%\u964d\u81f322.19%\uff0c\u663e\u793a\u51fa\u5373\u4f7f\u5728\u201c\u987d\u56fa\u201d\u6a21\u578b\u4e0a\u4e5f\u5177\u6709\u5de5\u5177\u8f85\u52a9\u81ea\u6211\u4fee\u590d\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63d0\u51fa\u7684\u65b9\u6cd5\u663e\u793a\u4e86\u901a\u8fc7\u4e00\u7cfb\u5217\u81ea\u52a8\u5de5\u5177\u4fee\u590dLLMs\u751f\u6210\u4ee3\u7801\u7684\u6709\u6548\u6027\uff0c\u7279\u522b\u662f\u5728\u63d0\u9ad8\u5b89\u5168\u6027\u65b9\u9762\u8868\u73b0\u51fa\u663e\u8457\u6539\u8fdb\uff0c\u8bc1\u660e\u4e86\u5de5\u5177\u8f85\u52a9\u81ea\u6211\u4fee\u590d\u5728\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u4ee3\u7801\u7684\u53ef\u9760\u6027\u4e0a\u7684\u6f5c\u529b\u3002"}}
{"id": "2601.00694", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.00694", "abs": "https://arxiv.org/abs/2601.00694", "authors": ["Qingwen Pu", "Kun Xie", "Hong Yang", "Guocong Zhai"], "title": "A Vision-and-Knowledge Enhanced Large Language Model for Generalizable Pedestrian Crossing Behavior Inference", "comment": null, "summary": "Existing paradigms for inferring pedestrian crossing behavior, ranging from statistical models to supervised learning methods, demonstrate limited generalizability and perform inadequately on new sites. Recent advances in Large Language Models (LLMs) offer a shift from numerical pattern fitting to semantic, context-aware behavioral reasoning, yet existing LLM applications lack domain-specific adaptation and visual context. This study introduces Pedestrian Crossing LLM (PedX-LLM), a vision-and-knowledge enhanced framework designed to transform pedestrian crossing inference from site-specific pattern recognition to generalizable behavioral reasoning. By integrating LLaVA-extracted visual features with textual data and transportation domain knowledge, PedX-LLM fine-tunes a LLaMA-2-7B foundation model via Low-Rank Adaptation (LoRA) to infer crossing decisions. PedX-LLM achieves 82.0% balanced accuracy, outperforming the best statistical and supervised learning methods. Results demonstrate that the vision-augmented module contributes a 2.9% performance gain by capturing the built environment and integrating domain knowledge yields an additional 4.1% improvement. To evaluate generalizability across unseen environments, cross-site validation was conducted using site-based partitioning. The zero-shot PedX-LLM configuration achieves 66.9% balanced accuracy on five unseen test sites, outperforming the baseline data-driven methods by at least 18 percentage points. Incorporating just five validation examples via few-shot learning to PedX-LLM further elevates the balanced accuracy to 72.2%. PedX-LLM demonstrates strong generalizability to unseen scenarios, confirming that vision-and-knowledge-enhanced reasoning enables the model to mimic human-like decision logic and overcome the limitations of purely data-driven methods.", "AI": {"tldr": "PedX-LLM \u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u89c6\u89c9\u7279\u5f81\u548c\u9886\u57df\u77e5\u8bc6\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u4f4e\u79e9\u9002\u5e94\u5fae\u8c03 LLaMA-2-7B \u57fa\u7840\u6a21\u578b\uff0c\u5b9e\u73b0\u4e8682.0%\u7684\u5e73\u8861\u51c6\u786e\u7387\uff0c\u4f18\u4e8e\u73b0\u6709\u7edf\u8ba1\u548c\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\uff0c\u5e76\u5c55\u793a\u4e86\u5728\u672a\u89c1\u8fc7\u7684\u73af\u5883\u4e2d\u7684\u5f3a\u5927\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u76ee\u524d\u7684\u884c\u4eba\u8fc7\u8857\u884c\u4e3a\u63a8\u65ad\u65b9\u6cd5\uff0c\u5982\u7edf\u8ba1\u6a21\u578b\u548c\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\uff0c\u8868\u73b0\u51fa\u6709\u9650\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5c24\u5176\u662f\u5728\u65b0\u5730\u70b9\u4e0a\u6027\u80fd\u4e0d\u4f73\u3002\u8bed\u8a00\u6a21\u578b\u7684\u8fdb\u6b65\u63d0\u4f9b\u4e86\u4ece\u6570\u503c\u6a21\u5f0f\u62df\u5408\u5230\u8bed\u4e49\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u884c\u4e3a\u63a8\u7406\u7684\u8f6c\u53d8\uff0c\u4f46\u73b0\u6709\u7684\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u7f3a\u4e4f\u9886\u57df\u7279\u5b9a\u9002\u5e94\u548c\u89c6\u89c9\u4e0a\u4e0b\u6587\u3002", "method": "PedX-LLM \u901a\u8fc7\u7ed3\u5408 LLaVA \u63d0\u53d6\u7684\u89c6\u89c9\u7279\u5f81\u3001\u6587\u672c\u6570\u636e\u548c\u4ea4\u901a\u9886\u57df\u7684\u77e5\u8bc6\uff0cfine-tune LLaMA-2-7B \u57fa\u7840\u6a21\u578b\u901a\u8fc7\u4f4e\u79e9\u9002\u5e94\uff08LoRA\uff09\u6765\u63a8\u65ad\u8fc7\u8857\u51b3\u5b9a\u3002\u4e00\u4e2a\u96f6\u6837\u672c\u914d\u7f6e\u5728\u4e94\u4e2a\u672a\u89c1\u8fc7\u7684\u6d4b\u8bd5\u7ad9\u70b9\u4e0a\u5b9e\u73b0\u4e8666.9%\u7684\u5e73\u8861\u51c6\u786e\u7387\uff0c\u901a\u8fc7\u5c11\u91cf\u6837\u672c\u5b66\u4e60\u8fdb\u4e00\u6b65\u63d0\u9ad8\u523072.2%\u3002", "result": "PedX-LLM \u8fbe\u523082.0%\u7684\u5e73\u8861\u51c6\u786e\u7387\uff0c\u4f18\u4e8e\u6700\u4f73\u7edf\u8ba1\u548c\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u3002\u521d\u6b65\u9a8c\u8bc1\u8868\u660e\uff0c\u89c6\u89c9\u589e\u5f3a\u6a21\u5757\u589e\u52a0\u4e862.9%\u7684\u6027\u80fd\uff0c\u901a\u8fc7\u96c6\u6210\u9886\u57df\u77e5\u8bc6\uff0c\u989d\u5916\u63d0\u5347\u4e864.1%\u3002\u96f6\u6837\u672c\u8bbe\u7f6e\u5728\u4e94\u4e2a\u672a\u89c1\u8fc7\u7684\u6d4b\u8bd5\u7ad9\u70b9\u4e0a\u7684\u51c6\u786e\u7387\u4e3a66.9%\uff0c\u4f18\u4e8e\u57fa\u7ebf\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u81f3\u5c1118\u4e2a\u767e\u5206\u70b9\u3002\u901a\u8fc7\u5c11\u91cf\u6837\u672c\u5b66\u4e60\u8fdb\u4e00\u6b65\u63d0\u5347\u523072.2%\u3002", "conclusion": "PedX-LLM \u8bc1\u5b9e\u4e86\u89c6\u89c9\u548c\u77e5\u8bc6\u589e\u5f3a\u7684\u63a8\u7406\u53ef\u4f7f\u6a21\u578b\u6a21\u4eff\u4eba\u7c7b\u7684\u51b3\u7b56\u903b\u8f91\uff0c\u4ece\u800c\u8d85\u8d8a\u7eaf\u7cb9\u6570\u636e\u9a71\u52a8\u7684\u65b9\u6cd5\u3002"}}
{"id": "2601.00559", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.00559", "abs": "https://arxiv.org/abs/2601.00559", "authors": ["Jason Quantrill", "Noura Khajehnouri", "Zihan Guo", "Manar H. Alalfi"], "title": "Cracking IoT Security: Can LLMs Outsmart Static Analysis Tools?", "comment": null, "summary": "Smart home IoT platforms such as openHAB rely on Trigger Action Condition (TAC) rules to automate device behavior, but the interplay among these rules can give rise to interaction threats, unintended or unsafe behaviors emerging from implicit dependencies, conflicting triggers, or overlapping conditions. Identifying these threats requires semantic understanding and structural reasoning that traditionally depend on symbolic, constraint-driven static analysis. This work presents the first comprehensive evaluation of Large Language Models (LLMs) across a multi-category interaction threat taxonomy, assessing their performance on both the original openHAB (oHC/IoTB) dataset and a structurally challenging Mutation dataset designed to test robustness under rule transformations. We benchmark Llama 3.1 8B, Llama 70B, GPT-4o, Gemini-2.5-Pro, and DeepSeek-R1 across zero-, one-, and two-shot settings, comparing their results against oHIT's manually validated ground truth. Our findings show that while LLMs exhibit promising semantic understanding, particularly on action- and condition-related threats, their accuracy degrades significantly for threats requiring cross-rule structural reasoning, especially under mutated rule forms. Model performance varies widely across threat categories and prompt settings, with no model providing consistent reliability. In contrast, the symbolic reasoning baseline maintains stable detection across both datasets, unaffected by rule rewrites or structural perturbations. These results underscore that LLMs alone are not yet dependable for safety critical interaction-threat detection in IoT environments. We discuss the implications for tool design and highlight the potential of hybrid architectures that combine symbolic analysis with LLM-based semantic interpretation to reduce false positives while maintaining structural rigor.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u667a\u80fd\u5bb6\u5eadIoT\u5e73\u53f0\u7684\u4ea4\u4e92\u5a01\u80c1\u68c0\u6d4b\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u867d\u7136LLMs\u5728\u7406\u89e3\u548c\u5904\u7406\u4e0e\u76f4\u6d47\u884c\u4e3a\u548c\u6761\u4ef6\u76f8\u5173\u7684\u95ee\u9898\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u9700\u8981\u8de8\u89c4\u5219\u7ed3\u6784\u63a8\u7406\u7684\u95ee\u9898\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u7279\u522b\u662f\u7ecf\u8fc7\u53d8\u5f02\u89c4\u5219\u5f62\u5f0f\u7684\u6d4b\u8bd5\uff0c\u5176\u51c6\u786e\u6027\u663e\u8457\u4e0b\u964d\u3002", "motivation": "\u9274\u4e8e\u667a\u80fd\u5bb6\u5eadIoT\u5e73\u53f0\u4f9d\u8d56\u4e8e\u89e6\u53d1\u884c\u4e3a\u6761\u4ef6\uff08TAC\uff09\u89c4\u5219\u6765\u81ea\u52a8\u5316\u8bbe\u5907\u884c\u4e3a\uff0c\u53ef\u80fd\u5b58\u5728\u4ea4\u4e92\u5a01\u80c1\u548c\u65e0\u610f\u7684\u5b89\u5168\u98ce\u9669\u3002\u672c\u6587\u65e8\u5728\u8bc4\u4f30LLMs\u5728\u667a\u80fd\u5bb6\u5ead\u573a\u666f\u4e2d\u7684\u9002\u7528\u6027\uff0c\u4ee5\u63d0\u9ad8IoT\u8bbe\u5907\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u3002", "method": "\u7814\u7a76\u56e2\u961f\u4f7f\u7528\u591a\u79cdLLM\u6a21\u578b\u5bf9\u539f\u59cbopenHAB\u6570\u636e\u96c6\u548c\u7ed3\u6784\u6311\u6218\u6d4b\u8bd5\u6570\u636e\u96c6\u8fdb\u884c\u4e86\u5168\u9762\u8bc4\u4f30\uff0c\u901a\u8fc7\u96f6\u3001\u4e00\u3001\u4e24\u8f6e\u8bbe\u7f6e\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4e0e\u624b\u52a8\u9a8c\u8bc1\u7684\u57fa\u51c6\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5c3d\u7ba1LLMs\u5728\u7406\u89e3\u548c\u5904\u7406\u4e0e\u884c\u52a8\u548c\u6761\u4ef6\u76f8\u5173\u7684\u95ee\u9898\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u9700\u8981\u8de8\u89c4\u5219\u7ed3\u6784\u63a8\u7406\u7684\u95ee\u9898\u4e0a\u8868\u73b0\u8f83\u5dee\uff0c\u7279\u522b\u662f\u7ecf\u8fc7\u53d8\u5f02\u89c4\u5219\u5f62\u5f0f\u7684\u6d4b\u8bd5\uff0c\u6a21\u578b\u51c6\u786e\u6027\u663e\u8457\u4e0b\u964d\u3002\u4e0d\u540c\u6a21\u578b\u5728\u4e0d\u540c\u5a01\u80c1\u7c7b\u522b\u548c\u63d0\u793a\u8bbe\u7f6e\u4e0b\u7684\u6027\u80fd\u5dee\u5f02\u663e\u8457\u3002", "conclusion": "\u7814\u7a76\u6307\u51fa\uff0c\u5355\u72ec\u4f7f\u7528LLMs\u5728IoT\u73af\u5883\u4e2d\u7684\u5b89\u5168\u5173\u952e\u4ea4\u4e92\u5a01\u80c1\u68c0\u6d4b\u5c1a\u4e0d\u53ef\u9760\uff0c\u5efa\u8bae\u7ed3\u5408\u7b26\u53f7\u5206\u6790\u548c\u57fa\u4e8eLLM\u7684\u8bed\u4e49\u89e3\u91ca\u7684\u6df7\u5408\u67b6\u6784\uff0c\u4ee5\u51cf\u5c11\u8bef\u62a5\u5e76\u4fdd\u6301\u7ed3\u6784\u4e25\u8c28\u3002"}}
{"id": "2601.00566", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.00566", "abs": "https://arxiv.org/abs/2601.00566", "authors": ["Yueyan Dong", "Minghui Xu", "Qin Hu", "Yinhao Xiao", "Qi Luo", "Yechao Zhang", "Yue Zhang", "Xiuzhen Cheng"], "title": "Low Rank Comes with Low Security: Gradient Assembly Poisoning Attacks against Distributed LoRA-based LLM Systems", "comment": "8 figures, 8 tables", "summary": "Low-Rank Adaptation (LoRA) has become a popular solution for fine-tuning large language models (LLMs) in federated settings, dramatically reducing update costs by introducing trainable low-rank matrices. However, when integrated with frameworks like FedIT, LoRA introduces a critical vulnerability: clients submit $A$ and $B$ matrices separately, while only their product $AB$ determines the model update, yet this composite is never directly verified. We propose Gradient Assembly Poisoning (GAP), a novel attack that exploits this blind spot by crafting individually benign $A$ and $B$ matrices whose product yields malicious updates. GAP operates without access to training data or inter-client coordination and remains undetected by standard anomaly detectors. We identify four systemic vulnerabilities in LoRA-based federated systems and validate GAP across LLaMA, ChatGLM, and GPT-2. GAP consistently induces degraded or biased outputs while preserving surface fluency, reducing BLEU by up to 14.5\\%, increasing factual and grammatical errors by over 800\\%, and maintaining 92.6\\% long-form response length. These results reveal a new class of stealthy, persistent threats in distributed LoRA fine-tuning.", "AI": {"tldr": "\u6587\u7ae0\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGradient Assembly Poisoning (GAP)\u7684\u65b0\u653b\u51fb\u65b9\u6cd5\uff0c\u9488\u5bf9\u5728\u8054\u90a6\u8bbe\u7f6e\u4e2d\u4f7f\u7528\u7684\u4f4e\u79e9\u9002\u5e94\uff08LoRA\uff09\u6280\u672f\u7684\u6f0f\u6d1e\uff0c\u5bfc\u81f4\u6a21\u578b\u66f4\u65b0\u53d7\u5230\u6076\u610f\u5f71\u54cd\uff0c\u540c\u65f6\u4fdd\u6301\u8868\u9762\u6d41\u7545\u6027\u3002", "motivation": "LoRA\u6280\u672f\u5728\u8054\u90a6\u5b66\u4e60\u73af\u5883\u4e2d\u88ab\u7528\u6765\u51cf\u5c11\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5fae\u8c03\u6210\u672c\uff0c\u4f46\u8fd9\u79cd\u65b9\u5f0f\u5f15\u5165\u4e86\u4e00\u4e2a\u5b89\u5168\u6f0f\u6d1e\uff0c\u5373\u7528\u6237\u4ec5\u63d0\u4ea4\u77e9\u9635A\u548cB\uff0c\u800c\u4ec5\u5176\u4e58\u79efAB\u51b3\u5b9a\u6a21\u578b\u66f4\u65b0\uff0c\u8be5\u8fc7\u7a0b\u672a\u8fdb\u884c\u76f4\u63a5\u9a8c\u8bc1\u3002", "method": "GAP\u653b\u51fb\u65b9\u6cd5\u901a\u8fc7\u5bf9\u975e\u6076\u610f\u7684\u5355\u72ec\u63d0\u4ea4\u77e9\u9635A\u548cB\u8fdb\u884c\u7cbe\u786e\u8bbe\u8ba1\uff0c\u4f7f\u5176\u4e58\u79efAB\u5bfc\u81f4\u6076\u610f\u66f4\u65b0\u3002\u653b\u51fb\u8005\u65e0\u9700\u8bbf\u95ee\u8bad\u7ec3\u6570\u636e\u6216\u8fdb\u884c\u5ba2\u6237\u7aef\u95f4\u534f\u8c03\uff0c\u5e76\u4e14\u80fd\u591f\u8eb2\u907f\u6807\u51c6\u5f02\u5e38\u68c0\u6d4b\u5668\u3002", "result": "\u7ecf\u8fc7GAP\u653b\u51fb\u540e\uff0c\u6a21\u578b\u4ea7\u751f\u4e86\u9000\u5316\u6216\u504f\u5dee\u7684\u7ed3\u679c\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u8868\u9762\u6d41\u7545\u6027\u3002\u7ec6\u7c92\u5ea6\u5bf9\u6bd4\u663e\u793a\uff0cBLEU\u5f97\u5206\u964d\u4f4e\u4e8614.5%\uff0c\u4e8b\u5b9e\u6027\u548c\u8bed\u6cd5\u9519\u8bef\u589e\u52a0\u4e86\u8d85\u8fc7800%\uff0c\u540c\u65f6\u957f\u6587\u672c\u957f\u5ea6\u4fdd\u7559\u572892.6%\u3002", "conclusion": "GAP\u653b\u51fb\u63ed\u793a\u4e86LoRA\u57fa\u4e8e\u7684\u8054\u90a6\u7cfb\u7edf\u7684\u9690\u853d\u4e14\u6301\u4e45\u7684\u65b0\u7c7b\u5a01\u80c1\uff0c\u5f3a\u8c03\u4e86\u5728\u8054\u90a6\u5b66\u4e60\u8bbe\u7f6e\u4e2d\u5f15\u5165\u6b64\u7c7b\u5b89\u5168\u68c0\u67e5\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2601.00627", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.00627", "abs": "https://arxiv.org/abs/2601.00627", "authors": ["Yuelin Wang", "Yuqiao Ning", "Yanbang Sun", "Xiaofei Xie", "Zhihua Xie", "Yang Chen", "Zhen Guo", "Shihao Xue", "Junjie Wang", "Sen Chen"], "title": "Towards Understanding and Characterizing Vulnerabilities in Intelligent Connected Vehicles through Real-World Exploits", "comment": null, "summary": "Intelligent Connected Vehicles (ICVs) are a core component of modern transportation systems, and their security is crucial as it directly relates to user safety. Despite prior research, most existing studies focus only on specific sub-components of ICVs due to their inherent complexity. As a result, there is a lack of systematic understanding of ICV vulnerabilities. Moreover, much of the current literature relies on human subjective analysis, such as surveys and interviews, which tends to be high-level and unvalidated, leaving a significant gap between theoretical findings and real-world attacks. To address this issue, we conducted the first large-scale empirical study on ICV vulnerabilities. We began by analyzing existing ICV security literature and summarizing the prevailing taxonomies in terms of vulnerability locations and types. To evaluate their real-world relevance, we collected a total of 649 exploitable vulnerabilities, including 592 from eight ICV vulnerability discovery competitions, Anonymous Cup, between January 2023 and April 2024, covering 48 different vehicles. The remaining 57 vulnerabilities were submitted daily by researchers. Based on this dataset, we assessed the coverage of existing taxonomies and identified several gaps, discovering one new vulnerability location and 13 new vulnerability types. We further categorized these vulnerabilities into 6 threat types (e.g., privacy data breach) and 4 risk levels (ranging from low to critical) and analyzed participants' skills and the types of ICVs involved in the competitions. This study provides a comprehensive and data-driven analysis of ICV vulnerabilities, offering actionable insights for researchers, industry practitioners, and policymakers. To support future research, we have made our vulnerability dataset publicly available.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2601.00783", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2601.00783", "abs": "https://arxiv.org/abs/2601.00783", "authors": ["John Carter", "Spiros Mancoridis", "Pavlos Protopapas", "Brian Mitchell", "Benji Lilley"], "title": "Improving Router Security using BERT", "comment": null, "summary": "Previous work on home router security has shown that using system calls to train a transformer-based language model built on a BERT-style encoder using contrastive learning is effective in detecting several types of malware, but the performance remains limited at low false positive rates. In this work, we demonstrate that using a high-fidelity eBPF-based system call sensor, together with contrastive augmented learning (which introduces controlled mutations of negative samples), improves detection performance at a low false positive rate. In addition, we introduce a network packet abstraction language that enables the creation of a pipeline similar to network packet data, and we show that network behavior provides complementary detection signals-yielding improved performance for network-focused malware at low false positive rates. Lastly, we implement these methods in an online router anomaly detection framework to validate the approach in an Internet of Things (IoT) deployment environment.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
