{"id": "2602.16012", "categories": ["cs.AI", "cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.16012", "abs": "https://arxiv.org/abs/2602.16012", "authors": ["Jieyi Bi", "Zhiguang Cao", "Jianan Zhou", "Wen Song", "Yaoxin Wu", "Jie Zhang", "Yining Ma", "Cathy Wu"], "title": "Towards Efficient Constraint Handling in Neural Solvers for Routing Problems", "comment": "Accepted by ICLR 2026", "summary": "Neural solvers have achieved impressive progress in addressing simple routing problems, particularly excelling in computational efficiency. However, their advantages under complex constraints remain nascent, for which current constraint-handling schemes via feasibility masking or implicit feasibility awareness can be inefficient or inapplicable for hard constraints. In this paper, we present Construct-and-Refine (CaR), the first general and efficient constraint-handling framework for neural routing solvers based on explicit learning-based feasibility refinement. Unlike prior construction-search hybrids that target reducing optimality gaps through heavy improvements yet still struggle with hard constraints, CaR achieves efficient constraint handling by designing a joint training framework that guides the construction module to generate diverse and high-quality solutions well-suited for a lightweight improvement process, e.g., 10 steps versus 5k steps in prior work. Moreover, CaR presents the first use of construction-improvement-shared representation, enabling potential knowledge sharing across paradigms by unifying the encoder, especially in more complex constrained scenarios. We evaluate CaR on typical hard routing constraints to showcase its broader applicability. Results demonstrate that CaR achieves superior feasibility, solution quality, and efficiency compared to both classical and neural state-of-the-art solvers.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u540d\u4e3aConstruct-and-Refine\uff08CaR\uff09\u7684\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u662f\u4e00\u4e2a\u57fa\u4e8e\u663e\u5f0f\u5b66\u4e60\u53ef\u6ee1\u8db3\u6027\u7ec6\u5316\u7684\u901a\u7528\u4e14\u9ad8\u6548\u7684\u7ea6\u675f\u5904\u7406\u65b9\u6848\uff0c\u7279\u522b\u9002\u7528\u4e8e\u795e\u7ecf\u8def\u7531\u6c42\u89e3\u5668\u5728\u9762\u5bf9\u590d\u6742\u7ea6\u675f\u65f6\u7684\u6709\u6548\u6027\uff0c\u76f8\u8f83\u4e8e\u5148\u524d\u65b9\u6cd5\uff0c\u5728\u5904\u7406\u786c\u7ea6\u675f\u65f6\u5177\u6709\u66f4\u9ad8\u7684\u53ef\u884c\u6027\u548c\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\uff0c\u4e14\u8ba1\u7b97\u6548\u7387\u66f4\u9ad8\u3002", "motivation": "\u9488\u5bf9\u795e\u7ecf\u6c42\u89e3\u5668\u5728\u5904\u7406\u590d\u6742\u7ea6\u675f\u65f6\u8868\u73b0\u4e0d\u4f73\u7684\u95ee\u9898\uff0c\u4ee5\u53ca\u73b0\u6709\u5904\u7406\u7ea6\u675f\u7684\u65b9\u6cd5\u6548\u7387\u4f4e\u4e0b\u6216\u4e0d\u9002\u7528\u4e8e\u786c\u7ea6\u675f\u7684\u60c5\u51b5\uff0c\u63d0\u51fa\u8be5\u6846\u67b6\u65e8\u5728\u63d0\u9ad8\u5728\u590d\u6742\u7ea6\u675f\u4e0b\u7684\u6027\u80fd\u3002", "method": "\u6846\u67b6\u901a\u8fc7\u8bbe\u8ba1\u4e00\u4e2a\u8054\u5408\u8bad\u7ec3\u6846\u67b6\uff0c\u6307\u5bfc\u6784\u9020\u6a21\u5757\u751f\u6210\u591a\u6837\u4e14\u9ad8\u8d28\u91cf\u7684\u89e3\u51b3\u65b9\u6848\u4ee5\u9002\u7528\u4e8e\u8f7b\u91cf\u7ea7\u6539\u8fdb\u8fc7\u7a0b\u3002\u540c\u65f6\uff0c\u63d0\u51fa\u7684\u6784\u9020-\u6539\u8fdb\u5171\u4eab\u8868\u793a\u6cd5\u53ef\u4ee5\u5728\u66f4\u590d\u6742\u7684\u7ea6\u675f\u573a\u666f\u4e2d\u6f5c\u5728\u5730\u5171\u4eab\u77e5\u8bc6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cCaR\u5728\u5178\u578b\u786c\u8def\u7531\u7ea6\u675f\u4e0b\u83b7\u5f97\u4e86\u6bd4\u4f20\u7edf\u548c\u795e\u7ecf\u72b6\u6001\u6700\u5148\u8fdb\u6c42\u89e3\u5668\u66f4\u597d\u7684\u53ef\u884c\u6027\u548c\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\uff0c\u5e76\u4e14\u5177\u6709\u66f4\u9ad8\u7684\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u795e\u7ecf\u8def\u7531\u6c42\u89e3\u5668\u5904\u7406\u590d\u6742\u7ea6\u675f\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u4e14\u901a\u7528\u7684\u65b9\u6cd5\uff0c\u5177\u6709\u5e7f\u9614\u7684\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2602.16156", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.16156", "abs": "https://arxiv.org/abs/2602.16156", "authors": ["Rohit Chatterjee", "Yunqi Li", "Prashant Nalini Vasudevan"], "title": "Weak Zero-Knowledge and One-Way Functions", "comment": null, "summary": "We study the implications of the existence of weak Zero-Knowledge (ZK) protocols for worst-case hard languages. These are protocols that have completeness, soundness, and zero-knowledge errors (denoted $\u03b5_c$, $\u03b5_s$, and $\u03b5_z$, respectively) that might not be negligible. Under the assumption that there are worst-case hard languages in NP, we show the following:\n  1. If all languages in NP have NIZK proofs or arguments satisfying $ \u03b5_c+\u03b5_s+ \u03b5_z < 1 $, then One-Way Functions (OWFs) exist.\n  This covers all possible non-trivial values for these error rates. It additionally implies that if all languages in NP have such NIZK proofs and $\u03b5_c$ is negligible, then they also have NIZK proofs where all errors are negligible. Previously, these results were known under the more restrictive condition $ \u03b5_c+\\sqrt{\u03b5_s}+\u03b5_z < 1 $ [Chakraborty et al., CRYPTO 2025].\n  2. If all languages in NP have $k$-round public-coin ZK proofs or arguments satisfying $ \u03b5_c+\u03b5_s+(2k-1).\u03b5_z < 1 $, then OWFs exist.\n  3. If, for some constant $k$, all languages in NP have $k$-round public-coin ZK proofs or arguments satisfying $ \u03b5_c+\u03b5_s+k.\u03b5_z < 1 $, then infinitely-often OWFs exist.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63a2\u8ba8\u4e86\u5f31\u96f6\u77e5\u8bc6\uff08ZK\uff09\u534f\u8bae\u5bf9\u6700\u96be\u8bed\u8a00\u7684\u5f71\u54cd\uff0c\u5e76\u5728\u5047\u8bbe NP \u4e2d\u5b58\u5728\u6700\u96be\u8bed\u8a00\u7684\u60c5\u51b5\u4e0b\uff0c\u5c55\u793a\u4e86\u5f31 ZK \u8bc1\u660e\u6216\u8bba\u8bc1\u7684\u5b58\u5728\u6027\u4e0e OWFs \u4e4b\u95f4\u7684\u5173\u7cfb\u3002\u8bba\u6587\u5206\u4e3a\u4e09\u4e2a\u7ed3\u8bba\uff1a1. \u5982\u679c\u6240\u6709 NP \u8bed\u8a00\u90fd\u5b58\u5728\u6ee1\u8db3 \u03b5_c+\u03b5_s+\u03b5_z < 1 \u7684\u975e\u96f6\u77e5\u8bc6\u8bc1\u660e\uff0c\u5219 OWFs \u5b58\u5728\uff1b2. \u5982\u679c\u6240\u6709 NP \u8bed\u8a00\u90fd\u5b58\u5728 k \u8f6e\u516c\u5171\u786c\u5e01\u96f6\u77e5\u8bc6\u8bc1\u660e\u4e14\u6ee1\u8db3 \u03b5_c+\u03b5_s+(2k-1)\u03b5_z < 1\uff0c\u5219 OWFs \u5b58\u5728\uff1b3. \u5982\u679c\u5bf9\u4e8e\u5e38\u6570 k\uff0c\u6240\u6709 NP \u8bed\u8a00\u90fd\u5b58\u5728 k \u8f6e\u516c\u5171\u786c\u5e01\u96f6\u77e5\u8bc6\u8bc1\u660e\u4e14\u6ee1\u8db3 \u03b5_c+\u03b5_s+k\u03b5_z < 1\uff0c\u5219\u65e0\u7a77\u591a\u6b21 OWFs \u5b58\u5728\u3002", "motivation": "\u7814\u7a76 ZK \u534f\u8bae\u5bf9\u4e8e NP \u5b8c\u5168\u95ee\u9898\u7684\u5f71\u54cd\uff0c\u65e8\u5728\u63a2\u7d22\u5728\u5047\u8bbe NP \u4e2d\u5b58\u5728\u6700\u96be\u95ee\u9898\u7684\u60c5\u51b5\u4e0b\uff0c\u76f8\u5173\u8bc1\u660e\u6216\u8bba\u8bc1\u7684\u5b58\u5728\u6027\u5982\u4f55\u4e0e\u5bc6\u7801\u5b66\u4e2d\u7684\u57fa\u672c\u5047\u8bbe\uff08\u5982 OWFs\uff09\u8054\u7cfb\u8d77\u6765\u3002", "method": "\u901a\u8fc7\u5f62\u5f0f\u5316\u7684\u6570\u5b66\u8bc1\u660e\u6765\u8bba\u8bc1\u7ed3\u8bba\u3002\u5047\u8bbe\u5b58\u5728\u5177\u6709\u7279\u5b9a\u8bef\u5dee\u7387\u7684 NP \u8bed\u8a00\uff0c\u8fdb\u800c\u63a8\u5bfc\u51fa OWFs \u7684\u5b58\u5728\u3002\u4f7f\u7528\u4e86\u590d\u6742\u5ea6\u7406\u8bba\u548c\u96f6\u77e5\u8bc6\u8bc1\u660e\u7684\u76f8\u5173\u6982\u5ff5\u3002", "result": "\u8bc1\u660e\u4e86\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\uff0cNP \u8bed\u8a00\u7684\u67d0\u4e9b\u96f6\u77e5\u8bc6\u8bc1\u660e\u6216\u8bba\u8bc1\u7684\u5b58\u5728\u6027\u53ef\u63a8\u51fa OWFs \u7684\u5b58\u5728\u3002\u5728\u4e0d\u4e25\u683c\u9650\u5236\u8bef\u5dee\u7387\u7684\u60c5\u51b5\u4e0b\uff0c\u63d0\u4f9b\u4e86\u6bd4\u4ee5\u5f80\u7814\u7a76\u66f4\u5e7f\u6cdb\u7684\u7ed3\u8bba\u3002", "conclusion": "\u8bba\u6587\u7684\u7814\u7a76\u7ed3\u679c\u52a0\u5f3a\u4e86\u96f6\u77e5\u8bc6\u8bc1\u660e\u9886\u57df\u548c\u57fa\u7840\u5bc6\u7801\u5b66\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u4e3a\u5728\u5305\u542b\u6700\u96be\u95ee\u9898\u7684\u8bed\u8a00\u4e2d\u5bfb\u627e\u5f31\u96f6\u77e5\u8bc6\u534f\u8bae\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5e76\u8fdb\u4e00\u6b65\u63a2\u8ba8\u4e86 OWFs \u7684\u5b58\u5728\u6761\u4ef6\u3002"}}
{"id": "2602.16037", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.16037", "abs": "https://arxiv.org/abs/2602.16037", "authors": ["Cameron Cagan", "Pedram Fard", "Jiazi Tian", "Jingya Cheng", "Shawn N. Murphy", "Hossein Estiri"], "title": "Optimization Instability in Autonomous Agentic Workflows for Clinical Symptom Detection", "comment": null, "summary": "Autonomous agentic workflows that iteratively refine their own behavior hold considerable promise, yet their failure modes remain poorly characterized. We investigate optimization instability, a phenomenon in which continued autonomous improvement paradoxically degrades classifier performance, using Pythia, an open-source framework for automated prompt optimization. Evaluating three clinical symptoms with varying prevalence (shortness of breath at 23%, chest pain at 12%, and Long COVID brain fog at 3%), we observed that validation sensitivity oscillated between 1.0 and 0.0 across iterations, with severity inversely proportional to class prevalence. At 3% prevalence, the system achieved 95% accuracy while detecting zero positive cases, a failure mode obscured by standard evaluation metrics. We evaluated two interventions: a guiding agent that actively redirected optimization, amplifying overfitting rather than correcting it, and a selector agent that retrospectively identified the best-performing iteration successfully prevented catastrophic failure. With selector agent oversight, the system outperformed expert-curated lexicons on brain fog detection by 331% (F1) and chest pain by 7%, despite requiring only a single natural language term as input. These findings characterize a critical failure mode of autonomous AI systems and demonstrate that retrospective selection outperforms active intervention for stabilization in low-prevalence classification tasks.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u81ea\u52a8\u4f18\u5316\u7684\u4e34\u5e8a\u75c7\u72b6\u5206\u7c7b\u7cfb\u7edf\u5728\u7f55\u89c1\u75c7\u72b6\u5206\u7c7b\u4e2d\u8868\u73b0\u51fa\u4f18\u5316\u4e0d\u7a33\u5b9a\u73b0\u8c61\uff0c\u5373\u4f7f\u91c7\u7528\u56de\u6eaf\u9009\u62e9\u673a\u5236\u4e5f\u65e0\u6cd5\u5b8c\u5168\u907f\u514d\u5931\u8d25\u3002\u7136\u800c\uff0c\u901a\u8fc7\u56de\u6eaf\u9009\u62e9\uff0c\u7cfb\u7edf\u5728\u8111\u96fe\u548c\u80f8\u90e8\u75bc\u75db\u68c0\u6d4b\u65b9\u9762\u7684\u8868\u73b0\u4f18\u4e8e\u4e13\u5bb6\u5b9a\u5236\u7684\u8bcd\u5178\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u63a2\u7a76\u81ea\u52a8\u4f18\u5316\u8fc7\u7a0b\u4e2d\u53ef\u80fd\u51fa\u73b0\u7684\u4f18\u5316\u4e0d\u7a33\u5b9a\u73b0\u8c61\uff0c\u5c24\u5176\u662f\u5728\u4f4e\u9891\u4e34\u5e8a\u75c7\u72b6\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002\u7814\u7a76\u8fd8\u63a2\u8ba8\u4e86\u9488\u5bf9\u6b64\u95ee\u9898\u7684\u4e24\u79cd\u6269\u5c55\u673a\u5236\u7684\u6709\u6548\u6027\u3002", "method": "\u7814\u7a76\u4f7f\u7528Pythia\u6846\u67b6\u5bf9\u4e09\u79cd\u4e0d\u540c\u4e34\u5e8a\u75c7\u72b6\uff08\u547c\u5438\u56f0\u96be\u3001\u80f8\u75db\u548c\u957f\u671fCOVID\u8111\u96fe\uff09\u8fdb\u884c\u81ea\u52a8\u5316\u4f18\u5316\u8bc4\u4f30\uff0c\u540c\u65f6\u63d0\u51fa\u4e24\u79cd\u5e72\u9884\u7b56\u7565\u6765\u76d1\u6d4b\u548c\u7ea0\u6b63\u4f18\u5316\u4e0d\u7a33\u5b9a\u73b0\u8c61\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u7cfb\u7edf\u5728\u4f4e\u9891\u75c7\u72b6\uff08\u5982\u957fCOVID\u8111\u96fe\uff09\u5206\u7c7b\u4e2d\u8868\u73b0\u51fa\u4f18\u5316\u4e0d\u7a33\u5b9a\u73b0\u8c61\uff0c\u5bfc\u81f4\u7cfb\u7edf\u51c6\u786e\u6027\u9ad8\u4f46\u672a\u80fd\u68c0\u6d4b\u51fa\u4efb\u4f55\u9633\u6027\u75c5\u4f8b\u3002\u4e24\u79cd\u5e72\u9884\u7b56\u7565\u4e2d\uff0c\u56de\u6eaf\u9009\u62e9\uff08selector agent\uff09\u5728\u8111\u96fe\u548c\u80f8\u75db\u68c0\u6d4b\u65b9\u9762\u4f18\u4e8e\u4e3b\u52a8\u5e72\u9884\uff08guiding agent\uff09\uff0c\u5e76\u5728\u4f4e\u9891\u75c7\u72b6\u5206\u7c7b\u4e2d\u8868\u73b0\u51fa\u66f4\u7a33\u5b9a\u7684\u8868\u73b0\u3002", "conclusion": "\u672c\u6587\u63ed\u793a\u4e86\u81ea\u52a8\u4f18\u5316\u7cfb\u7edf\u5728\u4f4e\u9891\u75c7\u72b6\u5206\u7c7b\u4e2d\u7684\u5173\u952e\u5931\u8d25\u6a21\u5f0f\uff0c\u5e76\u8bc1\u660e\u4e86\u56de\u6eaf\u9009\u62e9\u673a\u5236\u5bf9\u4e8e\u63d0\u5347\u4f4e\u9891\u75c7\u72b6\u5206\u7c7b\u4efb\u52a1\u7a33\u5b9a\u6027\u7684\u4f18\u8d8a\u6027\u3002"}}
{"id": "2602.16268", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2602.16268", "abs": "https://arxiv.org/abs/2602.16268", "authors": ["Marvin Beckmann", "Christian Majenz"], "title": "Quantum Oracle Distribution Switching and its Applications to Fully Anonymous Ring Signatures", "comment": null, "summary": "Ring signatures are a powerful primitive that allows a member to sign on behalf of a group, without revealing their identity. Recently, ring signatures have received additional attention as an ingredient for post-quantum deniable authenticated key exchange, e.g., for a post-quantum version of the Signal protocol, employed by virtually all end-to-end-encrypted messenger services. While several ring signature constructions from post-quantum assumptions offer suitable security and efficiency for use in deniable key exchange, they are currently proven secure in the random oracle model (ROM) only, which is insufficient for post-quantum security.\n  In this work, we provide four security reductions in the quantum-accessible random oracle model (QROM) for two generic ring signature constructions: two for the AOS framework and two for a construction paradigm based on ring trapdoors, whose generic backbone we formalize. The two security proofs for AOS ring signatures differ in their requirements on the underlying sigma protocol and their tightness. The two reductions for the ring-trapdoor-based ring signatures exhibit various differences in requirements and the security they provide. We employ the measure-and-reprogram technique, QROM straightline extraction tools based on the compressed oracle, history-free reductions and QROM reprogramming tools. To make use of R\u00e9nyi divergence properties in the QROM, we study the behavior of quantum algorithms that interact with an oracle whose distribution is based on one of two different distributions over the set of outputs. We provide tight bounds for the statistical distance, show that the R\u00e9nyi divergence can not be used to replace the entire oracle and provide a workaround.", "AI": {"tldr": "\u672c\u7814\u7a76\u5728\u91cf\u5b50\u8bbf\u95ee\u968f\u673a\u9884\u8a00\u6a21\u578b\uff08QROM\uff09\u4e2d\u4e3a\u4e24\u79cd\u73af\u7b7e\u540d\u6784\u9020\u63d0\u4f9b\u4e86\u56db\u4e2a\u5b89\u5168\u5f52\u7ea6\uff1a\u4e00\u79cd\u57fa\u4e8eAOS\u6846\u67b6\uff0c\u53e6\u4e00\u79cd\u57fa\u4e8e\u73af\u9677\u95e8\u7ed3\u6784\u3002\u4f7f\u7528\u4e86\u591a\u79cd\u6280\u672f\u624b\u6bb5\uff0c\u5305\u62ec\u91cf\u5b50\u968f\u673a\u9884\u8a00\u6a21\u578b\u4e2d\u7684\u76f4\u884c\u5316\u63d0\u53d6\u5de5\u5177\u3001\u538b\u7f29\u9884\u8a00\u3001\u65e0\u5386\u53f2\u5f52\u7ea6\u4ee5\u53ca\u91cf\u5b50\u91cd\u73b0\u5de5\u5177\u3002", "motivation": "\u968f\u7740\u540e\u91cf\u5b50\u65f6\u4ee3\u52a0\u5bc6\u534f\u8bae\u7684\u9700\u6c42\u589e\u52a0\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u53ef\u62b5\u8d56\u7684\u8ba4\u8bc1\u5bc6\u94a5\u4ea4\u6362\u7684\u9700\u6c42\uff0c\u73b0\u6709\u7684\u73af\u7b7e\u540d\u5728ROM\u4e2d\u7684\u5b89\u5168\u6027\u5df2\u4e0d\u8db3\u4ee5\u4fdd\u62a4\u7cfb\u7edf\u7684\u5b89\u5168\u3002\u56e0\u6b64\u9700\u8981\u5728QROM\u4e2d\u8fdb\u884c\u5b89\u5168\u5f52\u7ea6\uff0c\u786e\u4fdd\u8bc1\u636e\u7684\u5b89\u5168\u6027\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528\u4e86\u591a\u79cd\u6280\u672f\u624b\u6bb5\uff0c\u5728QROM\u4e2d\u4e3a\u73af\u7b7e\u540d\u6784\u9020\u63d0\u4f9b\u5b89\u5168\u5f52\u7ea6\uff0c\u5305\u62ec\u5bf9AOS\u6846\u67b6\u548c\u73af\u9677\u95e8\u7ed3\u6784\u7684\u6784\u9020\u8fdb\u884c\u5b89\u5168\u5f52\u7ea6\uff0c\u4f7f\u7528\u4e86\u76f4\u884c\u5316\u63d0\u53d6\u5de5\u5177\u3001\u538b\u7f29\u9884\u8a00\u3001\u65e0\u5386\u53f2\u5f52\u7ea6\u4ee5\u53ca\u91cf\u5b50\u91cd\u73b0\u5de5\u5177\u3002", "result": "\u7814\u7a76\u63d0\u4f9b\u4e86AOS\u6846\u67b6\u548c\u73af\u9677\u95e8\u7ed3\u6784\u4e24\u79cd\u73af\u7b7e\u540d\u6784\u9020\u7684\u5b89\u5168\u5f52\u7ea6\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u4e86\u5176\u5728QROM\u4e2d\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u57fa\u4e8eAOS\u6846\u67b6\u548c\u73af\u9677\u95e8\u7ed3\u6784\u7684\u73af\u7b7e\u540d\u5728QROM\u4e2d\u5177\u6709\u8f83\u9ad8\u7684\u5b89\u5168\u6027\uff0c\u80fd\u591f\u6ee1\u8db3\u540e\u91cf\u5b50\u65f6\u4ee3\u7684\u9700\u6c42\u3002"}}
{"id": "2602.16039", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16039", "abs": "https://arxiv.org/abs/2602.16039", "authors": ["Hang Li", "Kaiqi Yang", "Xianxuan Long", "Fedor Filippov", "Yucheng Chu", "Yasemin Copur-Gencturk", "Peng He", "Cory Miller", "Namsoo Shin", "Joseph Krajcik", "Hui Liu", "Jiliang Tang"], "title": "How Uncertain Is the Grade? A Benchmark of Uncertainty Metrics for LLM-Based Automatic Assessment", "comment": null, "summary": "The rapid rise of large language models (LLMs) is reshaping the landscape of automatic assessment in education. While these systems demonstrate substantial advantages in adaptability to diverse question types and flexibility in output formats, they also introduce new challenges related to output uncertainty, stemming from the inherently probabilistic nature of LLMs. Output uncertainty is an inescapable challenge in automatic assessment, as assessment results often play a critical role in informing subsequent pedagogical actions, such as providing feedback to students or guiding instructional decisions. Unreliable or poorly calibrated uncertainty estimates can lead to unstable downstream interventions, potentially disrupting students' learning processes and resulting in unintended negative consequences. To systematically understand this challenge and inform future research, we benchmark a broad range of uncertainty quantification methods in the context of LLM-based automatic assessment. Although the effectiveness of these methods has been demonstrated in many tasks across other domains, their applicability and reliability in educational settings, particularly for automatic grading, remain underexplored. Through comprehensive analyses of uncertainty behaviors across multiple assessment datasets, LLM families, and generation control settings, we characterize the uncertainty patterns exhibited by LLMs in grading scenarios. Based on these findings, we evaluate the strengths and limitations of different uncertainty metrics and analyze the influence of key factors, including model families, assessment tasks, and decoding strategies, on uncertainty estimates. Our study provides actionable insights into the characteristics of uncertainty in LLM-based automatic assessment and lays the groundwork for developing more reliable and effective uncertainty-aware grading systems in the future.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc4\u4f30\u4e86\u591a\u79cd\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\u5728\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u8bc4\u4f30\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u901a\u8fc7\u5168\u9762\u5206\u6790\u4e0d\u786e\u5b9a\u6027\u884c\u4e3a\uff0c\u63a2\u8ba8\u4e86\u4e0d\u540c\u4e0d\u786e\u5b9a\u6027\u6307\u6807\u7684\u4f18\u7f3a\u70b9\u53ca\u5176\u5f71\u54cd\u56e0\u7d20\uff0c\u4e3a\u5f00\u53d1\u66f4\u53ef\u9760\u548c\u6709\u6548\u7684\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u8bc4\u5206\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u89c1\u89e3\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u81ea\u52a8\u8bc4\u4f30\u4e2d\u7684\u5d1b\u8d77\uff0c\u8bc4\u4f30\u7ed3\u679c\u7684\u4e0d\u51c6\u786e\u6216\u672a\u6821\u51c6\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u53ef\u80fd\u5bfc\u81f4\u4e0b\u6e38\u5e72\u9884\u4e0d\u7a33\u5b9a\uff0c\u5f71\u54cd\u5b66\u751f\u7684\u5b66\u4e60\u8fc7\u7a0b\u3002\u56e0\u6b64\uff0c\u6709\u5fc5\u8981\u7cfb\u7edf\u5730\u7406\u89e3\u8fd9\u4e00\u6311\u6218\uff0c\u6307\u5bfc\u672a\u6765\u7684\u7814\u7a76\u3002", "method": "\u7814\u7a76\u901a\u8fc7\u5168\u9762\u5206\u6790\u591a\u4e2a\u8bc4\u4f30\u6570\u636e\u96c6\u3001\u4e0d\u540c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bb6\u65cf\u4ee5\u53ca\u89e3\u7801\u8bbe\u7f6e\u4e0b\u7684\u4e0d\u786e\u5b9a\u6027\u884c\u4e3a\uff0c\u7814\u7a76\u4e0d\u540c\u4e0d\u786e\u5b9a\u6027\u5ea6\u91cf\u7684\u4f18\u7f3a\u70b9\u3002", "result": "\u7814\u7a76\u63ed\u793a\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8bc4\u5206\u573a\u666f\u4e2d\u5c55\u793a\u51fa\u7684\u4e0d\u786e\u5b9a\u6027\u6a21\u5f0f\uff0c\u5e76\u8bc4\u4f30\u4e86\u4e0d\u540c\u4e0d\u786e\u5b9a\u6027\u6307\u6807\u7684\u6709\u6548\u6027\uff0c\u5206\u6790\u4e86\u6a21\u578b\u5bb6\u65cf\u3001\u8bc4\u4f30\u4efb\u52a1\u548c\u89e3\u7801\u7b56\u7565\u7b49\u5173\u952e\u56e0\u7d20\u5bf9\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u7684\u5f71\u54cd\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5f00\u53d1\u66f4\u53ef\u9760\u548c\u6709\u6548\u7684\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u8bc4\u5206\u7cfb\u7edf\u63d0\u4f9b\u4e86\u884c\u52a8\u6307\u5357\uff0c\u4e3a\u672a\u6765\u7684\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2602.16304", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.16304", "abs": "https://arxiv.org/abs/2602.16304", "authors": ["Ahmed Ryan", "Ibrahim Khalil", "Abdullah Al Jahid", "Md Erfan", "Akond Ashfaque Ur Rahman", "Md Rayhanur Rahman"], "title": "Mind the Gap: Evaluating LLMs for High-Level Malicious Package Detection vs. Fine-Grained Indicator Identification", "comment": null, "summary": "The prevalence of malicious packages in open-source repositories, such as PyPI, poses a critical threat to the software supply chain. While Large Language Models (LLMs) have emerged as a promising tool for automated security tasks, their effectiveness in detecting malicious packages and indicators remains underexplored. This paper presents a systematic evaluation of 13 LLMs for detecting malicious software packages. Using a curated dataset of 4,070 packages (3,700 benign and 370 malicious), we evaluate model performance across two tasks: binary classification (package detection) and multi-label classification (identification of specific malicious indicators). We further investigate the impact of prompting strategies, temperature settings, and model specifications on detection accuracy. We find a significant \"granularity gap\" in LLMs' capabilities. While GPT-4.1 achieves near-perfect performance in binary detection (F1 $\\approx$ 0.99), performance degrades by approximately 41\\% when the task shifts to identifying specific malicious indicators. We observe that general models are best for filtering out the majority of threats, while specialized coder models are better at detecting attacks that follow a strict, predictable code structure. Our correlation analysis indicates that parameter size and context width have negligible explanatory power regarding detection accuracy. We conclude that while LLMs are powerful detectors at the package level, they lack the semantic depth required for precise identification at the granular indicator level.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc4\u4f30\u4e8613\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u68c0\u6d4b\u6076\u610f\u8f6f\u4ef6\u5305\u53ca\u5176\u7279\u5b9a\u6076\u610f\u6307\u6807\u65b9\u9762\u7684\u6027\u80fd\u3002\u53d1\u73b0GPT-4.1\u5728\u4e8c\u5206\u7c7b\u4efb\u52a1\u4e2d\u51e0\u4e4e\u5b8c\u7f8e\uff0c\u4f46\u5728\u68c0\u6d4b\u7279\u5b9a\u6076\u610f\u6307\u6807\u65f6\u6027\u80fd\u4e0b\u964d\u7ea641%\u3002\u7814\u7a76\u8fd8\u53d1\u73b0\uff0c\u901a\u7528\u6a21\u578b\u66f4\u64c5\u957f\u8fc7\u6ee4\u5927\u90e8\u5206\u5a01\u80c1\uff0c\u800c\u4e13\u95e8\u7684\u7f16\u7a0b\u6a21\u578b\u66f4\u9002\u5408\u68c0\u6d4b\u9075\u5faa\u4e25\u683c\u3001\u53ef\u9884\u6d4b\u4ee3\u7801\u7ed3\u6784\u7684\u653b\u51fb\u3002", "motivation": "\u9274\u4e8e\u5f00\u6e90\u4ed3\u5e93\u4e2d\u6076\u610f\u8f6f\u4ef6\u5305\u7684\u5a01\u80c1\uff0c\u63a2\u7d22\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u68c0\u6d4b\u6076\u610f\u8f6f\u4ef6\u4e2d\u7684\u5e94\u7528\uff0c\u4ee5\u589e\u5f3a\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u7684\u5b89\u5168\u6027\u3002", "method": "\u4f7f\u7528\u4e00\u4e2a\u75314,070\u4e2a\u5305\u7ec4\u6210\u7684\u7cbe\u5fc3\u7b56\u5212\u7684\u6570\u636e\u96c6\uff083,700\u4e2a\u826f\u6027\u5305\u548c370\u4e2a\u6076\u610f\u5305\uff09\uff0c\u8bc4\u4f3013\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e8c\u5206\u7c7b\u548c\u591a\u6807\u7b7e\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002\u8fdb\u4e00\u6b65\u63a2\u8ba8\u63d0\u793a\u7b56\u7565\u3001\u6e29\u5ea6\u8bbe\u7f6e\u548c\u6a21\u578b\u89c4\u683c\u5bf9\u68c0\u6d4b\u51c6\u786e\u5ea6\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u663e\u793a\uff0cGPT-4.1\u5728\u4e8c\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u51e0\u4e4e\u5b8c\u7f8e\uff0c\u4f46\u5728\u68c0\u6d4b\u7279\u5b9a\u6076\u610f\u6307\u6807\u65f6\uff0c\u51c6\u786e\u6027\u4e0b\u964d\u4e86\u7ea641%\u3002\u901a\u7528\u6a21\u578b\u66f4\u64c5\u957f\u8fc7\u6ee4\u5927\u591a\u6570\u5a01\u80c1\uff0c\u800c\u4e13\u95e8\u7684\u7f16\u7a0b\u6a21\u578b\u66f4\u9002\u5408\u8bc6\u522b\u4e25\u683c\u3001\u53ef\u9884\u6d4b\u4ee3\u7801\u7ed3\u6784\u7684\u653b\u51fb\u3002\u53c2\u6570\u91cf\u548c\u4e0a\u4e0b\u6587\u5bbd\u5ea6\u5bf9\u68c0\u6d4b\u51c6\u786e\u6027\u7684\u5f71\u54cd\u8f83\u5c0f\u3002", "conclusion": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5305\u5c42\u9762\u5177\u6709\u5f3a\u5927\u7684\u68c0\u6d4b\u80fd\u529b\uff0c\u4f46\u5728\u7cbe\u7ec6\u7684\u6307\u6807\u5c42\u9762\u4ecd\u7f3a\u4e4f\u6240\u9700\u7684\u8bed\u4e49\u6df1\u5ea6\u3002"}}
{"id": "2602.16066", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16066", "abs": "https://arxiv.org/abs/2602.16066", "authors": ["Martin Klissarov", "Jonathan Cook", "Diego Antognini", "Hao Sun", "Jingling Li", "Natasha Jaques", "Claudiu Musat", "Edward Grefenstette"], "title": "Improving Interactive In-Context Learning from Natural Language Feedback", "comment": null, "summary": "Adapting one's thought process based on corrective feedback is an essential ability in human learning, particularly in collaborative settings. In contrast, the current large language model training paradigm relies heavily on modeling vast, static corpora. While effective for knowledge acquisition, it overlooks the interactive feedback loops essential for models to adapt dynamically to their context. In this work, we propose a framework that treats this interactive in-context learning ability not as an emergent property, but as a distinct, trainable skill. We introduce a scalable method that transforms single-turn verifiable tasks into multi-turn didactic interactions driven by information asymmetry. We first show that current flagship models struggle to integrate corrective feedback on hard reasoning tasks. We then demonstrate that models trained with our approach dramatically improve the ability to interactively learn from language feedback. More specifically, the multi-turn performance of a smaller model nearly reaches that of a model an order of magnitude larger. We also observe robust out-of-distribution generalization: interactive training on math problems transfers to diverse domains like coding, puzzles and maze navigation. Our qualitative analysis suggests that this improvement is due to an enhanced in-context plasticity. Finally, we show that this paradigm offers a unified path to self-improvement. By training the model to predict the teacher's critiques, effectively modeling the feedback environment, we convert this external signal into an internal capability, allowing the model to self-correct even without a teacher.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6846\u67b6\uff0c\u65e8\u5728\u4f7f\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5177\u5907\u5728\u4e0a\u4e0b\u6587\u4e92\u52a8\u4e2d\u52a8\u6001\u5b66\u4e60\u7684\u80fd\u529b\u3002\u901a\u8fc7\u5c06\u5355\u8f6e\u53ef\u9a8c\u8bc1\u4efb\u52a1\u8f6c\u5316\u4e3a\u591a\u8f6e\u6559\u5b66\u4e92\u52a8\uff0c\u6a21\u578b\u5728\u56f0\u96be\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u53cd\u9988\u6574\u5408\u80fd\u529b\u663e\u8457\u63d0\u5347\u3002\u5728\u6570\u5b66\u95ee\u9898\u4e0a\u7684\u4e92\u52a8\u8bad\u7ec3\u63a8\u5e7f\u5230\u591a\u4e2a\u9886\u57df\uff0c\u5c55\u793a\u4e86\u589e\u5f3a\u7684\u4e0a\u4e0b\u6587\u9002\u5e94\u6027\u548c\u81ea\u6211\u6539\u5584\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u65b9\u5f0f\u8fc7\u5206\u4f9d\u8d56\u4e8e\u9759\u6001\u8bed\u6599\u5e93\uff0c\u5ffd\u7565\u4e86\u91cd\u8981\u7684\u53cd\u9988\u5faa\u73af\u673a\u5236\u3002\u6587\u7ae0\u65e8\u5728\u5f25\u8865\u8fd9\u4e00\u7f3a\u9677\uff0c\u901a\u8fc7\u5f15\u5165\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\u91cd\u65b0\u5b9a\u4e49\u6a21\u578b\u4e92\u52a8\u5b66\u4e60\u7684\u80fd\u529b\uff0c\u4ece\u800c\u4f7f\u5f97\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u66f4\u597d\u5730\u9002\u5e94\u5b9e\u9645\u5e94\u7528\u573a\u666f\u3002", "method": "\u672c\u6587\u7684\u65b9\u6cd5\u9996\u5148\u901a\u8fc7\u591a\u8f6e\u4e92\u52a8\u5c06\u5355\u8f6e\u9a8c\u8bc1\u4efb\u52a1\u8f6c\u5316\u4e3a\u6559\u5b66\u4e92\u52a8\uff0c\u5f3a\u5316\u4fe1\u606f\u4e0d\u5bf9\u79f0\u4ee5\u4fc3\u8fdb\u6a21\u578b\u9010\u6b65\u63d0\u9ad8\u3002\u5176\u6b21\uff0c\u5bf9\u73b0\u6709\u4e3b\u6d41\u6a21\u578b\u5728\u56f0\u96be\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u53cd\u9988\u6574\u5408\u80fd\u529b\u8fdb\u884c\u5b9e\u9a8c\u5206\u6790\uff0c\u53d1\u73b0\u5b83\u4eec\u8868\u73b0\u4e0d\u4f73\u3002\u7136\u540e\uff0c\u901a\u8fc7\u672c\u6587\u7684\u65b9\u6cd5\u8fdb\u884c\u8bad\u7ec3\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5728\u8bed\u8a00\u53cd\u9988\u4e2d\u7684\u591a\u8f6e\u4ea4\u4e92\u80fd\u529b\u3002\u6700\u540e\uff0c\u901a\u8fc7\u5b9a\u6027\u5206\u6790\u7814\u7a76\u4e86\u6a21\u578b\u6539\u8fdb\u7684\u539f\u56e0\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8f83\u5c0f\u7684\u6a21\u578b\u5728\u591a\u8f6e\u8868\u73b0\u4e0a\u51e0\u4e4e\u8fbe\u5230\u4e86\u66f4\u5927\u6a21\u578b\u7684\u6548\u679c\u3002\u6b64\u5916\uff0c\u4e92\u52a8\u8bad\u7ec3\u5728\u6570\u5b66\u95ee\u9898\u4e0a\u7684\u6210\u6548\u80fd\u591f\u63a8\u5e7f\u81f3\u5176\u4ed6\u9886\u57df\uff0c\u5305\u62ec\u7f16\u7a0b\u3001\u8c1c\u9898\u548c\u8ff7\u5bab\u5bfc\u822a\u7b49\uff0c\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u5206\u5e03\u5916\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u5c06\u4e92\u52a8\u5b66\u4e60\u4f5c\u4e3a\u4e00\u4e2a\u53ef\u88ab\u8bad\u7ec3\u7684\u6280\u80fd\u5f15\u5165\uff0c\u5b9e\u73b0\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e0a\u4e0b\u6587\u4e92\u52a8\u4e2d\u7684\u80fd\u529b\u63d0\u5347\uff0c\u5e76\u5c55\u793a\u4e86\u8fd9\u4e00\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002\u8be5\u6846\u67b6\u4e3a\u6a21\u578b\u81ea\u6211\u6539\u8fdb\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u8def\u5f84\uff0c\u901a\u8fc7\u9884\u6d4b\u8001\u5e08\u7684\u6279\u8bc4\uff0c\u6a21\u578b\u80fd\u591f\u81ea\u7ea0\u9519\uff0c\u65e0\u9700\u5916\u90e8\u6559\u5e08\u4ecb\u5165\u3002"}}
{"id": "2602.16105", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16105", "abs": "https://arxiv.org/abs/2602.16105", "authors": ["Thinh Hung Truong", "Jey Han Lau", "Jianzhong Qi"], "title": "GPSBench: Do Large Language Models Understand GPS Coordinates?", "comment": null, "summary": "Large Language Models (LLMs) are increasingly deployed in applications that interact with the physical world, such as navigation, robotics, or mapping, making robust geospatial reasoning a critical capability. Despite that, LLMs' ability to reason about GPS coordinates and real-world geography remains underexplored. We introduce GPSBench, a dataset of 57,800 samples across 17 tasks for evaluating geospatial reasoning in LLMs, spanning geometric coordinate operations (e.g., distance and bearing computation) and reasoning that integrates coordinates with world knowledge. Focusing on intrinsic model capabilities rather than tool use, we evaluate 14 state-of-the-art LLMs and find that GPS reasoning remains challenging, with substantial variation across tasks: models are generally more reliable at real-world geographic reasoning than at geometric computations. Geographic knowledge degrades hierarchically, with strong country-level performance but weak city-level localization, while robustness to coordinate noise suggests genuine coordinate understanding rather than memorization. We further show that GPS-coordinate augmentation can improve in downstream geospatial tasks, and that finetuning induces trade-offs between gains in geometric computation and degradation in world knowledge. Our dataset and reproducible code are available at https://github.com/joey234/gpsbench", "AI": {"tldr": "\u8be5\u7814\u7a76\u5f15\u5165\u4e86\u4e00\u4e2a\u540d\u4e3aGPSBench\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5730\u7406\u7a7a\u95f4\u63a8\u7406\u65b9\u9762\u7684\u8868\u73b0\uff0c\u6db5\u76d6\u5750\u6807\u64cd\u4f5c\u548c\u7ed3\u5408\u4e16\u754c\u77e5\u8bc6\u7684\u63a8\u7406\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u5c3d\u7ba1\u6a21\u578b\u5728\u73b0\u5b9e\u5730\u7406\u63a8\u7406\u65b9\u9762\u8868\u73b0\u8f83\u597d\uff0c\u4f46\u5728\u51e0\u4f55\u8ba1\u7b97\u548c\u5730\u7406\u77e5\u8bc6\u7684\u5c42\u6b21\u6027\u65b9\u9762\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u4e14\u5fae\u8c03\u4f1a\u5bfc\u81f4\u8ba1\u7b97\u548c\u77e5\u8bc6\u4e4b\u95f4\u7684\u6743\u8861\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u73b0\u5b9e\u4e16\u754c\u5e94\u7528\u4e2d\u7684\u90e8\u7f72\u589e\u52a0\uff0c\u5982\u5bfc\u822a\u3001\u673a\u5668\u4eba\u6216\u5236\u56fe\uff0c\u9c81\u68d2\u7684\u5730\u7406\u7a7a\u95f4\u63a8\u7406\u6210\u4e3a\u5173\u952e\u80fd\u529b\u3002\u7136\u800c\uff0c\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406GPS\u5750\u6807\u548c\u73b0\u5b9e\u4e16\u754c\u5730\u7406\u65b9\u9762\u7684\u63a8\u7406\u80fd\u529b\u7814\u7a76\u4e0d\u8db3\u3002\u7814\u7a76\u8005\u521b\u5efa\u4e86GPSBench\u6570\u636e\u96c6\u4ee5\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u65e8\u5728\u66f4\u597d\u5730\u8bc4\u4f30\u5e76\u4fc3\u8fdb\u76f8\u5173\u6280\u672f\u7684\u53d1\u5c55\u3002", "method": "\u7814\u7a76\u4eba\u5458\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b57,800\u4e2a\u6837\u672c\u7684GPSBench\u6570\u636e\u96c6\uff0c\u6db5\u76d617\u9879\u4efb\u52a1\u4ee5\u53ca\u51e0\u4f55\u5750\u6807\u64cd\u4f5c\u548c\u7ed3\u5408\u4e16\u754c\u77e5\u8bc6\u7684\u63a8\u7406\u3002\u4ed6\u4eec\u8bc4\u4f30\u4e8614\u6b3e\u6700\u5148\u8fdb\u7684\u8bed\u8a00\u6a21\u578b\uff0c\u4f7f\u7528\u4e00\u4e2a\u6807\u51c6\u6765\u8861\u91cf\u8fd9\u4e9b\u6a21\u578b\u7684\u5730\u7406\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\uff0c\u5373\u8003\u8651\u6a21\u578b\u7684\u5185\u5728\u80fd\u529b\u800c\u975e\u5de5\u5177\u8f85\u52a9\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u6a21\u578b\u5728\u73b0\u5b9e\u5730\u7406\u65b9\u9762\u7684\u63a8\u7406\u8868\u73b0\u4f18\u4e8e\u51e0\u4f55\u8ba1\u7b97\u3002\u5730\u7406\u77e5\u8bc6\u5448\u73b0\u51fa\u5c42\u6b21\u6027\u7684\u8870\u9000\uff0c\u8868\u73b0\u4e3a\u5728\u56fd\u5bb6\u5c42\u9762\u7684\u6027\u80fd\u4f18\u4e8e\u57ce\u5e02\u5c42\u9762\u7684\u5b9a\u4f4d\u3002\u6a21\u578b\u5bf9\u5750\u6807\u566a\u58f0\u7684\u9c81\u68d2\u6027\u8868\u660e\uff0c\u8fd9\u4e9b\u6a21\u578b\u771f\u6b63\u7406\u89e3\u4e86\u5750\u6807\u800c\u975e\u4ec5\u4f9d\u8d56\u8bb0\u5fc6\u3002\u6b64\u5916\uff0c\u7814\u7a76\u4eba\u5458\u53d1\u73b0\u5750\u6807\u589e\u5f3a\u80fd\u591f\u63d0\u5347\u4e0b\u6e38\u5730\u7406\u7a7a\u95f4\u4efb\u52a1\u7684\u6548\u679c\uff0c\u540c\u65f6\u5fae\u8c03\u4f1a\u5e26\u6765\u51e0\u4f55\u8ba1\u7b97\u80fd\u529b\u63d0\u5347\u4e0e\u4e16\u754c\u77e5\u8bc6\u4e0b\u964d\u4e4b\u95f4\u7684\u6743\u8861\u3002", "conclusion": "\u7814\u7a76\u5f97\u51fa\u7ed3\u8bba\uff0c\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5730\u7406\u65b9\u9762\u7684\u63a8\u7406\u6709\u6f5c\u529b\uff0c\u4f46\u5728\u51e0\u4f55\u8ba1\u7b97\u3001\u5c42\u6b21\u5730\u7406\u77e5\u8bc6\u548c\u9c81\u68d2\u6027\u65b9\u9762\u4ecd\u5b58\u5728\u95ee\u9898\u3002\u672a\u6765\u7814\u7a76\u9700\u66f4\u6df1\u5165\u63a2\u7d22\u6a21\u578b\u7684\u80fd\u529b\uff0c\u5e76\u8003\u8651\u5982\u4f55\u4f18\u5316\u4ee5\u83b7\u5f97\u66f4\u5168\u9762\u7684\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2602.16520", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16520", "abs": "https://arxiv.org/abs/2602.16520", "authors": ["Doron Shavit"], "title": "Recursive language models for jailbreak detection: a procedural defense for tool-augmented agents", "comment": "5 pages and 1 figure. Appendix: an additional 5 pages", "summary": "Jailbreak prompts are a practical and evolving threat to large language models (LLMs), particularly in agentic systems that execute tools over untrusted content. Many attacks exploit long-context hiding, semantic camouflage, and lightweight obfuscations that can evade single-pass guardrails. We present RLM-JB, an end-to-end jailbreak detection framework built on Recursive Language Models (RLMs), in which a root model orchestrates a bounded analysis program that transforms the input, queries worker models over covered segments, and aggregates evidence into an auditable decision. RLM-JB treats detection as a procedure rather than a one-shot classification: it normalizes and de-obfuscates suspicious inputs, chunks text to reduce context dilution and guarantee coverage, performs parallel chunk screening, and composes cross-chunk signals to recover split-payload attacks. On AutoDAN-style adversarial inputs, RLM-JB achieves high detection effectiveness across three LLM backends (ASR/Recall 92.5-98.0%) while maintaining very high precision (98.99-100%) and low false positive rates (0.0-2.0%), highlighting a practical sensitivity-specificity trade-off as the screening backend changes.", "AI": {"tldr": "RLM-JB \u662f\u4e00\u4e2a\u57fa\u4e8e\u9012\u5f52\u8bed\u8a00\u6a21\u578b\uff08RLMs\uff09\u7684\u5168\u9762\u7684\u53cd\u8d8a\u72f1\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u6b65\u5904\u7406\u3001\u8bc1\u636e\u805a\u5408\u548c\u8de8\u7247\u6bb5\u4fe1\u53f7\u5904\u7406\uff0c\u6709\u6548\u68c0\u6d4b\u6f5c\u5728\u7684\u653b\u51fb\uff0c\u5e76\u4fdd\u6301\u9ad8\u5ea6\u7684\u7cbe\u5ea6\u548c\u4f4e\u8bef\u62a5\u7387\u3002", "motivation": "\u9762\u5bf9\u65e5\u76ca\u590d\u6742\u7684\u8bed\u8a00\u6a21\u578b\u653b\u51fb\uff0c\u7279\u522b\u662f\u9488\u5bf9\u4ee3\u6267\u884c\u5de5\u5177\u7684\u653b\u51fb\uff0c\u9700\u8981\u4e00\u4e2a\u5168\u9762\u4e14\u6709\u6548\u7684\u68c0\u6d4b\u6846\u67b6\u6765\u4fdd\u8bc1\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u3002", "method": "RLM-JB \u4f7f\u7528\u4e86\u9012\u5f52\u8bed\u8a00\u6a21\u578b\u6765\u6784\u5efa\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u6b65\u5904\u7406\u8f93\u5165\u3001\u8bc1\u636e\u805a\u5408\u4ee5\u53ca\u8de8\u7247\u6bb5\u4fe1\u53f7\u5904\u7406\u7b49\u65b9\u6cd5\uff0c\u63d0\u9ad8\u4e86\u68c0\u6d4b\u7684\u53ef\u9760\u6027\u548c\u51c6\u786e\u6027\u3002", "result": "\u5728\u9488\u5bf9 AutoDAN \u98ce\u683c\u7684\u5bf9\u6297\u8f93\u5165\u4e2d\uff0cRLM-JB \u80fd\u591f\u5728\u4e09\u4e2a\u4e0d\u540c\u7684\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u540e\u7aef\u4e2d\u5b9e\u73b0\u9ad8\u68c0\u6d4b\u6548\u529b\uff08ASR/\u53ec\u56de\u738792.5-98.0%\uff09\uff0c\u5e76\u4fdd\u6301\u9ad8\u7cbe\u5ea6\uff0898.99-100%\uff09\u548c\u4f4e\u8bef\u62a5\u7387\uff080.0-2.0%\uff09\u3002", "conclusion": "\u8be5\u7814\u7a76\u8bc1\u660e\u4e86\u57fa\u4e8e\u9012\u5f52\u8bed\u8a00\u6a21\u578b\u7684\u53cd\u8d8a\u72f1\u68c0\u6d4b\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u4e14\u5728\u4e0d\u540c\u8bed\u8a00\u6a21\u578b\u540e\u7aef\u5747\u80fd\u4fdd\u6301\u9ad8\u6027\u80fd\uff0c\u4e3a\u672a\u6765\u7684\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u63d0\u4f9b\u4e86\u501f\u9274\u610f\u4e49\u3002"}}
{"id": "2602.16192", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.16192", "abs": "https://arxiv.org/abs/2602.16192", "authors": ["Hiroaki Yamanaka", "Daisuke Miyashita", "Takashi Toi", "Asuka Maki", "Taiga Ikeda", "Jun Deguchi"], "title": "Revolutionizing Long-Term Memory in AI: New Horizons with High-Capacity and High-Speed Storage", "comment": "13 pages, 5 figures", "summary": "Driven by our mission of \"uplifting the world with memory,\" this paper explores the design concept of \"memory\" that is essential for achieving artificial superintelligence (ASI). Rather than proposing novel methods, we focus on several alternative approaches whose potential benefits are widely imaginable, yet have remained largely unexplored. The currently dominant paradigm, which can be termed \"extract then store,\" involves extracting information judged to be useful from experiences and saving only the extracted content. However, this approach inherently risks the loss of information, as some valuable knowledge particularly for different tasks may be discarded in the extraction process. In contrast, we emphasize the \"store then on-demand extract\" approach, which seeks to retain raw experiences and flexibly apply them to various tasks as needed, thus avoiding such information loss. In addition, we highlight two further approaches: discovering deeper insights from large collections of probabilistic experiences, and improving experience collection efficiency by sharing stored experiences. While these approaches seem intuitively effective, our simple experiments demonstrate that this is indeed the case. Finally, we discuss major challenges that have limited investigation into these promising directions and propose research topics to address them.", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22\u4e86\u5b9e\u73b0\u4eba\u5de5\u667a\u80fd\u8d85\u7ea7\u667a\u80fd\uff08ASI\uff09\u81f3\u5173\u91cd\u8981\u7684\u2018\u8bb0\u5fc6\u2019\u8bbe\u8ba1\u6982\u5ff5\uff0c\u63d0\u51fa\u4e86\u63d0\u53d6\u540e\u518d\u5b58\u50a8\u3001\u5b58\u50a8\u540e\u518d\u6309\u9700\u63d0\u53d6\u3001\u4ece\u5927\u91cf\u6982\u7387\u4f53\u9a8c\u4e2d\u53d1\u73b0\u66f4\u6df1\u5c42\u6b21\u7684\u6d1e\u89c1\u4ee5\u53ca\u63d0\u9ad8\u4f53\u9a8c\u6536\u96c6\u6548\u7387\u7b49\u66ff\u4ee3\u65b9\u6cd5\u3002", "motivation": "\u4e3a\u4e86\u5b9e\u73b0\u4eba\u5de5\u667a\u80fd\u8d85\u7ea7\u667a\u80fd\uff08ASI\uff09\uff0c\u63a2\u7d22\u5e76\u5f3a\u8c03\u4e86\u4e0d\u540c\u7684\u2018\u8bb0\u5fc6\u2019\u8bbe\u8ba1\u7b56\u7565\uff0c\u4ee5\u907f\u514d\u4fe1\u606f\u635f\u5931\u548c\u4fc3\u8fdb\u66f4\u9ad8\u6548\u7684\u4f53\u9a8c\u6536\u96c6\uff0c\u540c\u65f6\u63a8\u8fdb\u76f8\u5173\u7814\u7a76\u9886\u57df\u3002", "method": "\u5728\u6ca1\u6709\u63d0\u51fa\u65b0\u578b\u65b9\u6cd5\u7684\u60c5\u51b5\u4e0b\uff0c\u8ba8\u8bba\u4e86\u56db\u79cd\u66ff\u4ee3\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u7b80\u5355\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5b83\u4eec\u7684\u6709\u6548\u6027\u3002", "result": "\u7b80\u5355\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u63d0\u51fa\u7684\u66ff\u4ee3\u65b9\u6cd5\u5728\u5b9e\u8df5\u4e2d\u662f\u6709\u6548\u7684\u3002", "conclusion": "\u5c3d\u7ba1\u8fd9\u4e9b\u66ff\u4ee3\u65b9\u6cd5\u770b\u4f3c\u6709\u6548\uff0c\u4f46\u5728\u8c03\u67e5\u8fd9\u4e9b\u6709\u524d\u9014\u7684\u65b9\u5411\u4e2d\u4ecd\u9762\u4e34\u91cd\u5927\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u4e00\u4e9b\u7814\u7a76\u4e3b\u9898\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002"}}
{"id": "2602.16424", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.16424", "abs": "https://arxiv.org/abs/2602.16424", "authors": ["Philipp Schoenegger", "Matt Carlson", "Chris Schneider", "Chris Daly"], "title": "Verifiable Semantics for Agent-to-Agent Communication", "comment": null, "summary": "Multiagent AI systems require consistent communication, but we lack methods to verify that agents share the same understanding of the terms used. Natural language is interpretable but vulnerable to semantic drift, while learned protocols are efficient but opaque. We propose a certification protocol based on the stimulus-meaning model, where agents are tested on shared observable events and terms are certified if empirical disagreement falls below a statistical threshold. In this protocol, agents restricting their reasoning to certified terms (\"core-guarded reasoning\") achieve provably bounded disagreement. We also outline mechanisms for detecting drift (recertification) and recovering shared vocabulary (renegotiation). In simulations with varying degrees of semantic divergence, core-guarding reduces disagreement by 72-96%. In a validation with fine-tuned language models, disagreement is reduced by 51%. Our framework provides a first step towards verifiable agent-to-agent communication.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.16435", "categories": ["cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.16435", "abs": "https://arxiv.org/abs/2602.16435", "authors": ["Arun Vignesh Malarkkan", "Wangyang Ying", "Yanjie Fu"], "title": "Causally-Guided Automated Feature Engineering with Multi-Agent Reinforcement Learning", "comment": "11 Pages, References and Appendix", "summary": "Automated feature engineering (AFE) enables AI systems to autonomously construct high-utility representations from raw tabular data. However, existing AFE methods rely on statistical heuristics, yielding brittle features that fail under distribution shift. We introduce CAFE, a framework that reformulates AFE as a causally-guided sequential decision process, bridging causal discovery with reinforcement learning-driven feature construction. Phase I learns a sparse directed acyclic graph over features and the target to obtain soft causal priors, grouping features as direct, indirect, or other based on their causal influence with respect to the target. Phase II uses a cascading multi-agent deep Q-learning architecture to select causal groups and transformation operators, with hierarchical reward shaping and causal group-level exploration strategies that favor causally plausible transformations while controlling feature complexity. Across 15 public benchmarks (classification with macro-F1; regression with inverse relative absolute error), CAFE achieves up to 7% improvement over strong AFE baselines, reduces episodes-to-convergence, and delivers competitive time-to-target. Under controlled covariate shifts, CAFE reduces performance drop by ~4x relative to a non-causal multi-agent baseline, and produces more compact feature sets with more stable post-hoc attributions. These findings underscore that causal structure, used as a soft inductive prior rather than a rigid constraint, can substantially improve the robustness and efficiency of automated feature engineering.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.16481", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16481", "abs": "https://arxiv.org/abs/2602.16481", "authors": ["Zihao Li", "Fabrizio Russo"], "title": "Leveraging Large Language Models for Causal Discovery: a Constraint-based, Argumentation-driven Approach", "comment": "26 pages, including appendix", "summary": "Causal discovery seeks to uncover causal relations from data, typically represented as causal graphs, and is essential for predicting the effects of interventions. While expert knowledge is required to construct principled causal graphs, many statistical methods have been proposed to leverage observational data with varying formal guarantees. Causal Assumption-based Argumentation (ABA) is a framework that uses symbolic reasoning to ensure correspondence between input constraints and output graphs, while offering a principled way to combine data and expertise. We explore the use of large language models (LLMs) as imperfect experts for Causal ABA, eliciting semantic structural priors from variable names and descriptions and integrating them with conditional-independence evidence. Experiments on standard benchmarks and semantically grounded synthetic graphs demonstrate state-of-the-art performance, and we additionally introduce an evaluation protocol to mitigate memorisation bias when assessing LLMs for causal discovery.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.16512", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16512", "abs": "https://arxiv.org/abs/2602.16512", "authors": ["Felix Fricke", "Simon Malberg", "Georg Groh"], "title": "Framework of Thoughts: A Foundation Framework for Dynamic and Optimized Reasoning based on Chains, Trees, and Graphs", "comment": null, "summary": "Prompting schemes such as Chain of Thought, Tree of Thoughts, and Graph of Thoughts can significantly enhance the reasoning capabilities of large language models. However, most existing schemes require users to define static, problem-specific reasoning structures that lack adaptability to dynamic or unseen problem types. Additionally, these schemes are often under-optimized in terms of hyperparameters, prompts, runtime, and prompting cost. To address these limitations, we introduce Framework of Thoughts (FoT)--a general-purpose foundation framework for building and optimizing dynamic reasoning schemes. FoT comes with built-in features for hyperparameter tuning, prompt optimization, parallel execution, and intelligent caching, unlocking the latent performance potential of reasoning schemes. We demonstrate FoT's capabilities by implementing three popular schemes--Tree of Thoughts, Graph of Thoughts, and ProbTree--within FoT. We empirically show that FoT enables significantly faster execution, reduces costs, and achieves better task scores through optimization. We release our codebase to facilitate the development of future dynamic and efficient reasoning schemes.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.16578", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.16578", "abs": "https://arxiv.org/abs/2602.16578", "authors": ["Vered Tohar", "Tsahi Hayat", "Amir Leshem"], "title": "Creating a digital poet", "comment": "24 pages, 3 figures", "summary": "Can a machine write good poetry? Any positive answer raises fundamental questions about the nature and value of art. We report a seven-month poetry workshop in which a large language model was shaped into a digital poet through iterative in-context expert feedback, without retraining. Across sessions, the model developed a distinctive style and a coherent corpus, supported by quantitative and qualitative analyses, and it produced a pen name and author image. In a blinded authorship test with 50 humanities students and graduates (three AI poems and three poems by well-known poets each), judgments were at chance: human poems were labeled human 54% of the time and AI poems 52%, with 95% confidence intervals including 50%. After the workshop, a commercial publisher released a poetry collection authored by the model. These results show that workshop-style prompting can support long-horizon creative shaping and renew debates on creativity and authorship.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2602.16653", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16653", "abs": "https://arxiv.org/abs/2602.16653", "authors": ["Yangjie Xu", "Lujun Li", "Lama Sleem", "Niccolo Gentile", "Yewei Song", "Yiqun Wang", "Siming Ji", "Wenbo Wu", "Radu State"], "title": "Agent Skill Framework: Perspectives on the Potential of Small Language Models in Industrial Environments", "comment": null, "summary": "Agent Skill framework, now widely and officially supported by major players such as GitHub Copilot, LangChain, and OpenAI, performs especially well with proprietary models by improving context engineering, reducing hallucinations, and boosting task accuracy. Based on these observations, an investigation is conducted to determine whether the Agent Skill paradigm provides similar benefits to small language models (SLMs). This question matters in industrial scenarios where continuous reliance on public APIs is infeasible due to data-security and budget constraints requirements, and where SLMs often show limited generalization in highly customized scenarios. This work introduces a formal mathematical definition of the Agent Skill process, followed by a systematic evaluation of language models of varying sizes across multiple use cases. The evaluation encompasses two open-source tasks and a real-world insurance claims data set. The results show that tiny models struggle with reliable skill selection, while moderately sized SLMs (approximately 12B - 30B) parameters) benefit substantially from the Agent Skill approach. Moreover, code-specialized variants at around 80B parameters achieve performance comparable to closed-source baselines while improving GPU efficiency. Collectively, these findings provide a comprehensive and nuanced characterization of the capabilities and constraints of the framework, while providing actionable insights for the effective deployment of Agent Skills in SLM-centered environments.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
